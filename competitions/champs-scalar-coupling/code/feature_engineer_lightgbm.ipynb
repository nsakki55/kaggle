{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/criskiev/distance-is-all-you-need-lb-1-481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../input'\n",
    "SUBMISSIONS_PATH = './'\n",
    "# use atomic numbers to recode atomic names\n",
    "ATOMIC_NUMBERS = {\n",
    "    'H': 1,\n",
    "    'C': 6,\n",
    "    'N': 7,\n",
    "    'O': 8,\n",
    "    'F': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 120)\n",
    "pd.set_option('display.max_columns', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/home/nagae/anaconda3/envs/gpu-env/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
=======
      "/home/nagae/.conda/envs/gpu-env/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
>>>>>>> f38c5a3fada567d5fd5ef03c20ccba924f0bb423
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.807602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.807404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.809303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.809502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    molecule_index  atom_index_0  atom_index_1  type  scalar_coupling_constant\n",
       "id                                                                            \n",
       "0   1               1             0             1JHC  84.807602               \n",
       "1   1               1             2             2JHH -11.257000               \n",
       "2   1               1             3             2JHH -11.254800               \n",
       "3   1               1             4             2JHH -11.254300               \n",
       "4   1               2             0             1JHC  84.807404               \n",
       "5   1               2             3             2JHH -11.254100               \n",
       "6   1               2             4             2JHH -11.254800               \n",
       "7   1               3             0             1JHC  84.809303               \n",
       "8   1               3             4             2JHH -11.254300               \n",
       "9   1               4             0             1JHC  84.809502               "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dtypes = {\n",
    "    'molecule_name': 'category',\n",
    "    'atom_index_0': 'int8',\n",
    "    'atom_index_1': 'int8',\n",
    "    'type': 'category',\n",
    "    'scalar_coupling_constant': 'float32'\n",
    "}\n",
    "train_csv = pd.read_csv(f'{DATA_PATH}/train.csv', index_col='id', dtype=train_dtypes)\n",
    "train_csv['molecule_index'] = train_csv.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "train_csv = train_csv[['molecule_index', 'atom_index_0', 'atom_index_1', 'type', 'scalar_coupling_constant']]\n",
    "train_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (4658147, 5)\n",
      "Total:  88505177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index                       37265176\n",
       "molecule_index              18632588\n",
       "atom_index_0                4658147 \n",
       "atom_index_1                4658147 \n",
       "type                        4658531 \n",
       "scalar_coupling_constant    18632588\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Shape: ', train_csv.shape)\n",
    "print('Total: ', train_csv.memory_usage().sum())\n",
    "train_csv.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv = pd.read_csv(f'{DATA_PATH}/sample_submission.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4658147</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658148</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658149</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3JHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658150</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658151</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658152</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658153</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658154</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658155</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2JHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658156</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         molecule_index  atom_index_0  atom_index_1  type\n",
       "id                                                       \n",
       "4658147  4               2             0             2JHC\n",
       "4658148  4               2             1             1JHC\n",
       "4658149  4               2             3             3JHH\n",
       "4658150  4               3             0             1JHC\n",
       "4658151  4               3             1             2JHC\n",
       "4658152  15              3             0             1JHC\n",
       "4658153  15              3             2             3JHC\n",
       "4658154  15              3             4             2JHH\n",
       "4658155  15              3             5             2JHH\n",
       "4658156  15              4             0             1JHC"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv = pd.read_csv(f'{DATA_PATH}/test.csv', index_col='id', dtype=train_dtypes)\n",
    "test_csv['molecule_index'] = test_csv['molecule_name'].str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "test_csv = test_csv[['molecule_index', 'atom_index_0', 'atom_index_1', 'type']]\n",
    "test_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index</th>\n",
       "      <th>atom</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.040426</td>\n",
       "      <td>1.024108</td>\n",
       "      <td>0.062564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017257</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>-0.027377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>1.358745</td>\n",
       "      <td>-0.028758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.520278</td>\n",
       "      <td>1.343532</td>\n",
       "      <td>-0.775543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.034360</td>\n",
       "      <td>0.977540</td>\n",
       "      <td>0.007602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   molecule_index  atom_index  atom         x         y         z\n",
       "0  1               0           6    -0.012698  1.085804  0.008001\n",
       "1  1               1           1     0.002150 -0.006031  0.001976\n",
       "2  1               2           1     1.011731  1.463751  0.000277\n",
       "3  1               3           1    -0.540815  1.447527 -0.876644\n",
       "4  1               4           1    -0.523814  1.437933  0.906397\n",
       "5  2               0           7    -0.040426  1.024108  0.062564\n",
       "6  2               1           1     0.017257  0.012545 -0.027377\n",
       "7  2               2           1     0.915789  1.358745 -0.028758\n",
       "8  2               3           1    -0.520278  1.343532 -0.775543\n",
       "9  3               0           8    -0.034360  0.977540  0.007602"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_dtypes = {\n",
    "    'molecule_name': 'category',\n",
    "    'atom_index': 'int8',\n",
    "    'atom': 'category',\n",
    "    'x': 'float32',\n",
    "    'y': 'float32',\n",
    "    'z': 'float32'\n",
    "}\n",
    "structures_csv = pd.read_csv(f'{DATA_PATH}/structures.csv', dtype=structures_dtypes)\n",
    "structures_csv['molecule_index'] = structures_csv.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "structures_csv = structures_csv[['molecule_index', 'atom_index', 'atom', 'x', 'y', 'z']]\n",
    "structures_csv['atom'] = structures_csv['atom'].replace(ATOMIC_NUMBERS).astype('int8')\n",
    "structures_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_type_dataframes(base, structures, coupling_type):\n",
    "    base = base[base['type'] == coupling_type].drop('type', axis=1).copy()\n",
    "    base = base.reset_index()\n",
    "    base['id'] = base['id'].astype('int32')\n",
    "    structures = structures[structures['molecule_index'].isin(base['molecule_index'])]\n",
    "    return base, structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coordinates(base, structures, index):\n",
    "    df = pd.merge(base, structures, how='inner',\n",
    "                  left_on=['molecule_index', f'atom_index_{index}'],\n",
    "                  right_on=['molecule_index', 'atom_index']).drop(['atom_index'], axis=1)\n",
    "    df = df.rename(columns={\n",
    "        'atom': f'atom_{index}',\n",
    "        'x': f'x_{index}',\n",
    "        'y': f'y_{index}',\n",
    "        'z': f'z_{index}'\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_atoms(base, atoms):\n",
    "    df = pd.merge(base, atoms, how='inner',\n",
    "                  on=['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_atoms(base, structures):\n",
    "    df = pd.merge(base, structures, how='left',\n",
    "                  left_on=['molecule_index'],\n",
    "                  right_on=['molecule_index'])\n",
    "    df = df[(df.atom_index_0 != df.atom_index) & (df.atom_index_1 != df.atom_index)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_center(df):\n",
    "    df['x_c'] = ((df['x_1'] + df['x_0']) * np.float32(0.5))\n",
    "    df['y_c'] = ((df['y_1'] + df['y_0']) * np.float32(0.5))\n",
    "    df['z_c'] = ((df['z_1'] + df['z_0']) * np.float32(0.5))\n",
    "\n",
    "def add_distance_to_center(df):\n",
    "    df['d_c'] = ((\n",
    "        (df['x_c'] - df['x'])**np.float32(2) +\n",
    "        (df['y_c'] - df['y'])**np.float32(2) + \n",
    "        (df['z_c'] - df['z'])**np.float32(2)\n",
    "    )**np.float32(0.5))\n",
    "\n",
    "def add_distance_between(df, suffix1, suffix2):\n",
    "    df[f'd_{suffix1}_{suffix2}'] = ((\n",
    "        (df[f'x_{suffix1}'] - df[f'x_{suffix2}'])**np.float32(2) +\n",
    "        (df[f'y_{suffix1}'] - df[f'y_{suffix2}'])**np.float32(2) + \n",
    "        (df[f'z_{suffix1}'] - df[f'z_{suffix2}'])**np.float32(2)\n",
    "    )**np.float32(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distances(df):\n",
    "    n_atoms = 1 + max([int(c.split('_')[1]) for c in df.columns if c.startswith('x_')])\n",
    "    \n",
    "    for i in range(1, n_atoms):\n",
    "        for vi in range(min(4, i)):\n",
    "            add_distance_between(df, i, vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_n_atoms(base, structures):\n",
    "    dfs = structures['molecule_index'].value_counts().rename('n_atoms').to_frame()\n",
    "    return pd.merge(base, dfs, left_on='molecule_index', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms=10):\n",
    "    base, structures = build_type_dataframes(some_csv, structures_csv, coupling_type)\n",
    "    base = add_coordinates(base, structures, 0)\n",
    "    base = add_coordinates(base, structures, 1)\n",
    "    \n",
    "    base = base.drop(['atom_0', 'atom_1'], axis=1)\n",
    "    atoms = base.drop('id', axis=1).copy()\n",
    "    if 'scalar_coupling_constant' in some_csv:\n",
    "        atoms = atoms.drop(['scalar_coupling_constant'], axis=1)\n",
    "        \n",
    "    add_center(atoms)\n",
    "    atoms = atoms.drop(['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1'], axis=1)\n",
    "\n",
    "    atoms = merge_all_atoms(atoms, structures)\n",
    "    \n",
    "    add_distance_to_center(atoms)\n",
    "    \n",
    "    atoms = atoms.drop(['x_c', 'y_c', 'z_c', 'atom_index'], axis=1)\n",
    "    atoms.sort_values(['molecule_index', 'atom_index_0', 'atom_index_1', 'd_c'], inplace=True)\n",
    "    atom_groups = atoms.groupby(['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    atoms['num'] = atom_groups.cumcount() + 2\n",
    "    atoms = atoms.drop(['d_c'], axis=1)\n",
    "    atoms = atoms[atoms['num'] < n_atoms]\n",
    "\n",
    "    atoms = atoms.set_index(['molecule_index', 'atom_index_0', 'atom_index_1', 'num']).unstack()\n",
    "    atoms.columns = [f'{col[0]}_{col[1]}' for col in atoms.columns]\n",
    "    atoms = atoms.reset_index()\n",
    "    \n",
    "    # downcast back to int8\n",
    "    for col in atoms.columns:\n",
    "        if col.startswith('atom_'):\n",
    "            atoms[col] = atoms[col].fillna(0).astype('int8')\n",
    "            \n",
    "    atoms['molecule_index'] = atoms['molecule_index'].astype('int32')\n",
    "    \n",
    "    full = add_atoms(base, atoms)\n",
    "    add_distances(full)\n",
    "    \n",
    "    full.sort_values('id', inplace=True)\n",
    "    \n",
    "    return full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_n_atoms(df, n_atoms, four_start=4):\n",
    "    labels = []\n",
    "    for i in range(2, n_atoms):\n",
    "        label = f'atom_{i}'\n",
    "        labels.append(label)\n",
    "\n",
    "    for i in range(n_atoms):\n",
    "        num = min(i, 4) if i < four_start else 4\n",
    "        for j in range(num):\n",
    "            labels.append(f'd_{i}_{j}')\n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        labels.append('scalar_coupling_constant')\n",
    "    return df[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43363, 73)\n",
<<<<<<< HEAD
      "CPU times: user 5 s, sys: 376 ms, total: 5.38 s\n",
      "Wall time: 1.74 s\n"
=======
      "CPU times: user 3.13 s, sys: 79.9 ms, total: 3.21 s\n",
      "Wall time: 854 ms\n"
>>>>>>> f38c5a3fada567d5fd5ef03c20ccba924f0bb423
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full = build_couple_dataframe(train_csv, structures_csv, '1JHN', n_atoms=10)\n",
    "print(full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>atom_2</th>\n",
       "      <th>atom_3</th>\n",
       "      <th>atom_4</th>\n",
       "      <th>atom_5</th>\n",
       "      <th>atom_6</th>\n",
       "      <th>atom_7</th>\n",
       "      <th>atom_8</th>\n",
       "      <th>atom_9</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>y_7</th>\n",
       "      <th>y_8</th>\n",
       "      <th>y_9</th>\n",
       "      <th>z_2</th>\n",
       "      <th>z_3</th>\n",
       "      <th>z_4</th>\n",
       "      <th>z_5</th>\n",
       "      <th>z_6</th>\n",
       "      <th>z_7</th>\n",
       "      <th>z_8</th>\n",
       "      <th>z_9</th>\n",
       "      <th>d_1_0</th>\n",
       "      <th>d_2_0</th>\n",
       "      <th>d_2_1</th>\n",
       "      <th>d_3_0</th>\n",
       "      <th>d_3_1</th>\n",
       "      <th>d_3_2</th>\n",
       "      <th>d_4_0</th>\n",
       "      <th>d_4_1</th>\n",
       "      <th>d_4_2</th>\n",
       "      <th>d_4_3</th>\n",
       "      <th>d_5_0</th>\n",
       "      <th>d_5_1</th>\n",
       "      <th>d_5_2</th>\n",
       "      <th>d_5_3</th>\n",
       "      <th>d_6_0</th>\n",
       "      <th>d_6_1</th>\n",
       "      <th>d_6_2</th>\n",
       "      <th>d_6_3</th>\n",
       "      <th>d_7_0</th>\n",
       "      <th>d_7_1</th>\n",
       "      <th>d_7_2</th>\n",
       "      <th>d_7_3</th>\n",
       "      <th>d_8_0</th>\n",
       "      <th>d_8_1</th>\n",
       "      <th>d_8_2</th>\n",
       "      <th>d_8_3</th>\n",
       "      <th>d_9_0</th>\n",
       "      <th>d_9_1</th>\n",
       "      <th>d_9_2</th>\n",
       "      <th>d_9_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.688900</td>\n",
       "      <td>0.017257</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>-0.027377</td>\n",
       "      <td>-0.040426</td>\n",
       "      <td>1.024108</td>\n",
       "      <td>0.062564</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>-0.520278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.358745</td>\n",
       "      <td>1.343532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.028758</td>\n",
       "      <td>-0.775543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.017190</td>\n",
       "      <td>1.618523</td>\n",
       "      <td>1.017187</td>\n",
       "      <td>1.618710</td>\n",
       "      <td>1.017208</td>\n",
       "      <td>1.618706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32.689098</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>1.358745</td>\n",
       "      <td>-0.028758</td>\n",
       "      <td>-0.040426</td>\n",
       "      <td>1.024108</td>\n",
       "      <td>0.062564</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017257</td>\n",
       "      <td>-0.520278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>1.343532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.027377</td>\n",
       "      <td>-0.775543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.017187</td>\n",
       "      <td>1.618523</td>\n",
       "      <td>1.017190</td>\n",
       "      <td>1.618706</td>\n",
       "      <td>1.017208</td>\n",
       "      <td>1.618710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.690498</td>\n",
       "      <td>-0.520278</td>\n",
       "      <td>1.343532</td>\n",
       "      <td>-0.775543</td>\n",
       "      <td>-0.040426</td>\n",
       "      <td>1.024108</td>\n",
       "      <td>0.062564</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.017257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.358745</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.028758</td>\n",
       "      <td>-0.027377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.017208</td>\n",
       "      <td>1.618706</td>\n",
       "      <td>1.017187</td>\n",
       "      <td>1.618710</td>\n",
       "      <td>1.017190</td>\n",
       "      <td>1.618523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>55.525200</td>\n",
       "      <td>0.825355</td>\n",
       "      <td>1.885049</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>-0.025900</td>\n",
       "      <td>1.346146</td>\n",
       "      <td>0.008894</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.908377</td>\n",
       "      <td>0.046467</td>\n",
       "      <td>1.071835</td>\n",
       "      <td>-0.961441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.826796</td>\n",
       "      <td>-0.011743</td>\n",
       "      <td>-0.652588</td>\n",
       "      <td>-0.475004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>-0.011133</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.007511</td>\n",
       "      <td>1.734777</td>\n",
       "      <td>1.004933</td>\n",
       "      <td>2.050487</td>\n",
       "      <td>1.359838</td>\n",
       "      <td>2.071779</td>\n",
       "      <td>2.549623</td>\n",
       "      <td>2.280430</td>\n",
       "      <td>3.173246</td>\n",
       "      <td>1.209220</td>\n",
       "      <td>2.960154</td>\n",
       "      <td>2.047394</td>\n",
       "      <td>2.302437</td>\n",
       "      <td>1.109295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>54.735901</td>\n",
       "      <td>-0.908377</td>\n",
       "      <td>1.826796</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>-0.025900</td>\n",
       "      <td>1.346146</td>\n",
       "      <td>0.008894</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.825355</td>\n",
       "      <td>0.046467</td>\n",
       "      <td>-0.961441</td>\n",
       "      <td>1.071835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.885049</td>\n",
       "      <td>-0.011743</td>\n",
       "      <td>-0.475004</td>\n",
       "      <td>-0.652588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>-0.011133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.004933</td>\n",
       "      <td>1.734777</td>\n",
       "      <td>1.007511</td>\n",
       "      <td>2.071779</td>\n",
       "      <td>1.359838</td>\n",
       "      <td>2.050487</td>\n",
       "      <td>2.302437</td>\n",
       "      <td>2.047394</td>\n",
       "      <td>2.960154</td>\n",
       "      <td>1.109295</td>\n",
       "      <td>3.173246</td>\n",
       "      <td>2.280430</td>\n",
       "      <td>2.549623</td>\n",
       "      <td>1.209220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  molecule_index  atom_index_0  atom_index_1  scalar_coupling_constant  \\\n",
       "0  10   2               1             0             32.688900                  \n",
       "1  13   2               2             0             32.689098                  \n",
       "2  15   2               3             0             32.690498                  \n",
       "3  97   12              3             0             55.525200                  \n",
       "4  101  12              4             0             54.735901                  \n",
       "\n",
       "        x_0       y_0       z_0       x_1       y_1       z_1  atom_2  atom_3  \\\n",
       "0  0.017257  0.012545 -0.027377 -0.040426  1.024108  0.062564  1       1        \n",
       "1  0.915789  1.358745 -0.028758 -0.040426  1.024108  0.062564  1       1        \n",
       "2 -0.520278  1.343532 -0.775543 -0.040426  1.024108  0.062564  1       1        \n",
       "3  0.825355  1.885049  0.003738 -0.025900  1.346146  0.008894  1       6        \n",
       "4 -0.908377  1.826796  0.018920 -0.025900  1.346146  0.008894  1       6        \n",
       "\n",
       "   atom_4  atom_5  atom_6  atom_7  atom_8  atom_9       x_2       x_3  \\\n",
       "0  0       0       0       0       0       0       0.915789 -0.520278   \n",
       "1  0       0       0       0       0       0       0.017257 -0.520278   \n",
       "2  0       0       0       0       0       0       0.915789  0.017257   \n",
       "3  8       1       0       0       0       0      -0.908377  0.046467   \n",
       "4  1       8       0       0       0       0       0.825355  0.046467   \n",
       "\n",
       "        x_4       x_5  x_6  x_7  x_8  x_9       y_2       y_3       y_4  \\\n",
       "0 NaN       NaN       NaN  NaN  NaN  NaN   1.358745  1.343532 NaN         \n",
       "1 NaN       NaN       NaN  NaN  NaN  NaN   0.012545  1.343532 NaN         \n",
       "2 NaN       NaN       NaN  NaN  NaN  NaN   1.358745  0.012545 NaN         \n",
       "3  1.071835 -0.961441 NaN  NaN  NaN  NaN   1.826796 -0.011743 -0.652588   \n",
       "4 -0.961441  1.071835 NaN  NaN  NaN  NaN   1.885049 -0.011743 -0.475004   \n",
       "\n",
       "        y_5  y_6  y_7  y_8  y_9       z_2       z_3       z_4       z_5  z_6  \\\n",
       "0 NaN       NaN  NaN  NaN  NaN  -0.028758 -0.775543 NaN       NaN       NaN    \n",
       "1 NaN       NaN  NaN  NaN  NaN  -0.027377 -0.775543 NaN       NaN       NaN    \n",
       "2 NaN       NaN  NaN  NaN  NaN  -0.028758 -0.027377 NaN       NaN       NaN    \n",
       "3 -0.475004 NaN  NaN  NaN  NaN   0.018920  0.001204 -0.011133  0.008074 NaN    \n",
       "4 -0.652588 NaN  NaN  NaN  NaN   0.003738  0.001204  0.008074 -0.011133 NaN    \n",
       "\n",
       "   z_7  z_8  z_9     d_1_0     d_2_0     d_2_1     d_3_0     d_3_1     d_3_2  \\\n",
       "0 NaN  NaN  NaN   1.017190  1.618523  1.017187  1.618710  1.017208  1.618706   \n",
       "1 NaN  NaN  NaN   1.017187  1.618523  1.017190  1.618706  1.017208  1.618710   \n",
       "2 NaN  NaN  NaN   1.017208  1.618706  1.017187  1.618710  1.017190  1.618523   \n",
       "3 NaN  NaN  NaN   1.007511  1.734777  1.004933  2.050487  1.359838  2.071779   \n",
       "4 NaN  NaN  NaN   1.004933  1.734777  1.007511  2.071779  1.359838  2.050487   \n",
       "\n",
       "      d_4_0     d_4_1     d_4_2     d_4_3     d_5_0     d_5_1     d_5_2  \\\n",
       "0 NaN       NaN       NaN       NaN       NaN       NaN       NaN         \n",
       "1 NaN       NaN       NaN       NaN       NaN       NaN       NaN         \n",
       "2 NaN       NaN       NaN       NaN       NaN       NaN       NaN         \n",
       "3  2.549623  2.280430  3.173246  1.209220  2.960154  2.047394  2.302437   \n",
       "4  2.302437  2.047394  2.960154  1.109295  3.173246  2.280430  2.549623   \n",
       "\n",
       "      d_5_3  d_6_0  d_6_1  d_6_2  d_6_3  d_7_0  d_7_1  d_7_2  d_7_3  d_8_0  \\\n",
       "0 NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN      \n",
       "1 NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN      \n",
       "2 NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN      \n",
       "3  1.109295 NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN      \n",
       "4  1.209220 NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN      \n",
       "\n",
       "   d_8_1  d_8_2  d_8_3  d_9_0  d_9_1  d_9_2  d_9_3  \n",
       "0 NaN    NaN    NaN    NaN    NaN    NaN    NaN     \n",
       "1 NaN    NaN    NaN    NaN    NaN    NaN    NaN     \n",
       "2 NaN    NaN    NaN    NaN    NaN    NaN    NaN     \n",
       "3 NaN    NaN    NaN    NaN    NaN    NaN    NaN     \n",
       "4 NaN    NaN    NaN    NaN    NaN    NaN    NaN     "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
       "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
       "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
       "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
       "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
       "       'scalar_coupling_constant'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = take_n_atoms(full, 10)\n",
    "# LightGBM performs better with 0-s then with NaN-s\n",
    "df = df.fillna(0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34690, 38), (8673, 38), (34690,), (8673,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = df.drop(['scalar_coupling_constant'], axis=1).values.astype('float32')\n",
    "y_data = df['scalar_coupling_constant'].values.astype('float32')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=128)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": 40,
>>>>>>> f38c5a3fada567d5fd5ef03c20ccba924f0bb423
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration params are copied from @artgor kernel:\n",
    "# https://www.kaggle.com/artgor/brute-force-feature-engineering\n",
    "LGB_PARAMS = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.2,\n",
    "    'num_leaves': 128,\n",
    "    'min_child_samples': 79,\n",
<<<<<<< HEAD
    "    'max_depth': 25,\n",
=======
    "    'max_depth': 15,\n",
>>>>>>> f38c5a3fada567d5fd5ef03c20ccba924f0bb423
    "    'subsample_freq': 1,\n",
    "    'subsample': 0.9,\n",
    "    'bagging_seed': 11,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.3,\n",
    "    'colsample_bytree': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_PARAMS_1JHN= {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.2,\n",
    "    'num_leaves': 64,\n",
    "    'min_child_samples': 79,\n",
    "    'max_depth': 12,\n",
    "    'subsample_freq': 1,\n",
    "    'subsample': 0.9,\n",
    "    'bagging_seed': 11,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.3,\n",
    "    'colsample_bytree': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
>>>>>>> f38c5a3fada567d5fd5ef03c20ccba924f0bb423
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
<<<<<<< HEAD
      "[100]\ttraining's l1: 0.283513\tvalid_1's l1: 0.445556\n",
      "[200]\ttraining's l1: 0.197698\tvalid_1's l1: 0.409865\n",
      "[300]\ttraining's l1: 0.151573\tvalid_1's l1: 0.39582\n",
      "[400]\ttraining's l1: 0.121348\tvalid_1's l1: 0.387725\n",
      "[500]\ttraining's l1: 0.100032\tvalid_1's l1: 0.382911\n",
      "[600]\ttraining's l1: 0.0840414\tvalid_1's l1: 0.379714\n",
      "[700]\ttraining's l1: 0.0718533\tvalid_1's l1: 0.377831\n",
      "[800]\ttraining's l1: 0.0621238\tvalid_1's l1: 0.37602\n",
      "[900]\ttraining's l1: 0.0542927\tvalid_1's l1: 0.374726\n",
      "[1000]\ttraining's l1: 0.0478482\tvalid_1's l1: 0.373658\n",
      "[1100]\ttraining's l1: 0.0425389\tvalid_1's l1: 0.372942\n",
      "[1200]\ttraining's l1: 0.0380256\tvalid_1's l1: 0.372286\n",
      "[1300]\ttraining's l1: 0.0341548\tvalid_1's l1: 0.371787\n",
      "[1400]\ttraining's l1: 0.030845\tvalid_1's l1: 0.371334\n",
      "[1500]\ttraining's l1: 0.0280127\tvalid_1's l1: 0.370867\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\ttraining's l1: 0.0280127\tvalid_1's l1: 0.370867\n"
=======
      "[100]\ttraining's l1: 0.373664\tvalid_1's l1: 0.48981\n",
      "[200]\ttraining's l1: 0.296557\tvalid_1's l1: 0.446742\n",
      "[300]\ttraining's l1: 0.247452\tvalid_1's l1: 0.424625\n",
      "[400]\ttraining's l1: 0.210984\tvalid_1's l1: 0.410619\n",
      "[500]\ttraining's l1: 0.183504\tvalid_1's l1: 0.400631\n",
      "[600]\ttraining's l1: 0.158901\tvalid_1's l1: 0.393269\n",
      "[700]\ttraining's l1: 0.139522\tvalid_1's l1: 0.387746\n",
      "[800]\ttraining's l1: 0.123854\tvalid_1's l1: 0.383704\n",
      "[900]\ttraining's l1: 0.11068\tvalid_1's l1: 0.380712\n",
      "[1000]\ttraining's l1: 0.099639\tvalid_1's l1: 0.378078\n",
      "[1100]\ttraining's l1: 0.0903025\tvalid_1's l1: 0.376126\n",
      "[1200]\ttraining's l1: 0.0820192\tvalid_1's l1: 0.37463\n",
      "[1300]\ttraining's l1: 0.0746408\tvalid_1's l1: 0.373125\n",
      "[1400]\ttraining's l1: 0.0684193\tvalid_1's l1: 0.371902\n",
      "[1500]\ttraining's l1: 0.0625234\tvalid_1's l1: 0.370788\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\ttraining's l1: 0.0625234\tvalid_1's l1: 0.370788\n"
>>>>>>> f38c5a3fada567d5fd5ef03c20ccba924f0bb423
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "-0.9919129918909441"
=======
       "-0.9921234999423947"
>>>>>>> f38c5a3fada567d5fd5ef03c20ccba924f0bb423
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor(**LGB_PARAMS, n_estimators=1500, n_jobs = -1)\n",
    "model.fit(X_train, y_train, \n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric='mae',\n",
    "        verbose=100, early_stopping_rounds=200)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "np.log(mean_absolute_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "image/png": "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\n",
=======
      "image/png": "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\n",
>>>>>>> f38c5a3fada567d5fd5ef03c20ccba924f0bb423
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = list(df.columns)\n",
    "cols.remove('scalar_coupling_constant')\n",
    "cols\n",
    "df_importance = pd.DataFrame({'feature': cols, 'importance': model.feature_importances_})\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=df_importance.sort_values('importance', ascending=False));"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_x_y_data(some_csv, coupling_type, n_atoms):\n",
    "    full = build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms=n_atoms)\n",
    "    \n",
    "    df = take_n_atoms(full, n_atoms)\n",
    "    df = df.fillna(0)\n",
    "    print(df.columns)\n",
    "    \n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        X_data = df.drop(['scalar_coupling_constant'], axis=1).values.astype('float32')\n",
    "        y_data = df['scalar_coupling_constant'].values.astype('float32')\n",
    "    else:\n",
    "        X_data = df.values.astype('float32')\n",
    "        y_data = None\n",
    "        \n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def make_nn(input_dim):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(64,input_dim=input_dim,activation='relu'))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    model.compile(optimizer='rmsprop',loss='mean_absolute_error',metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_for_one_coupling_type(coupling_type, submission, n_atoms, n_folds=5, n_splits=5, random_state=128):\n",
    "    print(f'*** Training Model for {coupling_type} ***')\n",
    "    \n",
    "    X_data, y_data = build_x_y_data(train_csv, coupling_type, n_atoms)\n",
    "    X_test, _ = build_x_y_data(test_csv, coupling_type, n_atoms)\n",
    "    y_pred = np.zeros(X_test.shape[0], dtype='float32')\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc=StandardScaler()\n",
    "    X_data=sc.fit_transform(X_data)\n",
    "    X_test=sc.transform(X_test)\n",
    "    \n",
    "    cv_score = 0\n",
    "    \n",
    "    if n_folds > n_splits:\n",
    "        n_splits = n_folds\n",
    "    \n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X_data, y_data)):\n",
    "        if fold >= n_folds:\n",
    "            break\n",
    "\n",
    "        X_train, X_val = X_data[train_index], X_data[val_index]\n",
    "        y_train, y_val = y_data[train_index], y_data[val_index]\n",
    "        \n",
    "        #if coupling_type=='1JHN':\n",
    "        #    model = LGBMRegressor(**LGB_PARAMS_1JHN, n_estimators=1500, n_jobs = -1)\n",
    "        #else:\n",
    "        #    model = LGBMRegressor(**LGB_PARAMS, n_estimators=1500, n_jobs = -1)\n",
    "        #model.fit(X_train, y_train, \n",
    "        #    eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric='mae',\n",
    "        #    verbose=100, early_stopping_rounds=200)\n",
    "        \n",
    "        model=make_nn(X_train.shape[1])\n",
    "        model.fit(X_train,y_train,epochs=50,batch_size=128,validation_data=[X_val,y_val])\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        val_score = np.log(mean_absolute_error(y_val, y_val_pred))\n",
    "        print(f'{coupling_type} Fold {fold}, logMAE: {val_score}')\n",
    "        \n",
    "        cv_score += val_score / n_folds\n",
    "        pred=model.predict(X_test)\n",
    "        pred=pred.reshape(X_test.shape[0],)\n",
    "        print(y_pred.shape)\n",
    "        y_pred += pred / n_folds\n",
    "        print(cv_score)\n",
    "        \n",
    "        \n",
    "    submission.loc[test_csv['type'] == coupling_type, 'scalar_coupling_constant'] = y_pred\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training Model for 1JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'd_1_0', 'd_2_0',\n",
      "       'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1', 'd_4_2', 'd_4_3',\n",
      "       'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1', 'd_6_2', 'd_6_3',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'd_1_0', 'd_2_0',\n",
      "       'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1', 'd_4_2', 'd_4_3',\n",
      "       'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1', 'd_6_2', 'd_6_3'],\n",
      "      dtype='object')\n",
      "Train on 34690 samples, validate on 8673 samples\n",
      "Epoch 1/50\n",
      "34690/34690 [==============================] - 1s 18us/step - loss: 23.7609 - mean_absolute_error: 23.7609 - val_loss: 4.4902 - val_mean_absolute_error: 4.4902\n",
      "Epoch 2/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 2.5375 - mean_absolute_error: 2.5375 - val_loss: 1.9637 - val_mean_absolute_error: 1.9637\n",
      "Epoch 3/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.6181 - mean_absolute_error: 1.6181 - val_loss: 1.5631 - val_mean_absolute_error: 1.5631\n",
      "Epoch 4/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.3969 - mean_absolute_error: 1.3969 - val_loss: 1.6993 - val_mean_absolute_error: 1.6993\n",
      "Epoch 5/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.2899 - mean_absolute_error: 1.2899 - val_loss: 1.5234 - val_mean_absolute_error: 1.5234\n",
      "Epoch 6/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.2252 - mean_absolute_error: 1.2252 - val_loss: 1.4686 - val_mean_absolute_error: 1.4686\n",
      "Epoch 7/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.1751 - mean_absolute_error: 1.1751 - val_loss: 1.4231 - val_mean_absolute_error: 1.4231\n",
      "Epoch 8/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.1341 - mean_absolute_error: 1.1341 - val_loss: 1.2857 - val_mean_absolute_error: 1.2857\n",
      "Epoch 9/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.0961 - mean_absolute_error: 1.0961 - val_loss: 1.6725 - val_mean_absolute_error: 1.6725\n",
      "Epoch 10/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.0679 - mean_absolute_error: 1.0679 - val_loss: 1.3088 - val_mean_absolute_error: 1.3088\n",
      "Epoch 11/50\n",
      "34690/34690 [==============================] - 0s 13us/step - loss: 1.0427 - mean_absolute_error: 1.0427 - val_loss: 1.1522 - val_mean_absolute_error: 1.1522\n",
      "Epoch 12/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.0221 - mean_absolute_error: 1.0221 - val_loss: 1.3397 - val_mean_absolute_error: 1.3397\n",
      "Epoch 13/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.0018 - mean_absolute_error: 1.0018 - val_loss: 1.3013 - val_mean_absolute_error: 1.3013\n",
      "Epoch 14/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9872 - mean_absolute_error: 0.9872 - val_loss: 1.1040 - val_mean_absolute_error: 1.1040\n",
      "Epoch 15/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9699 - mean_absolute_error: 0.9699 - val_loss: 1.4881 - val_mean_absolute_error: 1.4881\n",
      "Epoch 16/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9611 - mean_absolute_error: 0.9611 - val_loss: 1.4439 - val_mean_absolute_error: 1.4439\n",
      "Epoch 17/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.9458 - mean_absolute_error: 0.9458 - val_loss: 1.0842 - val_mean_absolute_error: 1.0842\n",
      "Epoch 18/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9357 - mean_absolute_error: 0.9357 - val_loss: 1.2713 - val_mean_absolute_error: 1.2713\n",
      "Epoch 19/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9243 - mean_absolute_error: 0.9243 - val_loss: 1.2753 - val_mean_absolute_error: 1.2753\n",
      "Epoch 20/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9176 - mean_absolute_error: 0.9176 - val_loss: 1.2231 - val_mean_absolute_error: 1.2231\n",
      "Epoch 21/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9109 - mean_absolute_error: 0.9109 - val_loss: 1.2500 - val_mean_absolute_error: 1.2500\n",
      "Epoch 22/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9032 - mean_absolute_error: 0.9032 - val_loss: 1.3534 - val_mean_absolute_error: 1.3534\n",
      "Epoch 23/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8992 - mean_absolute_error: 0.8992 - val_loss: 1.1324 - val_mean_absolute_error: 1.1324\n",
      "Epoch 24/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8941 - mean_absolute_error: 0.8941 - val_loss: 1.1429 - val_mean_absolute_error: 1.1429\n",
      "Epoch 25/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8876 - mean_absolute_error: 0.8876 - val_loss: 1.2436 - val_mean_absolute_error: 1.2436\n",
      "Epoch 26/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8786 - mean_absolute_error: 0.8786 - val_loss: 1.3461 - val_mean_absolute_error: 1.3461\n",
      "Epoch 27/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8734 - mean_absolute_error: 0.8734 - val_loss: 1.2737 - val_mean_absolute_error: 1.2737\n",
      "Epoch 28/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8693 - mean_absolute_error: 0.8693 - val_loss: 1.4898 - val_mean_absolute_error: 1.4898\n",
      "Epoch 29/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8644 - mean_absolute_error: 0.8644 - val_loss: 1.1952 - val_mean_absolute_error: 1.1952\n",
      "Epoch 30/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8599 - mean_absolute_error: 0.8599 - val_loss: 0.8829 - val_mean_absolute_error: 0.8829\n",
      "Epoch 31/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8567 - mean_absolute_error: 0.8567 - val_loss: 0.9712 - val_mean_absolute_error: 0.9712\n",
      "Epoch 32/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8513 - mean_absolute_error: 0.8513 - val_loss: 0.9918 - val_mean_absolute_error: 0.9918\n",
      "Epoch 33/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8463 - mean_absolute_error: 0.8463 - val_loss: 1.3097 - val_mean_absolute_error: 1.3097\n",
      "Epoch 34/50\n",
      "34690/34690 [==============================] - 0s 13us/step - loss: 0.8444 - mean_absolute_error: 0.8444 - val_loss: 1.1421 - val_mean_absolute_error: 1.1421\n",
      "Epoch 35/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8378 - mean_absolute_error: 0.8378 - val_loss: 1.3075 - val_mean_absolute_error: 1.3075\n",
      "Epoch 36/50\n",
      "34690/34690 [==============================] - 0s 13us/step - loss: 0.8352 - mean_absolute_error: 0.8352 - val_loss: 1.1354 - val_mean_absolute_error: 1.1354\n",
      "Epoch 37/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8312 - mean_absolute_error: 0.8312 - val_loss: 1.1828 - val_mean_absolute_error: 1.1828\n",
      "Epoch 38/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8295 - mean_absolute_error: 0.8295 - val_loss: 1.7330 - val_mean_absolute_error: 1.7330\n",
      "Epoch 39/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8243 - mean_absolute_error: 0.8243 - val_loss: 1.4858 - val_mean_absolute_error: 1.4858\n",
      "Epoch 40/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8262 - mean_absolute_error: 0.8262 - val_loss: 1.4001 - val_mean_absolute_error: 1.4001\n",
      "Epoch 41/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8212 - mean_absolute_error: 0.8212 - val_loss: 0.9035 - val_mean_absolute_error: 0.9035\n",
      "Epoch 42/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8176 - mean_absolute_error: 0.8176 - val_loss: 1.0942 - val_mean_absolute_error: 1.0942\n",
      "Epoch 43/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8155 - mean_absolute_error: 0.8155 - val_loss: 1.1817 - val_mean_absolute_error: 1.1817\n",
      "Epoch 44/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8114 - mean_absolute_error: 0.8114 - val_loss: 1.0344 - val_mean_absolute_error: 1.0344\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8078 - mean_absolute_error: 0.8078 - val_loss: 1.2088 - val_mean_absolute_error: 1.2088\n",
      "Epoch 46/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8042 - mean_absolute_error: 0.8042 - val_loss: 1.3857 - val_mean_absolute_error: 1.3857\n",
      "Epoch 47/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8080 - mean_absolute_error: 0.8080 - val_loss: 1.0109 - val_mean_absolute_error: 1.0109\n",
      "Epoch 48/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8017 - mean_absolute_error: 0.8017 - val_loss: 1.3016 - val_mean_absolute_error: 1.3016\n",
      "Epoch 49/50\n",
      "34690/34690 [==============================] - 0s 10us/step - loss: 0.7999 - mean_absolute_error: 0.7999 - val_loss: 1.5651 - val_mean_absolute_error: 1.5651\n",
      "Epoch 50/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.7986 - mean_absolute_error: 0.7986 - val_loss: 1.1547 - val_mean_absolute_error: 1.1547\n",
      "1JHN Fold 0, logMAE: 0.14386363327503204\n",
      "(24195,)\n",
      "0.04795454442501068\n",
      "Train on 34690 samples, validate on 8673 samples\n",
      "Epoch 1/50\n",
      "34690/34690 [==============================] - 1s 19us/step - loss: 17.9125 - mean_absolute_error: 17.9125 - val_loss: 2.9808 - val_mean_absolute_error: 2.9808\n",
      "Epoch 2/50\n",
      "34690/34690 [==============================] - 0s 13us/step - loss: 2.1427 - mean_absolute_error: 2.1427 - val_loss: 2.0264 - val_mean_absolute_error: 2.0264\n",
      "Epoch 3/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 1.5700 - mean_absolute_error: 1.5700 - val_loss: 1.5098 - val_mean_absolute_error: 1.5098\n",
      "Epoch 4/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 1.3764 - mean_absolute_error: 1.3764 - val_loss: 1.5807 - val_mean_absolute_error: 1.5807\n",
      "Epoch 5/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 1.2835 - mean_absolute_error: 1.2835 - val_loss: 1.5640 - val_mean_absolute_error: 1.5640\n",
      "Epoch 6/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.2105 - mean_absolute_error: 1.2105 - val_loss: 1.2623 - val_mean_absolute_error: 1.2623\n",
      "Epoch 7/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 1.1547 - mean_absolute_error: 1.1547 - val_loss: 1.2636 - val_mean_absolute_error: 1.2636\n",
      "Epoch 8/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.1096 - mean_absolute_error: 1.1096 - val_loss: 1.2944 - val_mean_absolute_error: 1.2944\n",
      "Epoch 9/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 1.0702 - mean_absolute_error: 1.0702 - val_loss: 1.1732 - val_mean_absolute_error: 1.1732\n",
      "Epoch 10/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 1.0432 - mean_absolute_error: 1.0432 - val_loss: 1.4327 - val_mean_absolute_error: 1.4327\n",
      "Epoch 11/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.0202 - mean_absolute_error: 1.0202 - val_loss: 1.1207 - val_mean_absolute_error: 1.1207\n",
      "Epoch 12/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9976 - mean_absolute_error: 0.9976 - val_loss: 1.3283 - val_mean_absolute_error: 1.3283\n",
      "Epoch 13/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9840 - mean_absolute_error: 0.9840 - val_loss: 1.3325 - val_mean_absolute_error: 1.3325\n",
      "Epoch 14/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9602 - mean_absolute_error: 0.9602 - val_loss: 1.0447 - val_mean_absolute_error: 1.0447\n",
      "Epoch 15/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9480 - mean_absolute_error: 0.9480 - val_loss: 1.1773 - val_mean_absolute_error: 1.1773\n",
      "Epoch 16/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9362 - mean_absolute_error: 0.9362 - val_loss: 1.5041 - val_mean_absolute_error: 1.5041\n",
      "Epoch 17/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9233 - mean_absolute_error: 0.9233 - val_loss: 1.5677 - val_mean_absolute_error: 1.5677\n",
      "Epoch 18/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9158 - mean_absolute_error: 0.9158 - val_loss: 1.1974 - val_mean_absolute_error: 1.1974\n",
      "Epoch 19/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9027 - mean_absolute_error: 0.9027 - val_loss: 1.1836 - val_mean_absolute_error: 1.1836\n",
      "Epoch 20/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8967 - mean_absolute_error: 0.8967 - val_loss: 0.9503 - val_mean_absolute_error: 0.9503\n",
      "Epoch 21/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8869 - mean_absolute_error: 0.8869 - val_loss: 1.1622 - val_mean_absolute_error: 1.1622\n",
      "Epoch 22/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8814 - mean_absolute_error: 0.8814 - val_loss: 0.9498 - val_mean_absolute_error: 0.9498\n",
      "Epoch 23/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8707 - mean_absolute_error: 0.8707 - val_loss: 1.7013 - val_mean_absolute_error: 1.7013\n",
      "Epoch 24/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8663 - mean_absolute_error: 0.8663 - val_loss: 1.2870 - val_mean_absolute_error: 1.2870\n",
      "Epoch 25/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8634 - mean_absolute_error: 0.8634 - val_loss: 1.0532 - val_mean_absolute_error: 1.0532\n",
      "Epoch 26/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8552 - mean_absolute_error: 0.8552 - val_loss: 1.5722 - val_mean_absolute_error: 1.5722\n",
      "Epoch 27/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8514 - mean_absolute_error: 0.8514 - val_loss: 1.0202 - val_mean_absolute_error: 1.0202\n",
      "Epoch 28/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8449 - mean_absolute_error: 0.8449 - val_loss: 1.1376 - val_mean_absolute_error: 1.1376\n",
      "Epoch 29/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8423 - mean_absolute_error: 0.8423 - val_loss: 1.2958 - val_mean_absolute_error: 1.2958\n",
      "Epoch 30/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8339 - mean_absolute_error: 0.8339 - val_loss: 1.1805 - val_mean_absolute_error: 1.1805\n",
      "Epoch 31/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8352 - mean_absolute_error: 0.8352 - val_loss: 1.2629 - val_mean_absolute_error: 1.2629\n",
      "Epoch 32/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8271 - mean_absolute_error: 0.8271 - val_loss: 0.8441 - val_mean_absolute_error: 0.8441\n",
      "Epoch 33/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8248 - mean_absolute_error: 0.8248 - val_loss: 1.1802 - val_mean_absolute_error: 1.1802\n",
      "Epoch 34/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8184 - mean_absolute_error: 0.8184 - val_loss: 1.2785 - val_mean_absolute_error: 1.2785\n",
      "Epoch 35/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8184 - mean_absolute_error: 0.8184 - val_loss: 1.4167 - val_mean_absolute_error: 1.4167\n",
      "Epoch 36/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8136 - mean_absolute_error: 0.8136 - val_loss: 1.2737 - val_mean_absolute_error: 1.2737\n",
      "Epoch 37/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8123 - mean_absolute_error: 0.8123 - val_loss: 0.8619 - val_mean_absolute_error: 0.8619\n",
      "Epoch 38/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8049 - mean_absolute_error: 0.8049 - val_loss: 0.9106 - val_mean_absolute_error: 0.9106\n",
      "Epoch 39/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8063 - mean_absolute_error: 0.8063 - val_loss: 0.8721 - val_mean_absolute_error: 0.8721\n",
      "Epoch 40/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.7997 - mean_absolute_error: 0.7997 - val_loss: 1.1983 - val_mean_absolute_error: 1.1983\n",
      "Epoch 41/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.7974 - mean_absolute_error: 0.7974 - val_loss: 1.3130 - val_mean_absolute_error: 1.3130\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.7956 - mean_absolute_error: 0.7956 - val_loss: 1.1607 - val_mean_absolute_error: 1.1607\n",
      "Epoch 43/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.7917 - mean_absolute_error: 0.7917 - val_loss: 1.4984 - val_mean_absolute_error: 1.4984\n",
      "Epoch 44/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.7910 - mean_absolute_error: 0.7910 - val_loss: 1.1863 - val_mean_absolute_error: 1.1863\n",
      "Epoch 45/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.7884 - mean_absolute_error: 0.7884 - val_loss: 0.9977 - val_mean_absolute_error: 0.9977\n",
      "Epoch 46/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.7802 - mean_absolute_error: 0.7802 - val_loss: 1.3543 - val_mean_absolute_error: 1.3543\n",
      "Epoch 47/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.7864 - mean_absolute_error: 0.7864 - val_loss: 1.6040 - val_mean_absolute_error: 1.6040\n",
      "Epoch 48/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.7850 - mean_absolute_error: 0.7850 - val_loss: 1.2382 - val_mean_absolute_error: 1.2382\n",
      "Epoch 49/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.7822 - mean_absolute_error: 0.7822 - val_loss: 1.0636 - val_mean_absolute_error: 1.0636\n",
      "Epoch 50/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.7796 - mean_absolute_error: 0.7796 - val_loss: 1.1591 - val_mean_absolute_error: 1.1591\n",
      "1JHN Fold 1, logMAE: 0.1476697027683258\n",
      "(24195,)\n",
      "0.09717777868111929\n",
      "Train on 34690 samples, validate on 8673 samples\n",
      "Epoch 1/50\n",
      "34690/34690 [==============================] - 1s 20us/step - loss: 15.5454 - mean_absolute_error: 15.5454 - val_loss: 2.6056 - val_mean_absolute_error: 2.6056\n",
      "Epoch 2/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.7885 - mean_absolute_error: 1.7885 - val_loss: 1.7801 - val_mean_absolute_error: 1.7801\n",
      "Epoch 3/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.4420 - mean_absolute_error: 1.4420 - val_loss: 1.5778 - val_mean_absolute_error: 1.5778\n",
      "Epoch 4/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 1.3133 - mean_absolute_error: 1.3133 - val_loss: 1.2690 - val_mean_absolute_error: 1.2690\n",
      "Epoch 5/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.2359 - mean_absolute_error: 1.2359 - val_loss: 1.5813 - val_mean_absolute_error: 1.5813\n",
      "Epoch 6/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.1800 - mean_absolute_error: 1.1800 - val_loss: 1.1855 - val_mean_absolute_error: 1.1855\n",
      "Epoch 7/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.1315 - mean_absolute_error: 1.1315 - val_loss: 1.5793 - val_mean_absolute_error: 1.5793\n",
      "Epoch 8/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.0947 - mean_absolute_error: 1.0947 - val_loss: 1.4000 - val_mean_absolute_error: 1.4000\n",
      "Epoch 9/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.0636 - mean_absolute_error: 1.0636 - val_loss: 1.2240 - val_mean_absolute_error: 1.2240\n",
      "Epoch 10/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.0361 - mean_absolute_error: 1.0361 - val_loss: 1.5221 - val_mean_absolute_error: 1.5221\n",
      "Epoch 11/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 1.0127 - mean_absolute_error: 1.0127 - val_loss: 1.4862 - val_mean_absolute_error: 1.4862\n",
      "Epoch 12/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9908 - mean_absolute_error: 0.9908 - val_loss: 1.2152 - val_mean_absolute_error: 1.2152\n",
      "Epoch 13/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9757 - mean_absolute_error: 0.9757 - val_loss: 1.3470 - val_mean_absolute_error: 1.3470\n",
      "Epoch 14/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9608 - mean_absolute_error: 0.9608 - val_loss: 1.7450 - val_mean_absolute_error: 1.7450\n",
      "Epoch 15/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9445 - mean_absolute_error: 0.9445 - val_loss: 0.9567 - val_mean_absolute_error: 0.9567\n",
      "Epoch 16/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9315 - mean_absolute_error: 0.9315 - val_loss: 1.3556 - val_mean_absolute_error: 1.3556\n",
      "Epoch 17/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9201 - mean_absolute_error: 0.9201 - val_loss: 1.0196 - val_mean_absolute_error: 1.0196\n",
      "Epoch 18/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9129 - mean_absolute_error: 0.9129 - val_loss: 0.9277 - val_mean_absolute_error: 0.9277\n",
      "Epoch 19/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.9021 - mean_absolute_error: 0.9021 - val_loss: 1.4747 - val_mean_absolute_error: 1.4747\n",
      "Epoch 20/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8988 - mean_absolute_error: 0.8988 - val_loss: 0.9690 - val_mean_absolute_error: 0.9690\n",
      "Epoch 21/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8849 - mean_absolute_error: 0.8849 - val_loss: 1.2026 - val_mean_absolute_error: 1.2026\n",
      "Epoch 22/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8785 - mean_absolute_error: 0.8785 - val_loss: 1.3471 - val_mean_absolute_error: 1.3471\n",
      "Epoch 23/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8758 - mean_absolute_error: 0.8758 - val_loss: 1.2478 - val_mean_absolute_error: 1.2478\n",
      "Epoch 24/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8665 - mean_absolute_error: 0.8665 - val_loss: 0.9554 - val_mean_absolute_error: 0.9554\n",
      "Epoch 25/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8614 - mean_absolute_error: 0.8614 - val_loss: 1.2688 - val_mean_absolute_error: 1.2688\n",
      "Epoch 26/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8606 - mean_absolute_error: 0.8606 - val_loss: 1.2983 - val_mean_absolute_error: 1.2983\n",
      "Epoch 27/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8514 - mean_absolute_error: 0.8514 - val_loss: 1.5695 - val_mean_absolute_error: 1.5695\n",
      "Epoch 28/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8495 - mean_absolute_error: 0.8495 - val_loss: 0.9457 - val_mean_absolute_error: 0.9457\n",
      "Epoch 29/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8442 - mean_absolute_error: 0.8442 - val_loss: 1.3617 - val_mean_absolute_error: 1.3617\n",
      "Epoch 30/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8401 - mean_absolute_error: 0.8401 - val_loss: 1.1736 - val_mean_absolute_error: 1.1736\n",
      "Epoch 31/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8401 - mean_absolute_error: 0.8401 - val_loss: 1.2101 - val_mean_absolute_error: 1.2101\n",
      "Epoch 32/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8349 - mean_absolute_error: 0.8349 - val_loss: 1.0459 - val_mean_absolute_error: 1.0459\n",
      "Epoch 33/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8321 - mean_absolute_error: 0.8321 - val_loss: 1.4400 - val_mean_absolute_error: 1.4400\n",
      "Epoch 34/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8255 - mean_absolute_error: 0.8255 - val_loss: 1.4460 - val_mean_absolute_error: 1.4460\n",
      "Epoch 35/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8242 - mean_absolute_error: 0.8242 - val_loss: 1.1816 - val_mean_absolute_error: 1.1816\n",
      "Epoch 36/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8202 - mean_absolute_error: 0.8202 - val_loss: 0.9612 - val_mean_absolute_error: 0.9612\n",
      "Epoch 37/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8211 - mean_absolute_error: 0.8211 - val_loss: 0.9947 - val_mean_absolute_error: 0.9947\n",
      "Epoch 38/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8122 - mean_absolute_error: 0.8122 - val_loss: 0.9972 - val_mean_absolute_error: 0.9972\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8112 - mean_absolute_error: 0.8112 - val_loss: 0.9199 - val_mean_absolute_error: 0.9199\n",
      "Epoch 40/50\n",
      "34690/34690 [==============================] - 0s 12us/step - loss: 0.8104 - mean_absolute_error: 0.8104 - val_loss: 1.2279 - val_mean_absolute_error: 1.2279\n",
      "Epoch 41/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8065 - mean_absolute_error: 0.8065 - val_loss: 1.3752 - val_mean_absolute_error: 1.3752\n",
      "Epoch 42/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8049 - mean_absolute_error: 0.8049 - val_loss: 1.1116 - val_mean_absolute_error: 1.1116\n",
      "Epoch 43/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.8060 - mean_absolute_error: 0.8060 - val_loss: 0.8663 - val_mean_absolute_error: 0.8663\n",
      "Epoch 44/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.7987 - mean_absolute_error: 0.7987 - val_loss: 1.2377 - val_mean_absolute_error: 1.2377\n",
      "Epoch 45/50\n",
      "34690/34690 [==============================] - 0s 13us/step - loss: 0.7998 - mean_absolute_error: 0.7998 - val_loss: 0.8988 - val_mean_absolute_error: 0.8988\n",
      "Epoch 46/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.7941 - mean_absolute_error: 0.7941 - val_loss: 1.0646 - val_mean_absolute_error: 1.0646\n",
      "Epoch 47/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.7972 - mean_absolute_error: 0.7972 - val_loss: 0.9962 - val_mean_absolute_error: 0.9962\n",
      "Epoch 48/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.7949 - mean_absolute_error: 0.7949 - val_loss: 0.9977 - val_mean_absolute_error: 0.9977\n",
      "Epoch 49/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.7906 - mean_absolute_error: 0.7906 - val_loss: 1.2418 - val_mean_absolute_error: 1.2418\n",
      "Epoch 50/50\n",
      "34690/34690 [==============================] - 0s 11us/step - loss: 0.7927 - mean_absolute_error: 0.7927 - val_loss: 0.9670 - val_mean_absolute_error: 0.9670\n",
      "1JHN Fold 2, logMAE: -0.033529654145240784\n",
      "(24195,)\n",
      "0.08600122729937236\n",
      "*** Training Model for 1JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3'],\n",
      "      dtype='object')\n",
      "Train on 567532 samples, validate on 141884 samples\n",
      "Epoch 1/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 6.1079 - mean_absolute_error: 6.1079 - val_loss: 2.5029 - val_mean_absolute_error: 2.5029\n",
      "Epoch 2/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 2.3214 - mean_absolute_error: 2.3214 - val_loss: 2.2332 - val_mean_absolute_error: 2.2332\n",
      "Epoch 3/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 2.1717 - mean_absolute_error: 2.1717 - val_loss: 2.0850 - val_mean_absolute_error: 2.0850\n",
      "Epoch 4/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 2.0869 - mean_absolute_error: 2.0869 - val_loss: 2.1216 - val_mean_absolute_error: 2.1216\n",
      "Epoch 5/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 2.0301 - mean_absolute_error: 2.0301 - val_loss: 1.9632 - val_mean_absolute_error: 1.9632\n",
      "Epoch 6/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.9863 - mean_absolute_error: 1.9863 - val_loss: 1.9689 - val_mean_absolute_error: 1.9689\n",
      "Epoch 7/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.9490 - mean_absolute_error: 1.9490 - val_loss: 1.9405 - val_mean_absolute_error: 1.9405\n",
      "Epoch 8/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.9171 - mean_absolute_error: 1.9171 - val_loss: 1.8621 - val_mean_absolute_error: 1.8621\n",
      "Epoch 9/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.8912 - mean_absolute_error: 1.8912 - val_loss: 1.8648 - val_mean_absolute_error: 1.8648\n",
      "Epoch 10/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.8714 - mean_absolute_error: 1.8714 - val_loss: 2.0635 - val_mean_absolute_error: 2.0635\n",
      "Epoch 11/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.8514 - mean_absolute_error: 1.8514 - val_loss: 1.8746 - val_mean_absolute_error: 1.8746\n",
      "Epoch 12/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.8343 - mean_absolute_error: 1.8343 - val_loss: 1.8254 - val_mean_absolute_error: 1.8254\n",
      "Epoch 13/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.8191 - mean_absolute_error: 1.8191 - val_loss: 1.8081 - val_mean_absolute_error: 1.8081\n",
      "Epoch 14/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.8058 - mean_absolute_error: 1.8058 - val_loss: 1.8650 - val_mean_absolute_error: 1.8650\n",
      "Epoch 15/50\n",
      "567532/567532 [==============================] - 7s 11us/step - loss: 1.7944 - mean_absolute_error: 1.7944 - val_loss: 1.7319 - val_mean_absolute_error: 1.7319\n",
      "Epoch 16/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.7854 - mean_absolute_error: 1.7854 - val_loss: 1.7471 - val_mean_absolute_error: 1.7471\n",
      "Epoch 17/50\n",
      "567532/567532 [==============================] - 7s 12us/step - loss: 1.7758 - mean_absolute_error: 1.7758 - val_loss: 1.8189 - val_mean_absolute_error: 1.8189\n",
      "Epoch 18/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.7674 - mean_absolute_error: 1.7674 - val_loss: 1.8047 - val_mean_absolute_error: 1.8047\n",
      "Epoch 19/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.7604 - mean_absolute_error: 1.7604 - val_loss: 1.9995 - val_mean_absolute_error: 1.9995\n",
      "Epoch 20/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.7533 - mean_absolute_error: 1.7533 - val_loss: 1.7976 - val_mean_absolute_error: 1.7976\n",
      "Epoch 21/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.7467 - mean_absolute_error: 1.7467 - val_loss: 1.7809 - val_mean_absolute_error: 1.7809\n",
      "Epoch 22/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.7399 - mean_absolute_error: 1.7399 - val_loss: 1.7714 - val_mean_absolute_error: 1.7714\n",
      "Epoch 23/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.7344 - mean_absolute_error: 1.7344 - val_loss: 1.7184 - val_mean_absolute_error: 1.7184\n",
      "Epoch 24/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.7268 - mean_absolute_error: 1.7268 - val_loss: 1.7538 - val_mean_absolute_error: 1.7538\n",
      "Epoch 25/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.7199 - mean_absolute_error: 1.7199 - val_loss: 1.6791 - val_mean_absolute_error: 1.6791\n",
      "Epoch 26/50\n",
      "567532/567532 [==============================] - 7s 12us/step - loss: 1.7146 - mean_absolute_error: 1.7146 - val_loss: 1.7447 - val_mean_absolute_error: 1.7447\n",
      "Epoch 27/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.7094 - mean_absolute_error: 1.7094 - val_loss: 1.6881 - val_mean_absolute_error: 1.6881\n",
      "Epoch 28/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.7069 - mean_absolute_error: 1.7069 - val_loss: 1.6861 - val_mean_absolute_error: 1.6861\n",
      "Epoch 29/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.7022 - mean_absolute_error: 1.7022 - val_loss: 1.7648 - val_mean_absolute_error: 1.7648\n",
      "Epoch 30/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.6979 - mean_absolute_error: 1.6979 - val_loss: 1.7266 - val_mean_absolute_error: 1.7266\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567532/567532 [==============================] - 7s 12us/step - loss: 1.6939 - mean_absolute_error: 1.6939 - val_loss: 1.7493 - val_mean_absolute_error: 1.7493\n",
      "Epoch 32/50\n",
      "567532/567532 [==============================] - 7s 12us/step - loss: 1.6902 - mean_absolute_error: 1.6902 - val_loss: 1.7163 - val_mean_absolute_error: 1.7163\n",
      "Epoch 33/50\n",
      "567532/567532 [==============================] - 7s 11us/step - loss: 1.6874 - mean_absolute_error: 1.6874 - val_loss: 1.6844 - val_mean_absolute_error: 1.6844\n",
      "Epoch 34/50\n",
      "567532/567532 [==============================] - 7s 12us/step - loss: 1.6840 - mean_absolute_error: 1.6840 - val_loss: 1.6701 - val_mean_absolute_error: 1.6701\n",
      "Epoch 35/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.6811 - mean_absolute_error: 1.6811 - val_loss: 1.8204 - val_mean_absolute_error: 1.8204\n",
      "Epoch 36/50\n",
      "567532/567532 [==============================] - 7s 12us/step - loss: 1.6764 - mean_absolute_error: 1.6764 - val_loss: 1.7460 - val_mean_absolute_error: 1.7460\n",
      "Epoch 37/50\n",
      "567532/567532 [==============================] - 7s 12us/step - loss: 1.6730 - mean_absolute_error: 1.6730 - val_loss: 1.6407 - val_mean_absolute_error: 1.6407\n",
      "Epoch 38/50\n",
      "567532/567532 [==============================] - 7s 12us/step - loss: 1.6712 - mean_absolute_error: 1.6712 - val_loss: 1.6922 - val_mean_absolute_error: 1.6922\n",
      "Epoch 39/50\n",
      "567532/567532 [==============================] - 7s 11us/step - loss: 1.6674 - mean_absolute_error: 1.6674 - val_loss: 1.7274 - val_mean_absolute_error: 1.7274\n",
      "Epoch 40/50\n",
      "567532/567532 [==============================] - 7s 12us/step - loss: 1.6656 - mean_absolute_error: 1.6656 - val_loss: 1.6476 - val_mean_absolute_error: 1.6476\n",
      "Epoch 41/50\n",
      "567532/567532 [==============================] - 7s 12us/step - loss: 1.6621 - mean_absolute_error: 1.6621 - val_loss: 1.7963 - val_mean_absolute_error: 1.7963\n",
      "Epoch 42/50\n",
      "567532/567532 [==============================] - 7s 12us/step - loss: 1.6591 - mean_absolute_error: 1.6591 - val_loss: 1.6986 - val_mean_absolute_error: 1.6986\n",
      "Epoch 43/50\n",
      "567532/567532 [==============================] - 7s 12us/step - loss: 1.6540 - mean_absolute_error: 1.6540 - val_loss: 1.7131 - val_mean_absolute_error: 1.7131\n",
      "Epoch 44/50\n",
      "567532/567532 [==============================] - 7s 13us/step - loss: 1.6524 - mean_absolute_error: 1.6524 - val_loss: 1.5980 - val_mean_absolute_error: 1.5980\n",
      "Epoch 45/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.6504 - mean_absolute_error: 1.6504 - val_loss: 1.6112 - val_mean_absolute_error: 1.6112\n",
      "Epoch 46/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.6459 - mean_absolute_error: 1.6459 - val_loss: 1.8354 - val_mean_absolute_error: 1.8354\n",
      "Epoch 47/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.6436 - mean_absolute_error: 1.6436 - val_loss: 1.6705 - val_mean_absolute_error: 1.6705\n",
      "Epoch 48/50\n",
      "567532/567532 [==============================] - 7s 12us/step - loss: 1.6390 - mean_absolute_error: 1.6390 - val_loss: 1.6155 - val_mean_absolute_error: 1.6155\n",
      "Epoch 49/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.6374 - mean_absolute_error: 1.6374 - val_loss: 1.6633 - val_mean_absolute_error: 1.6633\n",
      "Epoch 50/50\n",
      "567532/567532 [==============================] - 6s 11us/step - loss: 1.6334 - mean_absolute_error: 1.6334 - val_loss: 1.5813 - val_mean_absolute_error: 1.5813\n",
      "1JHC Fold 0, logMAE: 0.45822176337242126\n",
      "(380609,)\n",
      "0.1527405877908071\n",
      "Train on 567533 samples, validate on 141883 samples\n",
      "Epoch 1/50\n",
      "567533/567533 [==============================] - 7s 12us/step - loss: 5.6323 - mean_absolute_error: 5.6323 - val_loss: 2.4462 - val_mean_absolute_error: 2.4462\n",
      "Epoch 2/50\n",
      "567533/567533 [==============================] - 7s 12us/step - loss: 2.3212 - mean_absolute_error: 2.3212 - val_loss: 2.3006 - val_mean_absolute_error: 2.3006\n",
      "Epoch 3/50\n",
      "567533/567533 [==============================] - 7s 13us/step - loss: 2.1895 - mean_absolute_error: 2.1895 - val_loss: 2.0555 - val_mean_absolute_error: 2.0555\n",
      "Epoch 4/50\n",
      "567533/567533 [==============================] - 7s 13us/step - loss: 2.1084 - mean_absolute_error: 2.1084 - val_loss: 2.0309 - val_mean_absolute_error: 2.0309\n",
      "Epoch 5/50\n",
      "567533/567533 [==============================] - 8s 13us/step - loss: 2.0487 - mean_absolute_error: 2.0487 - val_loss: 2.1183 - val_mean_absolute_error: 2.1183\n",
      "Epoch 6/50\n",
      "567533/567533 [==============================] - 7s 12us/step - loss: 2.0051 - mean_absolute_error: 2.0051 - val_loss: 2.0285 - val_mean_absolute_error: 2.0285\n",
      "Epoch 7/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.9703 - mean_absolute_error: 1.9703 - val_loss: 2.0075 - val_mean_absolute_error: 2.0075\n",
      "Epoch 8/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.9378 - mean_absolute_error: 1.9378 - val_loss: 1.8981 - val_mean_absolute_error: 1.8981\n",
      "Epoch 9/50\n",
      "567533/567533 [==============================] - 7s 12us/step - loss: 1.9100 - mean_absolute_error: 1.9100 - val_loss: 1.8928 - val_mean_absolute_error: 1.8928\n",
      "Epoch 10/50\n",
      "567533/567533 [==============================] - 7s 11us/step - loss: 1.8882 - mean_absolute_error: 1.8882 - val_loss: 1.8392 - val_mean_absolute_error: 1.8392\n",
      "Epoch 11/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.8668 - mean_absolute_error: 1.8668 - val_loss: 1.8359 - val_mean_absolute_error: 1.8359\n",
      "Epoch 12/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.8494 - mean_absolute_error: 1.8494 - val_loss: 1.8611 - val_mean_absolute_error: 1.8611\n",
      "Epoch 13/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.8358 - mean_absolute_error: 1.8358 - val_loss: 1.8755 - val_mean_absolute_error: 1.8755\n",
      "Epoch 14/50\n",
      "567533/567533 [==============================] - 7s 12us/step - loss: 1.8214 - mean_absolute_error: 1.8214 - val_loss: 1.7634 - val_mean_absolute_error: 1.7634\n",
      "Epoch 15/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.8103 - mean_absolute_error: 1.8103 - val_loss: 1.8486 - val_mean_absolute_error: 1.8486\n",
      "Epoch 16/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7995 - mean_absolute_error: 1.7995 - val_loss: 1.7818 - val_mean_absolute_error: 1.7818\n",
      "Epoch 17/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7899 - mean_absolute_error: 1.7899 - val_loss: 1.7888 - val_mean_absolute_error: 1.7888\n",
      "Epoch 18/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7821 - mean_absolute_error: 1.7821 - val_loss: 1.8596 - val_mean_absolute_error: 1.8596\n",
      "Epoch 19/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7730 - mean_absolute_error: 1.7730 - val_loss: 1.7271 - val_mean_absolute_error: 1.7271\n",
      "Epoch 20/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7647 - mean_absolute_error: 1.7647 - val_loss: 1.7337 - val_mean_absolute_error: 1.7337\n",
      "Epoch 21/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7596 - mean_absolute_error: 1.7596 - val_loss: 1.7687 - val_mean_absolute_error: 1.7687\n",
      "Epoch 22/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7515 - mean_absolute_error: 1.7515 - val_loss: 1.7708 - val_mean_absolute_error: 1.7708\n",
      "Epoch 23/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7454 - mean_absolute_error: 1.7454 - val_loss: 1.8414 - val_mean_absolute_error: 1.8414\n",
      "Epoch 24/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7398 - mean_absolute_error: 1.7398 - val_loss: 1.7064 - val_mean_absolute_error: 1.7064\n",
      "Epoch 25/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7347 - mean_absolute_error: 1.7347 - val_loss: 1.7232 - val_mean_absolute_error: 1.7232\n",
      "Epoch 26/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7289 - mean_absolute_error: 1.7289 - val_loss: 1.7961 - val_mean_absolute_error: 1.7961\n",
      "Epoch 27/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7252 - mean_absolute_error: 1.7252 - val_loss: 1.7627 - val_mean_absolute_error: 1.7627\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7205 - mean_absolute_error: 1.7205 - val_loss: 1.7045 - val_mean_absolute_error: 1.7045\n",
      "Epoch 29/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7137 - mean_absolute_error: 1.7137 - val_loss: 1.6702 - val_mean_absolute_error: 1.6702\n",
      "Epoch 30/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7080 - mean_absolute_error: 1.7080 - val_loss: 1.7156 - val_mean_absolute_error: 1.7156\n",
      "Epoch 31/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7022 - mean_absolute_error: 1.7022 - val_loss: 1.6988 - val_mean_absolute_error: 1.6988\n",
      "Epoch 32/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6979 - mean_absolute_error: 1.6979 - val_loss: 1.7776 - val_mean_absolute_error: 1.7776\n",
      "Epoch 33/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6909 - mean_absolute_error: 1.6909 - val_loss: 1.6305 - val_mean_absolute_error: 1.6305\n",
      "Epoch 34/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6854 - mean_absolute_error: 1.6854 - val_loss: 1.6853 - val_mean_absolute_error: 1.6853\n",
      "Epoch 35/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6825 - mean_absolute_error: 1.6825 - val_loss: 1.7170 - val_mean_absolute_error: 1.7170\n",
      "Epoch 36/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6792 - mean_absolute_error: 1.6792 - val_loss: 1.6165 - val_mean_absolute_error: 1.6165\n",
      "Epoch 37/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6730 - mean_absolute_error: 1.6730 - val_loss: 1.6810 - val_mean_absolute_error: 1.6810\n",
      "Epoch 38/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6696 - mean_absolute_error: 1.6696 - val_loss: 1.7974 - val_mean_absolute_error: 1.7974\n",
      "Epoch 39/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6677 - mean_absolute_error: 1.6677 - val_loss: 1.6514 - val_mean_absolute_error: 1.6514\n",
      "Epoch 40/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6610 - mean_absolute_error: 1.6610 - val_loss: 1.6601 - val_mean_absolute_error: 1.6601\n",
      "Epoch 41/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6596 - mean_absolute_error: 1.6596 - val_loss: 1.7701 - val_mean_absolute_error: 1.7701\n",
      "Epoch 42/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6547 - mean_absolute_error: 1.6547 - val_loss: 1.7360 - val_mean_absolute_error: 1.7360\n",
      "Epoch 43/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6509 - mean_absolute_error: 1.6509 - val_loss: 1.5991 - val_mean_absolute_error: 1.5991\n",
      "Epoch 44/50\n",
      "567533/567533 [==============================] - 7s 12us/step - loss: 1.6465 - mean_absolute_error: 1.6465 - val_loss: 1.6397 - val_mean_absolute_error: 1.6397\n",
      "Epoch 45/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6421 - mean_absolute_error: 1.6421 - val_loss: 1.6161 - val_mean_absolute_error: 1.6161\n",
      "Epoch 46/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6385 - mean_absolute_error: 1.6385 - val_loss: 1.6436 - val_mean_absolute_error: 1.6436\n",
      "Epoch 47/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6350 - mean_absolute_error: 1.6350 - val_loss: 1.7308 - val_mean_absolute_error: 1.7308\n",
      "Epoch 48/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6307 - mean_absolute_error: 1.6307 - val_loss: 1.6420 - val_mean_absolute_error: 1.6420\n",
      "Epoch 49/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6272 - mean_absolute_error: 1.6272 - val_loss: 1.6107 - val_mean_absolute_error: 1.6107\n",
      "Epoch 50/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6247 - mean_absolute_error: 1.6247 - val_loss: 1.5814 - val_mean_absolute_error: 1.5814\n",
      "1JHC Fold 1, logMAE: 0.45832502841949463\n",
      "(380609,)\n",
      "0.305515597263972\n",
      "Train on 567533 samples, validate on 141883 samples\n",
      "Epoch 1/50\n",
      "567533/567533 [==============================] - 7s 12us/step - loss: 5.7198 - mean_absolute_error: 5.7198 - val_loss: 2.3798 - val_mean_absolute_error: 2.3798\n",
      "Epoch 2/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 2.3009 - mean_absolute_error: 2.3009 - val_loss: 2.1721 - val_mean_absolute_error: 2.1721\n",
      "Epoch 3/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 2.1654 - mean_absolute_error: 2.1654 - val_loss: 2.0430 - val_mean_absolute_error: 2.0430\n",
      "Epoch 4/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 2.0800 - mean_absolute_error: 2.0800 - val_loss: 1.9990 - val_mean_absolute_error: 1.9990\n",
      "Epoch 5/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 2.0111 - mean_absolute_error: 2.0111 - val_loss: 1.9696 - val_mean_absolute_error: 1.9696\n",
      "Epoch 6/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.9639 - mean_absolute_error: 1.9639 - val_loss: 1.9496 - val_mean_absolute_error: 1.9496\n",
      "Epoch 7/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.9300 - mean_absolute_error: 1.9300 - val_loss: 1.9055 - val_mean_absolute_error: 1.9055\n",
      "Epoch 8/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.9022 - mean_absolute_error: 1.9022 - val_loss: 1.9304 - val_mean_absolute_error: 1.9304\n",
      "Epoch 9/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.8808 - mean_absolute_error: 1.8808 - val_loss: 1.8446 - val_mean_absolute_error: 1.8446\n",
      "Epoch 10/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.8630 - mean_absolute_error: 1.8630 - val_loss: 1.8434 - val_mean_absolute_error: 1.8434\n",
      "Epoch 11/50\n",
      "567533/567533 [==============================] - 7s 12us/step - loss: 1.8467 - mean_absolute_error: 1.8467 - val_loss: 1.8702 - val_mean_absolute_error: 1.8702\n",
      "Epoch 12/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.8327 - mean_absolute_error: 1.8327 - val_loss: 1.7835 - val_mean_absolute_error: 1.7835\n",
      "Epoch 13/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.8220 - mean_absolute_error: 1.8220 - val_loss: 1.7905 - val_mean_absolute_error: 1.7905\n",
      "Epoch 14/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.8101 - mean_absolute_error: 1.8101 - val_loss: 1.7705 - val_mean_absolute_error: 1.7705\n",
      "Epoch 15/50\n",
      "567533/567533 [==============================] - 7s 12us/step - loss: 1.7998 - mean_absolute_error: 1.7998 - val_loss: 1.7600 - val_mean_absolute_error: 1.7600\n",
      "Epoch 16/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7907 - mean_absolute_error: 1.7907 - val_loss: 1.7050 - val_mean_absolute_error: 1.7050\n",
      "Epoch 17/50\n",
      "567533/567533 [==============================] - 7s 12us/step - loss: 1.7825 - mean_absolute_error: 1.7825 - val_loss: 1.8892 - val_mean_absolute_error: 1.8892\n",
      "Epoch 18/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7722 - mean_absolute_error: 1.7722 - val_loss: 1.7562 - val_mean_absolute_error: 1.7562\n",
      "Epoch 19/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7666 - mean_absolute_error: 1.7666 - val_loss: 1.7188 - val_mean_absolute_error: 1.7188\n",
      "Epoch 20/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7588 - mean_absolute_error: 1.7588 - val_loss: 1.8643 - val_mean_absolute_error: 1.8643\n",
      "Epoch 21/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7503 - mean_absolute_error: 1.7503 - val_loss: 1.7961 - val_mean_absolute_error: 1.7961\n",
      "Epoch 22/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7426 - mean_absolute_error: 1.7426 - val_loss: 1.7628 - val_mean_absolute_error: 1.7628\n",
      "Epoch 23/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7366 - mean_absolute_error: 1.7366 - val_loss: 1.7685 - val_mean_absolute_error: 1.7685\n",
      "Epoch 24/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7302 - mean_absolute_error: 1.7302 - val_loss: 1.7677 - val_mean_absolute_error: 1.7677\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7252 - mean_absolute_error: 1.7252 - val_loss: 1.7770 - val_mean_absolute_error: 1.7770\n",
      "Epoch 26/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7193 - mean_absolute_error: 1.7193 - val_loss: 1.6783 - val_mean_absolute_error: 1.6783\n",
      "Epoch 27/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7139 - mean_absolute_error: 1.7139 - val_loss: 1.6723 - val_mean_absolute_error: 1.6723\n",
      "Epoch 28/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7090 - mean_absolute_error: 1.7090 - val_loss: 1.6404 - val_mean_absolute_error: 1.6404\n",
      "Epoch 29/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.7038 - mean_absolute_error: 1.7038 - val_loss: 1.8118 - val_mean_absolute_error: 1.8118\n",
      "Epoch 30/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6991 - mean_absolute_error: 1.6991 - val_loss: 1.7413 - val_mean_absolute_error: 1.7413\n",
      "Epoch 31/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6922 - mean_absolute_error: 1.6922 - val_loss: 1.7938 - val_mean_absolute_error: 1.7938\n",
      "Epoch 32/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6886 - mean_absolute_error: 1.6886 - val_loss: 1.6534 - val_mean_absolute_error: 1.6534\n",
      "Epoch 33/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6834 - mean_absolute_error: 1.6834 - val_loss: 1.7401 - val_mean_absolute_error: 1.7401\n",
      "Epoch 34/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6787 - mean_absolute_error: 1.6787 - val_loss: 1.7361 - val_mean_absolute_error: 1.7361\n",
      "Epoch 35/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6740 - mean_absolute_error: 1.6740 - val_loss: 1.8394 - val_mean_absolute_error: 1.8394\n",
      "Epoch 36/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6676 - mean_absolute_error: 1.6676 - val_loss: 1.8004 - val_mean_absolute_error: 1.8004\n",
      "Epoch 37/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6631 - mean_absolute_error: 1.6631 - val_loss: 1.6643 - val_mean_absolute_error: 1.6643\n",
      "Epoch 38/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6586 - mean_absolute_error: 1.6586 - val_loss: 1.6427 - val_mean_absolute_error: 1.6427\n",
      "Epoch 39/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6517 - mean_absolute_error: 1.6517 - val_loss: 1.6164 - val_mean_absolute_error: 1.6164\n",
      "Epoch 40/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6467 - mean_absolute_error: 1.6467 - val_loss: 1.7183 - val_mean_absolute_error: 1.7183\n",
      "Epoch 41/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6415 - mean_absolute_error: 1.6415 - val_loss: 1.6271 - val_mean_absolute_error: 1.6271\n",
      "Epoch 42/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6381 - mean_absolute_error: 1.6381 - val_loss: 1.6932 - val_mean_absolute_error: 1.6932\n",
      "Epoch 43/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6332 - mean_absolute_error: 1.6332 - val_loss: 1.6147 - val_mean_absolute_error: 1.6147\n",
      "Epoch 44/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6280 - mean_absolute_error: 1.6280 - val_loss: 1.6164 - val_mean_absolute_error: 1.6164\n",
      "Epoch 45/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6226 - mean_absolute_error: 1.6226 - val_loss: 1.8049 - val_mean_absolute_error: 1.8049\n",
      "Epoch 46/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6193 - mean_absolute_error: 1.6193 - val_loss: 1.5812 - val_mean_absolute_error: 1.5812\n",
      "Epoch 47/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6159 - mean_absolute_error: 1.6159 - val_loss: 1.6699 - val_mean_absolute_error: 1.6699\n",
      "Epoch 48/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6110 - mean_absolute_error: 1.6110 - val_loss: 1.7375 - val_mean_absolute_error: 1.7375\n",
      "Epoch 49/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6067 - mean_absolute_error: 1.6067 - val_loss: 1.5780 - val_mean_absolute_error: 1.5780\n",
      "Epoch 50/50\n",
      "567533/567533 [==============================] - 6s 11us/step - loss: 1.6033 - mean_absolute_error: 1.6033 - val_loss: 1.6545 - val_mean_absolute_error: 1.6545\n",
      "1JHC Fold 2, logMAE: 0.5035250186920166\n",
      "(380609,)\n",
      "0.47335727016131085\n",
      "*** Training Model for 2JHH ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3'],\n",
      "      dtype='object')\n",
      "Train on 302428 samples, validate on 75608 samples\n",
      "Epoch 1/50\n",
      "302428/302428 [==============================] - 4s 12us/step - loss: 0.9181 - mean_absolute_error: 0.9181 - val_loss: 0.6189 - val_mean_absolute_error: 0.6189\n",
      "Epoch 2/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.5779 - mean_absolute_error: 0.5779 - val_loss: 0.5714 - val_mean_absolute_error: 0.5714\n",
      "Epoch 3/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.5256 - mean_absolute_error: 0.5256 - val_loss: 0.5304 - val_mean_absolute_error: 0.5304\n",
      "Epoch 4/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.4963 - mean_absolute_error: 0.4963 - val_loss: 0.4775 - val_mean_absolute_error: 0.4775\n",
      "Epoch 5/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.4755 - mean_absolute_error: 0.4755 - val_loss: 0.4541 - val_mean_absolute_error: 0.4541\n",
      "Epoch 6/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.4595 - mean_absolute_error: 0.4595 - val_loss: 0.4965 - val_mean_absolute_error: 0.4965\n",
      "Epoch 7/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.4466 - mean_absolute_error: 0.4466 - val_loss: 0.4466 - val_mean_absolute_error: 0.4466\n",
      "Epoch 8/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.4362 - mean_absolute_error: 0.4362 - val_loss: 0.4293 - val_mean_absolute_error: 0.4293\n",
      "Epoch 9/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.4278 - mean_absolute_error: 0.4278 - val_loss: 0.4391 - val_mean_absolute_error: 0.4391\n",
      "Epoch 10/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.4210 - mean_absolute_error: 0.4210 - val_loss: 0.4294 - val_mean_absolute_error: 0.4294\n",
      "Epoch 11/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.4151 - mean_absolute_error: 0.4151 - val_loss: 0.4300 - val_mean_absolute_error: 0.4300\n",
      "Epoch 12/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.4094 - mean_absolute_error: 0.4094 - val_loss: 0.4003 - val_mean_absolute_error: 0.4003\n",
      "Epoch 13/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.4044 - mean_absolute_error: 0.4044 - val_loss: 0.3973 - val_mean_absolute_error: 0.3973\n",
      "Epoch 14/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.4004 - mean_absolute_error: 0.4004 - val_loss: 0.3929 - val_mean_absolute_error: 0.3929\n",
      "Epoch 15/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3961 - mean_absolute_error: 0.3961 - val_loss: 0.4003 - val_mean_absolute_error: 0.4003\n",
      "Epoch 16/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3921 - mean_absolute_error: 0.3921 - val_loss: 0.3821 - val_mean_absolute_error: 0.3821\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3878 - mean_absolute_error: 0.3878 - val_loss: 0.3818 - val_mean_absolute_error: 0.3818\n",
      "Epoch 18/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3845 - mean_absolute_error: 0.3845 - val_loss: 0.3805 - val_mean_absolute_error: 0.3805\n",
      "Epoch 19/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3819 - mean_absolute_error: 0.3819 - val_loss: 0.3985 - val_mean_absolute_error: 0.3985\n",
      "Epoch 20/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3786 - mean_absolute_error: 0.3786 - val_loss: 0.3941 - val_mean_absolute_error: 0.3941\n",
      "Epoch 21/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3757 - mean_absolute_error: 0.3757 - val_loss: 0.3788 - val_mean_absolute_error: 0.3788\n",
      "Epoch 22/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3732 - mean_absolute_error: 0.3732 - val_loss: 0.3746 - val_mean_absolute_error: 0.3746\n",
      "Epoch 23/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3710 - mean_absolute_error: 0.3710 - val_loss: 0.3722 - val_mean_absolute_error: 0.3722\n",
      "Epoch 24/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3685 - mean_absolute_error: 0.3685 - val_loss: 0.4070 - val_mean_absolute_error: 0.4070\n",
      "Epoch 25/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3663 - mean_absolute_error: 0.3663 - val_loss: 0.3687 - val_mean_absolute_error: 0.3687\n",
      "Epoch 26/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3646 - mean_absolute_error: 0.3646 - val_loss: 0.3654 - val_mean_absolute_error: 0.3654\n",
      "Epoch 27/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3621 - mean_absolute_error: 0.3621 - val_loss: 0.3848 - val_mean_absolute_error: 0.3848\n",
      "Epoch 28/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3609 - mean_absolute_error: 0.3609 - val_loss: 0.3541 - val_mean_absolute_error: 0.3541\n",
      "Epoch 29/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3590 - mean_absolute_error: 0.3590 - val_loss: 0.3601 - val_mean_absolute_error: 0.3601\n",
      "Epoch 30/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3574 - mean_absolute_error: 0.3574 - val_loss: 0.4057 - val_mean_absolute_error: 0.4057\n",
      "Epoch 31/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3559 - mean_absolute_error: 0.3559 - val_loss: 0.3540 - val_mean_absolute_error: 0.3540\n",
      "Epoch 32/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3544 - mean_absolute_error: 0.3544 - val_loss: 0.3797 - val_mean_absolute_error: 0.3797\n",
      "Epoch 33/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3528 - mean_absolute_error: 0.3528 - val_loss: 0.3611 - val_mean_absolute_error: 0.3611\n",
      "Epoch 34/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3521 - mean_absolute_error: 0.3521 - val_loss: 0.3479 - val_mean_absolute_error: 0.3479\n",
      "Epoch 35/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3507 - mean_absolute_error: 0.3507 - val_loss: 0.3623 - val_mean_absolute_error: 0.3623\n",
      "Epoch 36/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3490 - mean_absolute_error: 0.3490 - val_loss: 0.3480 - val_mean_absolute_error: 0.3480\n",
      "Epoch 37/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3478 - mean_absolute_error: 0.3478 - val_loss: 0.3536 - val_mean_absolute_error: 0.3536\n",
      "Epoch 38/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3473 - mean_absolute_error: 0.3473 - val_loss: 0.3657 - val_mean_absolute_error: 0.3657\n",
      "Epoch 39/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3452 - mean_absolute_error: 0.3452 - val_loss: 0.3470 - val_mean_absolute_error: 0.3470\n",
      "Epoch 40/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3441 - mean_absolute_error: 0.3441 - val_loss: 0.3462 - val_mean_absolute_error: 0.3462\n",
      "Epoch 41/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3432 - mean_absolute_error: 0.3432 - val_loss: 0.3469 - val_mean_absolute_error: 0.3469\n",
      "Epoch 42/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3421 - mean_absolute_error: 0.3421 - val_loss: 0.3705 - val_mean_absolute_error: 0.3705\n",
      "Epoch 43/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3413 - mean_absolute_error: 0.3413 - val_loss: 0.3491 - val_mean_absolute_error: 0.3491\n",
      "Epoch 44/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3399 - mean_absolute_error: 0.3399 - val_loss: 0.3436 - val_mean_absolute_error: 0.3436\n",
      "Epoch 45/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3391 - mean_absolute_error: 0.3391 - val_loss: 0.3357 - val_mean_absolute_error: 0.3357\n",
      "Epoch 46/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3378 - mean_absolute_error: 0.3378 - val_loss: 0.3419 - val_mean_absolute_error: 0.3419\n",
      "Epoch 47/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3370 - mean_absolute_error: 0.3370 - val_loss: 0.3274 - val_mean_absolute_error: 0.3274\n",
      "Epoch 48/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3358 - mean_absolute_error: 0.3358 - val_loss: 0.3660 - val_mean_absolute_error: 0.3660\n",
      "Epoch 49/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3349 - mean_absolute_error: 0.3349 - val_loss: 0.3593 - val_mean_absolute_error: 0.3593\n",
      "Epoch 50/50\n",
      "302428/302428 [==============================] - 3s 11us/step - loss: 0.3336 - mean_absolute_error: 0.3336 - val_loss: 0.3365 - val_mean_absolute_error: 0.3365\n",
      "2JHH Fold 0, logMAE: -1.0892146825790405\n",
      "(203126,)\n",
      "-0.3630715608596802\n",
      "Train on 302429 samples, validate on 75607 samples\n",
      "Epoch 1/50\n",
      "302429/302429 [==============================] - 4s 14us/step - loss: 0.9182 - mean_absolute_error: 0.9182 - val_loss: 0.6285 - val_mean_absolute_error: 0.6285\n",
      "Epoch 2/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.5981 - mean_absolute_error: 0.5981 - val_loss: 0.6370 - val_mean_absolute_error: 0.6370\n",
      "Epoch 3/50\n",
      "302429/302429 [==============================] - 4s 12us/step - loss: 0.5533 - mean_absolute_error: 0.5533 - val_loss: 0.5537 - val_mean_absolute_error: 0.5537\n",
      "Epoch 4/50\n",
      "302429/302429 [==============================] - 4s 12us/step - loss: 0.5259 - mean_absolute_error: 0.5259 - val_loss: 0.5327 - val_mean_absolute_error: 0.5327\n",
      "Epoch 5/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.5035 - mean_absolute_error: 0.5035 - val_loss: 0.5001 - val_mean_absolute_error: 0.5001\n",
      "Epoch 6/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.4857 - mean_absolute_error: 0.4857 - val_loss: 0.4674 - val_mean_absolute_error: 0.4674\n",
      "Epoch 7/50\n",
      "302429/302429 [==============================] - 4s 12us/step - loss: 0.4701 - mean_absolute_error: 0.4701 - val_loss: 0.5240 - val_mean_absolute_error: 0.5240\n",
      "Epoch 8/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.4579 - mean_absolute_error: 0.4579 - val_loss: 0.4432 - val_mean_absolute_error: 0.4432\n",
      "Epoch 9/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.4467 - mean_absolute_error: 0.4467 - val_loss: 0.4444 - val_mean_absolute_error: 0.4444\n",
      "Epoch 10/50\n",
      "302429/302429 [==============================] - 4s 12us/step - loss: 0.4377 - mean_absolute_error: 0.4377 - val_loss: 0.4123 - val_mean_absolute_error: 0.4123\n",
      "Epoch 11/50\n",
      "302429/302429 [==============================] - 4s 12us/step - loss: 0.4294 - mean_absolute_error: 0.4294 - val_loss: 0.4857 - val_mean_absolute_error: 0.4857\n",
      "Epoch 12/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.4233 - mean_absolute_error: 0.4233 - val_loss: 0.3977 - val_mean_absolute_error: 0.3977\n",
      "Epoch 13/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.4169 - mean_absolute_error: 0.4169 - val_loss: 0.4113 - val_mean_absolute_error: 0.4113\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.4114 - mean_absolute_error: 0.4114 - val_loss: 0.4201 - val_mean_absolute_error: 0.4201\n",
      "Epoch 15/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.4063 - mean_absolute_error: 0.4063 - val_loss: 0.3975 - val_mean_absolute_error: 0.3975\n",
      "Epoch 16/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.4014 - mean_absolute_error: 0.4014 - val_loss: 0.4105 - val_mean_absolute_error: 0.4105\n",
      "Epoch 17/50\n",
      "302429/302429 [==============================] - 4s 12us/step - loss: 0.3969 - mean_absolute_error: 0.3969 - val_loss: 0.3948 - val_mean_absolute_error: 0.3948\n",
      "Epoch 18/50\n",
      "302429/302429 [==============================] - 4s 12us/step - loss: 0.3936 - mean_absolute_error: 0.3936 - val_loss: 0.4017 - val_mean_absolute_error: 0.4017\n",
      "Epoch 19/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.3896 - mean_absolute_error: 0.3896 - val_loss: 0.3975 - val_mean_absolute_error: 0.3975\n",
      "Epoch 20/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.3869 - mean_absolute_error: 0.3869 - val_loss: 0.3835 - val_mean_absolute_error: 0.3835\n",
      "Epoch 21/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.3839 - mean_absolute_error: 0.3839 - val_loss: 0.4382 - val_mean_absolute_error: 0.4382\n",
      "Epoch 22/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.3808 - mean_absolute_error: 0.3808 - val_loss: 0.3728 - val_mean_absolute_error: 0.3728\n",
      "Epoch 23/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.3777 - mean_absolute_error: 0.3777 - val_loss: 0.3641 - val_mean_absolute_error: 0.3641\n",
      "Epoch 24/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.3755 - mean_absolute_error: 0.3755 - val_loss: 0.3745 - val_mean_absolute_error: 0.3745\n",
      "Epoch 25/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.3724 - mean_absolute_error: 0.3724 - val_loss: 0.3829 - val_mean_absolute_error: 0.3829\n",
      "Epoch 26/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.3699 - mean_absolute_error: 0.3699 - val_loss: 0.4132 - val_mean_absolute_error: 0.4132\n",
      "Epoch 27/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.3684 - mean_absolute_error: 0.3684 - val_loss: 0.4092 - val_mean_absolute_error: 0.4092\n",
      "Epoch 28/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.3663 - mean_absolute_error: 0.3663 - val_loss: 0.3784 - val_mean_absolute_error: 0.3784\n",
      "Epoch 29/50\n",
      "302429/302429 [==============================] - 3s 11us/step - loss: 0.3640 - mean_absolute_error: 0.3640 - val_loss: 0.3811 - val_mean_absolute_error: 0.3811\n",
      "Epoch 30/50\n",
      "243456/302429 [=======================>......] - ETA: 0s - loss: 0.3639 - mean_absolute_error: 0.3639"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    '1JHN': 7,\n",
    "    '1JHC': 10,\n",
    "    '2JHH': 9,\n",
    "    '2JHN': 9,\n",
    "    '2JHC': 9,\n",
    "    '3JHH': 9,\n",
    "    '3JHC': 10,\n",
    "    '3JHN': 10\n",
    "}\n",
    "N_FOLDS = 3\n",
    "submission = submission_csv.copy()\n",
    "\n",
    "cv_scores = {}\n",
    "for coupling_type in model_params.keys():\n",
    "    cv_score = train_and_predict_for_one_coupling_type(\n",
    "        coupling_type, submission, n_atoms=model_params[coupling_type], n_folds=N_FOLDS)\n",
    "    cv_scores[coupling_type] = cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
>>>>>>> f38c5a3fada567d5fd5ef03c20ccba924f0bb423
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>atom_2</th>\n",
       "      <th>atom_3</th>\n",
       "      <th>atom_4</th>\n",
       "      <th>atom_5</th>\n",
       "      <th>atom_6</th>\n",
       "      <th>atom_7</th>\n",
       "      <th>atom_8</th>\n",
       "      <th>atom_9</th>\n",
       "      <th>d_1_0</th>\n",
       "      <th>d_2_0</th>\n",
       "      <th>d_2_1</th>\n",
       "      <th>d_3_0</th>\n",
       "      <th>d_3_1</th>\n",
       "      <th>d_3_2</th>\n",
       "      <th>d_4_0</th>\n",
       "      <th>d_4_1</th>\n",
       "      <th>d_4_2</th>\n",
       "      <th>d_4_3</th>\n",
       "      <th>d_5_0</th>\n",
       "      <th>d_5_1</th>\n",
       "      <th>d_5_2</th>\n",
       "      <th>d_5_3</th>\n",
       "      <th>d_6_0</th>\n",
       "      <th>d_6_1</th>\n",
       "      <th>d_6_2</th>\n",
       "      <th>d_6_3</th>\n",
       "      <th>d_7_0</th>\n",
       "      <th>d_7_1</th>\n",
       "      <th>d_7_2</th>\n",
       "      <th>d_7_3</th>\n",
       "      <th>d_8_0</th>\n",
       "      <th>d_8_1</th>\n",
       "      <th>d_8_2</th>\n",
       "      <th>d_8_3</th>\n",
       "      <th>d_9_0</th>\n",
       "      <th>d_9_1</th>\n",
       "      <th>d_9_2</th>\n",
       "      <th>d_9_3</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
=======
       "      <th>type</th>\n",
       "      <th>cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1JHN</td>\n",
       "      <td>-0.989828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1JHC</td>\n",
       "      <td>-0.259521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2JHH</td>\n",
       "      <td>-1.739042</td>\n",
>>>>>>> f38c5a3fada567d5fd5ef03c20ccba924f0bb423
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.017190</td>\n",
       "      <td>1.618523</td>\n",
       "      <td>1.017187</td>\n",
       "      <td>1.618710</td>\n",
       "      <td>1.017208</td>\n",
       "      <td>1.618706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.688900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.017187</td>\n",
       "      <td>1.618523</td>\n",
       "      <td>1.017190</td>\n",
       "      <td>1.618706</td>\n",
       "      <td>1.017208</td>\n",
       "      <td>1.618710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.689098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.017208</td>\n",
       "      <td>1.618706</td>\n",
       "      <td>1.017187</td>\n",
       "      <td>1.618710</td>\n",
       "      <td>1.017190</td>\n",
       "      <td>1.618523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.690498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.007511</td>\n",
       "      <td>1.734777</td>\n",
       "      <td>1.004933</td>\n",
       "      <td>2.050487</td>\n",
       "      <td>1.359838</td>\n",
       "      <td>2.071779</td>\n",
       "      <td>2.549623</td>\n",
       "      <td>2.280430</td>\n",
       "      <td>3.173246</td>\n",
       "      <td>1.209220</td>\n",
       "      <td>2.960154</td>\n",
       "      <td>2.047394</td>\n",
       "      <td>2.302437</td>\n",
       "      <td>1.109295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.525200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.004933</td>\n",
       "      <td>1.734777</td>\n",
       "      <td>1.007511</td>\n",
       "      <td>2.071779</td>\n",
       "      <td>1.359838</td>\n",
       "      <td>2.050487</td>\n",
       "      <td>2.302437</td>\n",
       "      <td>2.047394</td>\n",
       "      <td>2.960154</td>\n",
       "      <td>1.109295</td>\n",
       "      <td>3.173246</td>\n",
       "      <td>2.280430</td>\n",
       "      <td>2.549623</td>\n",
       "      <td>1.209220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.735901</td>\n",
=======
       "      <th>3</th>\n",
       "      <td>2JHN</td>\n",
       "      <td>-1.957707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2JHC</td>\n",
       "      <td>-1.182418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3JHH</td>\n",
       "      <td>-1.743725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3JHC</td>\n",
       "      <td>-1.093818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3JHN</td>\n",
       "      <td>-2.196844</td>\n",
>>>>>>> f38c5a3fada567d5fd5ef03c20ccba924f0bb423
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "   atom_2  atom_3  atom_4  atom_5  atom_6  atom_7  atom_8  atom_9     d_1_0  \\\n",
       "0  1       1       0       0       0       0       0       0       1.017190   \n",
       "1  1       1       0       0       0       0       0       0       1.017187   \n",
       "2  1       1       0       0       0       0       0       0       1.017208   \n",
       "3  1       6       8       1       0       0       0       0       1.007511   \n",
       "4  1       6       1       8       0       0       0       0       1.004933   \n",
       "\n",
       "      d_2_0     d_2_1     d_3_0     d_3_1     d_3_2     d_4_0     d_4_1  \\\n",
       "0  1.618523  1.017187  1.618710  1.017208  1.618706  0.000000  0.000000   \n",
       "1  1.618523  1.017190  1.618706  1.017208  1.618710  0.000000  0.000000   \n",
       "2  1.618706  1.017187  1.618710  1.017190  1.618523  0.000000  0.000000   \n",
       "3  1.734777  1.004933  2.050487  1.359838  2.071779  2.549623  2.280430   \n",
       "4  1.734777  1.007511  2.071779  1.359838  2.050487  2.302437  2.047394   \n",
       "\n",
       "      d_4_2     d_4_3     d_5_0     d_5_1     d_5_2     d_5_3  d_6_0  d_6_1  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0    0.0     \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0    0.0     \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0    0.0     \n",
       "3  3.173246  1.209220  2.960154  2.047394  2.302437  1.109295  0.0    0.0     \n",
       "4  2.960154  1.109295  3.173246  2.280430  2.549623  1.209220  0.0    0.0     \n",
       "\n",
       "   d_6_2  d_6_3  d_7_0  d_7_1  d_7_2  d_7_3  d_8_0  d_8_1  d_8_2  d_8_3  \\\n",
       "0  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     \n",
       "1  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     \n",
       "2  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     \n",
       "3  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     \n",
       "4  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     \n",
       "\n",
       "   d_9_0  d_9_1  d_9_2  d_9_3  scalar_coupling_constant  \n",
       "0  0.0    0.0    0.0    0.0    32.688900                 \n",
       "1  0.0    0.0    0.0    0.0    32.689098                 \n",
       "2  0.0    0.0    0.0    0.0    32.690498                 \n",
       "3  0.0    0.0    0.0    0.0    55.525200                 \n",
       "4  0.0    0.0    0.0    0.0    54.735901                 "
      ]
     },
     "execution_count": 25,
=======
       "   type  cv_score\n",
       "0  1JHN -0.989828\n",
       "1  1JHC -0.259521\n",
       "2  2JHH -1.739042\n",
       "3  2JHN -1.957707\n",
       "4  2JHC -1.182418\n",
       "5  3JHH -1.743725\n",
       "6  3JHC -1.093818\n",
       "7  3JHN -2.196844"
      ]
     },
     "execution_count": 48,
>>>>>>> f38c5a3fada567d5fd5ef03c20ccba924f0bb423
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'd_1_0', 'd_2_0',\n",
      "       'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1', 'd_4_2', 'd_4_3',\n",
      "       'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1', 'd_6_2', 'd_6_3',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:28,036] Finished trial#0 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:28,300] Finished trial#1 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:28,570] Finished trial#2 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:28,851] Finished trial#3 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:29,203] Finished trial#4 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:29,507] Finished trial#5 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:29,811] Finished trial#6 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:30,093] Finished trial#7 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:30,370] Finished trial#8 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:30,679] Finished trial#9 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:31,013] Finished trial#10 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:31,338] Finished trial#11 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:31,651] Finished trial#12 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:31,966] Finished trial#13 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:32,372] Finished trial#14 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:32,715] Finished trial#15 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:33,063] Finished trial#16 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:33,480] Finished trial#17 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:33,836] Finished trial#18 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:34,204] Finished trial#19 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:34,624] Finished trial#20 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:34,986] Finished trial#21 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:35,339] Finished trial#22 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:35,679] Finished trial#23 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:36,023] Finished trial#24 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:36,398] Finished trial#25 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:36,735] Finished trial#26 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:37,100] Finished trial#27 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:37,442] Finished trial#28 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:37,817] Finished trial#29 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:38,159] Finished trial#30 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:38,507] Finished trial#31 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:38,860] Finished trial#32 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:39,217] Finished trial#33 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:39,590] Finished trial#34 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:39,944] Finished trial#35 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:40,317] Finished trial#36 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:40,693] Finished trial#37 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:41,078] Finished trial#38 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:41,448] Finished trial#39 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:41,829] Finished trial#40 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:42,196] Finished trial#41 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:42,597] Finished trial#42 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:43,038] Finished trial#43 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:43,404] Finished trial#44 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:43,798] Finished trial#45 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:44,193] Finished trial#46 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:44,585] Finished trial#47 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:44,976] Finished trial#48 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:45,384] Finished trial#49 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:45,768] Finished trial#50 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:46,156] Finished trial#51 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:46,557] Finished trial#52 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:46,951] Finished trial#53 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:47,366] Finished trial#54 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:47,789] Finished trial#55 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:48,186] Finished trial#56 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:48,584] Finished trial#57 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:48,998] Finished trial#58 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:49,425] Finished trial#59 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:49,895] Finished trial#60 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:50,350] Finished trial#61 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:50,779] Finished trial#62 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:51,211] Finished trial#63 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:51,664] Finished trial#64 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:52,091] Finished trial#65 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:52,577] Finished trial#66 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:53,019] Finished trial#67 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:53,437] Finished trial#68 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:53,884] Finished trial#69 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:54,306] Finished trial#70 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:54,732] Finished trial#71 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:55,187] Finished trial#72 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:55,616] Finished trial#73 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:56,067] Finished trial#74 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:56,525] Finished trial#75 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:56,970] Finished trial#76 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:57,451] Finished trial#77 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:57,964] Finished trial#78 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:58,405] Finished trial#79 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:58,853] Finished trial#80 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:59,292] Finished trial#81 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:49:59,740] Finished trial#82 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:00,196] Finished trial#83 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:00,645] Finished trial#84 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:01,090] Finished trial#85 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:01,621] Finished trial#86 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:02,066] Finished trial#87 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:02,569] Finished trial#88 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:03,028] Finished trial#89 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:03,532] Finished trial#90 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:03,981] Finished trial#91 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:04,432] Finished trial#92 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:04,897] Finished trial#93 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:05,367] Finished trial#94 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:05,912] Finished trial#95 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:06,403] Finished trial#96 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:06,909] Finished trial#97 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:07,405] Finished trial#98 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:07,904] Finished trial#99 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:08,411] Finished trial#100 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:08,889] Finished trial#101 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:09,363] Finished trial#102 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:09,843] Finished trial#103 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:10,328] Finished trial#104 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:10,822] Finished trial#105 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:11,310] Finished trial#106 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:11,805] Finished trial#107 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:12,293] Finished trial#108 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:12,817] Finished trial#109 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:13,294] Finished trial#110 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:13,770] Finished trial#111 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:14,255] Finished trial#112 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:14,762] Finished trial#113 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:15,287] Finished trial#114 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:15,809] Finished trial#115 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:16,366] Finished trial#116 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:16,883] Finished trial#117 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:17,423] Finished trial#118 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:17,973] Finished trial#119 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:18,473] Finished trial#120 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:18,963] Finished trial#121 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:19,459] Finished trial#122 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:19,956] Finished trial#123 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:20,470] Finished trial#124 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:20,997] Finished trial#125 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:21,502] Finished trial#126 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:22,013] Finished trial#127 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:22,566] Finished trial#128 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:23,085] Finished trial#129 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:23,635] Finished trial#130 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:24,244] Finished trial#131 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:24,813] Finished trial#132 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:25,385] Finished trial#133 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:25,928] Finished trial#134 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:26,454] Finished trial#135 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:26,968] Finished trial#136 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:27,477] Finished trial#137 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:27,998] Finished trial#138 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:28,535] Finished trial#139 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:29,095] Finished trial#140 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:29,634] Finished trial#141 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:30,174] Finished trial#142 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:30,715] Finished trial#143 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:31,264] Finished trial#144 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:31,789] Finished trial#145 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:32,326] Finished trial#146 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:32,878] Finished trial#147 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:33,448] Finished trial#148 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold_index: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.4349565981664\n",
      "kfold_index: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.549965994906024\n",
      "kfold_index: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0\n",
      "46.454733982115215\n",
      "[46.4349565981664, 46.549965994906024, 46.454733982115215]\n",
      "[1, 1, 1] 1.0\n",
      "(43363, 23)\n",
      "(43363,)\n",
      "[46.479884488950496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-12 20:50:33,986] Finished trial#149 resulted in value: 46.479884488950496. Current best value is 46.479884488950496 with parameters: {'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}.\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "import optuna\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=218)\n",
    "\n",
    "X_data, y_data = build_x_y_data(train_csv, coupling_type='1JHN', n_atoms=7)\n",
    "\n",
    "def objective(trial):\n",
    "    drop_rate = trial.suggest_uniform('drop_rate', 0, 1.0)\n",
    "    feature_fraction = trial.suggest_uniform('feature_fraction', 0, 1.0)\n",
    "    learning_rate = trial.suggest_uniform('learning_rate', 0, 1.0)\n",
    "    subsample = trial.suggest_uniform('subsample', 0.8, 1.0)\n",
    "    num_leaves = trial.suggest_int('num_leaves', 5, 1000)\n",
    "    verbosity = trial.suggest_int('verbosity', -1, 1)\n",
    "    num_boost_round = trial.suggest_int('num_boost_round', 10, 100000)\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 10, 100000)\n",
    "    min_child_samples = trial.suggest_int('min_child_samples', 5, 500)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 5, 500)\n",
    " \n",
    "    params = {\"objective\": \"binary\",\n",
    "              \"boosting_type\": \"gbdt\",\n",
    "              \"learning_rate\": learning_rate,\n",
    "              \"num_leaves\": num_leaves,\n",
    "              \"max_bin\": 256,\n",
    "              \"feature_fraction\": feature_fraction,\n",
    "              \"verbosity\": verbosity,\n",
    "              \"drop_rate\": drop_rate,\n",
    "              \"is_unbalance\": False,\n",
    "              \"max_drop\": 50,\n",
    "              \"min_child_samples\": min_child_samples,\n",
    "              \"min_child_weight\": min_child_weight,\n",
    "              \"min_split_gain\": 0,\n",
    "              \"min_data_in_leaf\": min_data_in_leaf,\n",
    "              \"subsample\": subsample\n",
    "              }\n",
    " \n",
    "    x_score = []\n",
    "    final_cv_train = np.zeros(len(y_data))\n",
    "   # final_cv_pred = np.zeros(len(test_id))\n",
    " \n",
    "    cv_train = np.zeros(len(y_data))\n",
    "    #cv_pred = np.zeros(len(test_id))\n",
    " \n",
    "    params['seed'] = 0\n",
    " \n",
    "    kf = kfold.split(X_data, y_data)\n",
    " \n",
    "    best_trees = []\n",
    "    fold_scores = []\n",
    " \n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        print('kfold_index:', i)\n",
    "        X_train, X_validate, label_train, label_validate = \\\n",
    "            X_data[train_fold, :], X_data[validate, :], y_data[train_fold], y_data[validate]\n",
    "        dtrain = lgbm.Dataset(X_train, label_train)\n",
    "        dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "        bst = lgbm.train(params, dtrain, num_boost_round, valid_sets=dvalid, verbose_eval=100,\n",
    "                        early_stopping_rounds=100)\n",
    "        best_trees.append(bst.best_iteration)\n",
    "#        cv_pred += bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "        cv_train[validate] += bst.predict(X_validate)\n",
    " \n",
    "        score = mean_absolute_error(label_validate,cv_train[validate])\n",
    "        print(score)\n",
    "        fold_scores.append(score)\n",
    " \n",
    " \n",
    "    #cv_pred /= 3\n",
    "    final_cv_train += cv_train\n",
    "    #final_cv_pred += cv_pred\n",
    " \n",
    "    print(fold_scores)\n",
    "    print(best_trees, np.mean(best_trees))\n",
    "    print(X_data.shape)\n",
    "    print(cv_train.shape)\n",
    " \n",
    "    x_score.append(mean_absolute_error(y_data, cv_train))\n",
    "    print(x_score)\n",
    " \n",
    "    return x_score[0]\n",
    " \n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'drop_rate': 0.040960108343318535, 'feature_fraction': 0.6584099063624647, 'learning_rate': 0.9639550458959371, 'subsample': 0.8500161901682345, 'num_leaves': 383, 'verbosity': 1, 'num_boost_round': 79917, 'min_data_in_leaf': 72387, 'min_child_samples': 290, 'min_child_weight': 491}\n",
      "46.479884488950496\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_x_y_data(some_csv, coupling_type, n_atoms):\n",
    "    full = build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms=n_atoms)\n",
    "    \n",
    "    df = take_n_atoms(full, n_atoms)\n",
    "    df = df.fillna(0)\n",
    "    print(df.columns)\n",
    "    \n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        X_data = df.drop(['scalar_coupling_constant'], axis=1).values.astype('float32')\n",
    "        y_data = df['scalar_coupling_constant'].values.astype('float32')\n",
    "    else:\n",
    "        X_data = df.values.astype('float32')\n",
    "        y_data = None\n",
    "    \n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_for_one_coupling_type(coupling_type, submission, n_atoms, n_folds=5, n_splits=5, random_state=128):\n",
    "    print(f'*** Training Model for {coupling_type} ***')\n",
    "    \n",
    "    X_data, y_data = build_x_y_data(train_csv, coupling_type, n_atoms)\n",
    "    X_test, _ = build_x_y_data(test_csv, coupling_type, n_atoms)\n",
    "    y_pred = np.zeros(X_test.shape[0], dtype='float32')\n",
    "\n",
    "    cv_score = 0\n",
    "    \n",
    "    if n_folds > n_splits:\n",
    "        n_splits = n_folds\n",
    "    \n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X_data, y_data)):\n",
    "        if fold >= n_folds:\n",
    "            break\n",
    "\n",
    "        X_train, X_val = X_data[train_index], X_data[val_index]\n",
    "        y_train, y_val = y_data[train_index], y_data[val_index]\n",
    "\n",
    "        model = LGBMRegressor(**LGB_PARAMS, n_estimators=3000, n_jobs = -1)\n",
    "        model.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric='mae',\n",
    "            verbose=100, early_stopping_rounds=200)\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        val_score = np.log(mean_absolute_error(y_val, y_val_pred))\n",
    "        print(f'{coupling_type} Fold {fold}, logMAE: {val_score}')\n",
    "        \n",
    "        cv_score += val_score / n_folds\n",
    "        y_pred += model.predict(X_test) / n_folds\n",
    "        \n",
    "        \n",
    "    submission.loc[test_csv['type'] == coupling_type, 'scalar_coupling_constant'] = y_pred\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training Model for 1JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'd_1_0', 'd_2_0',\n",
      "       'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1', 'd_4_2', 'd_4_3',\n",
      "       'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1', 'd_6_2', 'd_6_3',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'd_1_0', 'd_2_0',\n",
      "       'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1', 'd_4_2', 'd_4_3',\n",
      "       'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1', 'd_6_2', 'd_6_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.318865\tvalid_1's l1: 0.463026\n",
      "[200]\ttraining's l1: 0.235867\tvalid_1's l1: 0.423691\n",
      "[300]\ttraining's l1: 0.188683\tvalid_1's l1: 0.407229\n",
      "[400]\ttraining's l1: 0.157509\tvalid_1's l1: 0.39844\n",
      "[500]\ttraining's l1: 0.134101\tvalid_1's l1: 0.392723\n",
      "[600]\ttraining's l1: 0.116837\tvalid_1's l1: 0.38907\n",
      "[700]\ttraining's l1: 0.10274\tvalid_1's l1: 0.386181\n",
      "[800]\ttraining's l1: 0.0911797\tvalid_1's l1: 0.384086\n",
      "[900]\ttraining's l1: 0.0817441\tvalid_1's l1: 0.382195\n",
      "[1000]\ttraining's l1: 0.0736049\tvalid_1's l1: 0.380949\n",
      "[1100]\ttraining's l1: 0.0668515\tvalid_1's l1: 0.379963\n",
      "[1200]\ttraining's l1: 0.0607948\tvalid_1's l1: 0.379215\n",
      "[1300]\ttraining's l1: 0.0557823\tvalid_1's l1: 0.378678\n",
      "[1400]\ttraining's l1: 0.0513113\tvalid_1's l1: 0.37842\n",
      "[1500]\ttraining's l1: 0.0472493\tvalid_1's l1: 0.377966\n",
      "[1600]\ttraining's l1: 0.0437806\tvalid_1's l1: 0.377537\n",
      "[1700]\ttraining's l1: 0.0406232\tvalid_1's l1: 0.377188\n",
      "[1800]\ttraining's l1: 0.0378541\tvalid_1's l1: 0.376968\n",
      "[1900]\ttraining's l1: 0.0353928\tvalid_1's l1: 0.376796\n",
      "[2000]\ttraining's l1: 0.0331291\tvalid_1's l1: 0.376579\n",
      "[2100]\ttraining's l1: 0.0311141\tvalid_1's l1: 0.376415\n",
      "[2200]\ttraining's l1: 0.0292634\tvalid_1's l1: 0.376368\n",
      "[2300]\ttraining's l1: 0.0275663\tvalid_1's l1: 0.376337\n",
      "[2400]\ttraining's l1: 0.026034\tvalid_1's l1: 0.376204\n",
      "[2500]\ttraining's l1: 0.0246483\tvalid_1's l1: 0.376153\n",
      "[2600]\ttraining's l1: 0.0233664\tvalid_1's l1: 0.376048\n",
      "[2700]\ttraining's l1: 0.0221854\tvalid_1's l1: 0.375963\n",
      "[2800]\ttraining's l1: 0.0210934\tvalid_1's l1: 0.375836\n",
      "[2900]\ttraining's l1: 0.0200851\tvalid_1's l1: 0.375756\n",
      "[3000]\ttraining's l1: 0.0191509\tvalid_1's l1: 0.375703\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0191509\tvalid_1's l1: 0.375703\n",
      "1JHN Fold 0, logMAE: -0.97895596612208\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.318101\tvalid_1's l1: 0.455287\n",
      "[200]\ttraining's l1: 0.234356\tvalid_1's l1: 0.419764\n",
      "[300]\ttraining's l1: 0.188263\tvalid_1's l1: 0.404007\n",
      "[400]\ttraining's l1: 0.156997\tvalid_1's l1: 0.394532\n",
      "[500]\ttraining's l1: 0.133883\tvalid_1's l1: 0.389079\n",
      "[600]\ttraining's l1: 0.116772\tvalid_1's l1: 0.385465\n",
      "[700]\ttraining's l1: 0.102715\tvalid_1's l1: 0.382546\n",
      "[800]\ttraining's l1: 0.0913246\tvalid_1's l1: 0.380531\n",
      "[900]\ttraining's l1: 0.0818923\tvalid_1's l1: 0.37913\n",
      "[1000]\ttraining's l1: 0.0740338\tvalid_1's l1: 0.37807\n",
      "[1100]\ttraining's l1: 0.0671981\tvalid_1's l1: 0.3771\n",
      "[1200]\ttraining's l1: 0.0613901\tvalid_1's l1: 0.375909\n",
      "[1300]\ttraining's l1: 0.056295\tvalid_1's l1: 0.375212\n",
      "[1400]\ttraining's l1: 0.0518232\tvalid_1's l1: 0.374798\n",
      "[1500]\ttraining's l1: 0.0478619\tvalid_1's l1: 0.374442\n",
      "[1600]\ttraining's l1: 0.0444005\tvalid_1's l1: 0.374008\n",
      "[1700]\ttraining's l1: 0.0412648\tvalid_1's l1: 0.373938\n",
      "[1800]\ttraining's l1: 0.0385041\tvalid_1's l1: 0.373689\n",
      "[1900]\ttraining's l1: 0.0360199\tvalid_1's l1: 0.373464\n",
      "[2000]\ttraining's l1: 0.0337015\tvalid_1's l1: 0.373136\n",
      "[2100]\ttraining's l1: 0.0316418\tvalid_1's l1: 0.373013\n",
      "[2200]\ttraining's l1: 0.0297938\tvalid_1's l1: 0.37288\n",
      "[2300]\ttraining's l1: 0.0280579\tvalid_1's l1: 0.372746\n",
      "[2400]\ttraining's l1: 0.0265065\tvalid_1's l1: 0.372608\n",
      "[2500]\ttraining's l1: 0.0250721\tvalid_1's l1: 0.372436\n",
      "[2600]\ttraining's l1: 0.0237709\tvalid_1's l1: 0.37239\n",
      "[2700]\ttraining's l1: 0.0225636\tvalid_1's l1: 0.372299\n",
      "[2800]\ttraining's l1: 0.0214773\tvalid_1's l1: 0.372129\n",
      "[2900]\ttraining's l1: 0.0204591\tvalid_1's l1: 0.372081\n",
      "[3000]\ttraining's l1: 0.0195201\tvalid_1's l1: 0.372041\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0195201\tvalid_1's l1: 0.372041\n",
      "1JHN Fold 1, logMAE: -0.9887514325177348\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.319958\tvalid_1's l1: 0.453507\n",
      "[200]\ttraining's l1: 0.235983\tvalid_1's l1: 0.418637\n",
      "[300]\ttraining's l1: 0.190829\tvalid_1's l1: 0.402941\n",
      "[400]\ttraining's l1: 0.159302\tvalid_1's l1: 0.393724\n",
      "[500]\ttraining's l1: 0.136132\tvalid_1's l1: 0.387802\n",
      "[600]\ttraining's l1: 0.118302\tvalid_1's l1: 0.382836\n",
      "[700]\ttraining's l1: 0.10385\tvalid_1's l1: 0.380158\n",
      "[800]\ttraining's l1: 0.092281\tvalid_1's l1: 0.377934\n",
      "[900]\ttraining's l1: 0.0825938\tvalid_1's l1: 0.376488\n",
      "[1000]\ttraining's l1: 0.0744146\tvalid_1's l1: 0.375222\n",
      "[1100]\ttraining's l1: 0.0675201\tvalid_1's l1: 0.374159\n",
      "[1200]\ttraining's l1: 0.0615724\tvalid_1's l1: 0.373373\n",
      "[1300]\ttraining's l1: 0.0563783\tvalid_1's l1: 0.372502\n",
      "[1400]\ttraining's l1: 0.0518039\tvalid_1's l1: 0.372073\n",
      "[1500]\ttraining's l1: 0.0478146\tvalid_1's l1: 0.371453\n",
      "[1600]\ttraining's l1: 0.0442702\tvalid_1's l1: 0.371157\n",
      "[1700]\ttraining's l1: 0.0410969\tvalid_1's l1: 0.370883\n",
      "[1800]\ttraining's l1: 0.0382381\tvalid_1's l1: 0.370586\n",
      "[1900]\ttraining's l1: 0.0356506\tvalid_1's l1: 0.370413\n",
      "[2000]\ttraining's l1: 0.0333383\tvalid_1's l1: 0.370072\n",
      "[2100]\ttraining's l1: 0.0312498\tvalid_1's l1: 0.369899\n",
      "[2200]\ttraining's l1: 0.0294043\tvalid_1's l1: 0.369733\n",
      "[2300]\ttraining's l1: 0.0276603\tvalid_1's l1: 0.369606\n",
      "[2400]\ttraining's l1: 0.0261201\tvalid_1's l1: 0.369572\n",
      "[2500]\ttraining's l1: 0.0246838\tvalid_1's l1: 0.369498\n",
      "[2600]\ttraining's l1: 0.0233911\tvalid_1's l1: 0.36939\n",
      "[2700]\ttraining's l1: 0.0221805\tvalid_1's l1: 0.369299\n",
      "[2800]\ttraining's l1: 0.0210845\tvalid_1's l1: 0.369196\n",
      "[2900]\ttraining's l1: 0.0200723\tvalid_1's l1: 0.36912\n",
      "[3000]\ttraining's l1: 0.0191173\tvalid_1's l1: 0.369061\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0191173\tvalid_1's l1: 0.369061\n",
      "1JHN Fold 2, logMAE: -0.99679395010422\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.318835\tvalid_1's l1: 0.443525\n",
      "[200]\ttraining's l1: 0.234839\tvalid_1's l1: 0.407762\n",
      "[300]\ttraining's l1: 0.18854\tvalid_1's l1: 0.392389\n",
      "[400]\ttraining's l1: 0.157307\tvalid_1's l1: 0.383399\n",
      "[500]\ttraining's l1: 0.13416\tvalid_1's l1: 0.377591\n",
      "[600]\ttraining's l1: 0.116442\tvalid_1's l1: 0.37375\n",
      "[700]\ttraining's l1: 0.102572\tvalid_1's l1: 0.371325\n",
      "[800]\ttraining's l1: 0.091221\tvalid_1's l1: 0.36934\n",
      "[900]\ttraining's l1: 0.0818193\tvalid_1's l1: 0.3676\n",
      "[1000]\ttraining's l1: 0.0736955\tvalid_1's l1: 0.36658\n",
      "[1100]\ttraining's l1: 0.0668943\tvalid_1's l1: 0.365389\n",
      "[1200]\ttraining's l1: 0.0611258\tvalid_1's l1: 0.364587\n",
      "[1300]\ttraining's l1: 0.0559833\tvalid_1's l1: 0.363857\n",
      "[1400]\ttraining's l1: 0.0514875\tvalid_1's l1: 0.363163\n",
      "[1500]\ttraining's l1: 0.0475535\tvalid_1's l1: 0.362697\n",
      "[1600]\ttraining's l1: 0.0440068\tvalid_1's l1: 0.362117\n",
      "[1700]\ttraining's l1: 0.0409094\tvalid_1's l1: 0.361806\n",
      "[1800]\ttraining's l1: 0.0381061\tvalid_1's l1: 0.361431\n",
      "[1900]\ttraining's l1: 0.0356019\tvalid_1's l1: 0.36121\n",
      "[2000]\ttraining's l1: 0.0333598\tvalid_1's l1: 0.361028\n",
      "[2100]\ttraining's l1: 0.0313008\tvalid_1's l1: 0.360907\n",
      "[2200]\ttraining's l1: 0.0294655\tvalid_1's l1: 0.36073\n",
      "[2300]\ttraining's l1: 0.0277762\tvalid_1's l1: 0.360642\n",
      "[2400]\ttraining's l1: 0.0262318\tvalid_1's l1: 0.360493\n",
      "[2500]\ttraining's l1: 0.0248422\tvalid_1's l1: 0.360484\n",
      "[2600]\ttraining's l1: 0.023554\tvalid_1's l1: 0.360452\n",
      "[2700]\ttraining's l1: 0.0223751\tvalid_1's l1: 0.360374\n",
      "[2800]\ttraining's l1: 0.0212829\tvalid_1's l1: 0.360264\n",
      "[2900]\ttraining's l1: 0.0202535\tvalid_1's l1: 0.360169\n",
      "[3000]\ttraining's l1: 0.0193098\tvalid_1's l1: 0.360071\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0193098\tvalid_1's l1: 0.360071\n",
      "1JHN Fold 3, logMAE: -1.0214537364135359\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.320513\tvalid_1's l1: 0.457909\n",
      "[200]\ttraining's l1: 0.237559\tvalid_1's l1: 0.419215\n",
      "[300]\ttraining's l1: 0.190021\tvalid_1's l1: 0.403693\n",
      "[400]\ttraining's l1: 0.15835\tvalid_1's l1: 0.395264\n",
      "[500]\ttraining's l1: 0.135316\tvalid_1's l1: 0.389417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttraining's l1: 0.117618\tvalid_1's l1: 0.385725\n",
      "[700]\ttraining's l1: 0.103641\tvalid_1's l1: 0.383031\n",
      "[800]\ttraining's l1: 0.092285\tvalid_1's l1: 0.381301\n",
      "[900]\ttraining's l1: 0.0829065\tvalid_1's l1: 0.379605\n",
      "[1000]\ttraining's l1: 0.0749165\tvalid_1's l1: 0.378181\n",
      "[1100]\ttraining's l1: 0.0680995\tvalid_1's l1: 0.377211\n",
      "[1200]\ttraining's l1: 0.0621036\tvalid_1's l1: 0.376236\n",
      "[1300]\ttraining's l1: 0.056958\tvalid_1's l1: 0.37564\n",
      "[1400]\ttraining's l1: 0.0524324\tvalid_1's l1: 0.375175\n",
      "[1500]\ttraining's l1: 0.0485381\tvalid_1's l1: 0.37468\n",
      "[1600]\ttraining's l1: 0.0449936\tvalid_1's l1: 0.374166\n",
      "[1700]\ttraining's l1: 0.0418165\tvalid_1's l1: 0.373782\n",
      "[1800]\ttraining's l1: 0.0390199\tvalid_1's l1: 0.373718\n",
      "[1900]\ttraining's l1: 0.0364904\tvalid_1's l1: 0.373304\n",
      "[2000]\ttraining's l1: 0.0342112\tvalid_1's l1: 0.373177\n",
      "[2100]\ttraining's l1: 0.0321273\tvalid_1's l1: 0.373012\n",
      "[2200]\ttraining's l1: 0.030228\tvalid_1's l1: 0.372931\n",
      "[2300]\ttraining's l1: 0.0285463\tvalid_1's l1: 0.372818\n",
      "[2400]\ttraining's l1: 0.026973\tvalid_1's l1: 0.372643\n",
      "[2500]\ttraining's l1: 0.0255753\tvalid_1's l1: 0.372629\n",
      "[2600]\ttraining's l1: 0.0242314\tvalid_1's l1: 0.372401\n",
      "[2700]\ttraining's l1: 0.0230195\tvalid_1's l1: 0.372263\n",
      "[2800]\ttraining's l1: 0.0219227\tvalid_1's l1: 0.372123\n",
      "[2900]\ttraining's l1: 0.0208828\tvalid_1's l1: 0.372023\n",
      "[3000]\ttraining's l1: 0.0199051\tvalid_1's l1: 0.37197\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0199051\tvalid_1's l1: 0.37197\n",
      "1JHN Fold 4, logMAE: -0.9889411228952919\n",
      "*** Training Model for 1JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 1.12564\tvalid_1's l1: 1.17892\n",
      "[200]\ttraining's l1: 0.960007\tvalid_1's l1: 1.04737\n",
      "[300]\ttraining's l1: 0.865363\tvalid_1's l1: 0.979846\n",
      "[400]\ttraining's l1: 0.797529\tvalid_1's l1: 0.934776\n",
      "[500]\ttraining's l1: 0.745119\tvalid_1's l1: 0.902089\n",
      "[600]\ttraining's l1: 0.700449\tvalid_1's l1: 0.876338\n",
      "[700]\ttraining's l1: 0.663431\tvalid_1's l1: 0.856291\n",
      "[800]\ttraining's l1: 0.630619\tvalid_1's l1: 0.839095\n",
      "[900]\ttraining's l1: 0.603032\tvalid_1's l1: 0.825446\n",
      "[1000]\ttraining's l1: 0.578238\tvalid_1's l1: 0.813338\n",
      "[1100]\ttraining's l1: 0.555574\tvalid_1's l1: 0.80271\n",
      "[1200]\ttraining's l1: 0.534978\tvalid_1's l1: 0.794008\n",
      "[1300]\ttraining's l1: 0.516092\tvalid_1's l1: 0.78613\n",
      "[1400]\ttraining's l1: 0.498861\tvalid_1's l1: 0.7787\n",
      "[1500]\ttraining's l1: 0.483222\tvalid_1's l1: 0.771973\n",
      "[1600]\ttraining's l1: 0.468591\tvalid_1's l1: 0.766438\n",
      "[1700]\ttraining's l1: 0.453833\tvalid_1's l1: 0.760804\n",
      "[1800]\ttraining's l1: 0.440884\tvalid_1's l1: 0.755743\n",
      "[1900]\ttraining's l1: 0.428567\tvalid_1's l1: 0.751477\n",
      "[2000]\ttraining's l1: 0.416881\tvalid_1's l1: 0.747269\n",
      "[2100]\ttraining's l1: 0.40568\tvalid_1's l1: 0.743314\n",
      "[2200]\ttraining's l1: 0.395214\tvalid_1's l1: 0.73966\n",
      "[2300]\ttraining's l1: 0.38515\tvalid_1's l1: 0.736098\n",
      "[2400]\ttraining's l1: 0.37558\tvalid_1's l1: 0.732901\n",
      "[2500]\ttraining's l1: 0.36629\tvalid_1's l1: 0.729837\n",
      "[2600]\ttraining's l1: 0.357258\tvalid_1's l1: 0.726874\n",
      "[2700]\ttraining's l1: 0.348963\tvalid_1's l1: 0.724193\n",
      "[2800]\ttraining's l1: 0.341011\tvalid_1's l1: 0.721768\n",
      "[2900]\ttraining's l1: 0.33313\tvalid_1's l1: 0.719486\n",
      "[3000]\ttraining's l1: 0.325938\tvalid_1's l1: 0.717233\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.325938\tvalid_1's l1: 0.717233\n",
      "1JHC Fold 0, logMAE: -0.33235425787861184\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 1.12363\tvalid_1's l1: 1.17217\n",
      "[200]\ttraining's l1: 0.963427\tvalid_1's l1: 1.04546\n",
      "[300]\ttraining's l1: 0.866887\tvalid_1's l1: 0.97605\n",
      "[400]\ttraining's l1: 0.800052\tvalid_1's l1: 0.932257\n",
      "[500]\ttraining's l1: 0.745765\tvalid_1's l1: 0.898167\n",
      "[600]\ttraining's l1: 0.70264\tvalid_1's l1: 0.872974\n",
      "[700]\ttraining's l1: 0.665797\tvalid_1's l1: 0.85278\n",
      "[800]\ttraining's l1: 0.634295\tvalid_1's l1: 0.835813\n",
      "[900]\ttraining's l1: 0.606088\tvalid_1's l1: 0.821861\n",
      "[1000]\ttraining's l1: 0.581223\tvalid_1's l1: 0.809844\n",
      "[1100]\ttraining's l1: 0.558359\tvalid_1's l1: 0.799328\n",
      "[1200]\ttraining's l1: 0.537901\tvalid_1's l1: 0.7902\n",
      "[1300]\ttraining's l1: 0.518617\tvalid_1's l1: 0.781561\n",
      "[1400]\ttraining's l1: 0.501759\tvalid_1's l1: 0.774763\n",
      "[1500]\ttraining's l1: 0.485778\tvalid_1's l1: 0.76824\n",
      "[1600]\ttraining's l1: 0.470805\tvalid_1's l1: 0.762374\n",
      "[1700]\ttraining's l1: 0.456913\tvalid_1's l1: 0.757046\n",
      "[1800]\ttraining's l1: 0.443406\tvalid_1's l1: 0.75158\n",
      "[1900]\ttraining's l1: 0.430696\tvalid_1's l1: 0.746488\n",
      "[2000]\ttraining's l1: 0.418705\tvalid_1's l1: 0.742192\n",
      "[2100]\ttraining's l1: 0.407754\tvalid_1's l1: 0.738431\n",
      "[2200]\ttraining's l1: 0.397178\tvalid_1's l1: 0.734974\n",
      "[2300]\ttraining's l1: 0.386843\tvalid_1's l1: 0.731491\n",
      "[2400]\ttraining's l1: 0.377014\tvalid_1's l1: 0.728289\n",
      "[2500]\ttraining's l1: 0.367949\tvalid_1's l1: 0.72548\n",
      "[2600]\ttraining's l1: 0.359367\tvalid_1's l1: 0.722763\n",
      "[2700]\ttraining's l1: 0.350864\tvalid_1's l1: 0.720053\n",
      "[2800]\ttraining's l1: 0.342697\tvalid_1's l1: 0.717477\n",
      "[2900]\ttraining's l1: 0.334849\tvalid_1's l1: 0.715212\n",
      "[3000]\ttraining's l1: 0.327388\tvalid_1's l1: 0.712865\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.327388\tvalid_1's l1: 0.712865\n",
      "1JHC Fold 1, logMAE: -0.3384633799164262\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 1.12778\tvalid_1's l1: 1.18174\n",
      "[200]\ttraining's l1: 0.96377\tvalid_1's l1: 1.05196\n",
      "[300]\ttraining's l1: 0.867316\tvalid_1's l1: 0.983658\n",
      "[400]\ttraining's l1: 0.7985\tvalid_1's l1: 0.936388\n",
      "[500]\ttraining's l1: 0.746199\tvalid_1's l1: 0.904555\n",
      "[600]\ttraining's l1: 0.701835\tvalid_1's l1: 0.878529\n",
      "[700]\ttraining's l1: 0.664249\tvalid_1's l1: 0.857675\n",
      "[800]\ttraining's l1: 0.633644\tvalid_1's l1: 0.84234\n",
      "[900]\ttraining's l1: 0.60503\tvalid_1's l1: 0.82821\n",
      "[1000]\ttraining's l1: 0.580538\tvalid_1's l1: 0.816231\n",
      "[1100]\ttraining's l1: 0.55783\tvalid_1's l1: 0.805652\n",
      "[1200]\ttraining's l1: 0.536755\tvalid_1's l1: 0.796596\n",
      "[1300]\ttraining's l1: 0.5176\tvalid_1's l1: 0.788179\n",
      "[1400]\ttraining's l1: 0.499983\tvalid_1's l1: 0.781042\n",
      "[1500]\ttraining's l1: 0.484142\tvalid_1's l1: 0.774568\n",
      "[1600]\ttraining's l1: 0.469065\tvalid_1's l1: 0.768665\n",
      "[1700]\ttraining's l1: 0.455462\tvalid_1's l1: 0.763234\n",
      "[1800]\ttraining's l1: 0.442307\tvalid_1's l1: 0.758257\n",
      "[1900]\ttraining's l1: 0.429788\tvalid_1's l1: 0.753478\n",
      "[2000]\ttraining's l1: 0.417692\tvalid_1's l1: 0.749073\n",
      "[2100]\ttraining's l1: 0.40681\tvalid_1's l1: 0.745311\n",
      "[2200]\ttraining's l1: 0.396179\tvalid_1's l1: 0.741376\n",
      "[2300]\ttraining's l1: 0.386124\tvalid_1's l1: 0.737821\n",
      "[2400]\ttraining's l1: 0.376681\tvalid_1's l1: 0.734834\n",
      "[2500]\ttraining's l1: 0.367299\tvalid_1's l1: 0.731798\n",
      "[2600]\ttraining's l1: 0.358535\tvalid_1's l1: 0.728906\n",
      "[2700]\ttraining's l1: 0.350282\tvalid_1's l1: 0.726435\n",
      "[2800]\ttraining's l1: 0.342284\tvalid_1's l1: 0.723916\n",
      "[2900]\ttraining's l1: 0.334266\tvalid_1's l1: 0.721195\n",
      "[3000]\ttraining's l1: 0.326922\tvalid_1's l1: 0.719048\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.326922\tvalid_1's l1: 0.719048\n",
      "1JHC Fold 2, logMAE: -0.32982737698396664\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 1.12558\tvalid_1's l1: 1.18451\n",
      "[200]\ttraining's l1: 0.964532\tvalid_1's l1: 1.05461\n",
      "[300]\ttraining's l1: 0.866773\tvalid_1's l1: 0.983254\n",
      "[400]\ttraining's l1: 0.797936\tvalid_1's l1: 0.936934\n",
      "[500]\ttraining's l1: 0.744611\tvalid_1's l1: 0.903948\n",
      "[600]\ttraining's l1: 0.701009\tvalid_1's l1: 0.878598\n",
      "[700]\ttraining's l1: 0.664551\tvalid_1's l1: 0.857699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800]\ttraining's l1: 0.634039\tvalid_1's l1: 0.841631\n",
      "[900]\ttraining's l1: 0.607013\tvalid_1's l1: 0.827973\n",
      "[1000]\ttraining's l1: 0.581883\tvalid_1's l1: 0.815746\n",
      "[1100]\ttraining's l1: 0.55921\tvalid_1's l1: 0.805063\n",
      "[1200]\ttraining's l1: 0.538553\tvalid_1's l1: 0.795723\n",
      "[1300]\ttraining's l1: 0.519433\tvalid_1's l1: 0.787333\n",
      "[1400]\ttraining's l1: 0.501918\tvalid_1's l1: 0.779527\n",
      "[1500]\ttraining's l1: 0.485965\tvalid_1's l1: 0.772603\n",
      "[1600]\ttraining's l1: 0.470462\tvalid_1's l1: 0.766181\n",
      "[1700]\ttraining's l1: 0.45614\tvalid_1's l1: 0.760846\n",
      "[1800]\ttraining's l1: 0.443132\tvalid_1's l1: 0.755796\n",
      "[1900]\ttraining's l1: 0.43042\tvalid_1's l1: 0.7509\n",
      "[2000]\ttraining's l1: 0.418543\tvalid_1's l1: 0.746675\n",
      "[2100]\ttraining's l1: 0.407051\tvalid_1's l1: 0.742343\n",
      "[2200]\ttraining's l1: 0.396427\tvalid_1's l1: 0.73869\n",
      "[2300]\ttraining's l1: 0.386545\tvalid_1's l1: 0.735346\n",
      "[2400]\ttraining's l1: 0.376934\tvalid_1's l1: 0.732027\n",
      "[2500]\ttraining's l1: 0.367659\tvalid_1's l1: 0.729009\n",
      "[2600]\ttraining's l1: 0.358775\tvalid_1's l1: 0.72625\n",
      "[2700]\ttraining's l1: 0.350296\tvalid_1's l1: 0.723673\n",
      "[2800]\ttraining's l1: 0.342118\tvalid_1's l1: 0.720954\n",
      "[2900]\ttraining's l1: 0.334428\tvalid_1's l1: 0.718626\n",
      "[3000]\ttraining's l1: 0.326953\tvalid_1's l1: 0.716359\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.326953\tvalid_1's l1: 0.716359\n",
      "1JHC Fold 3, logMAE: -0.3335732521026938\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 1.11999\tvalid_1's l1: 1.17882\n",
      "[200]\ttraining's l1: 0.959206\tvalid_1's l1: 1.05095\n",
      "[300]\ttraining's l1: 0.862075\tvalid_1's l1: 0.979682\n",
      "[400]\ttraining's l1: 0.797139\tvalid_1's l1: 0.936071\n",
      "[500]\ttraining's l1: 0.743488\tvalid_1's l1: 0.902533\n",
      "[600]\ttraining's l1: 0.699378\tvalid_1's l1: 0.875909\n",
      "[700]\ttraining's l1: 0.662834\tvalid_1's l1: 0.856107\n",
      "[800]\ttraining's l1: 0.632262\tvalid_1's l1: 0.840129\n",
      "[900]\ttraining's l1: 0.603664\tvalid_1's l1: 0.825275\n",
      "[1000]\ttraining's l1: 0.578719\tvalid_1's l1: 0.812691\n",
      "[1100]\ttraining's l1: 0.555917\tvalid_1's l1: 0.801961\n",
      "[1200]\ttraining's l1: 0.535214\tvalid_1's l1: 0.792521\n",
      "[1300]\ttraining's l1: 0.516628\tvalid_1's l1: 0.784688\n",
      "[1400]\ttraining's l1: 0.499412\tvalid_1's l1: 0.776877\n",
      "[1500]\ttraining's l1: 0.483005\tvalid_1's l1: 0.76997\n",
      "[1600]\ttraining's l1: 0.46771\tvalid_1's l1: 0.763664\n",
      "[1700]\ttraining's l1: 0.453202\tvalid_1's l1: 0.758024\n",
      "[1800]\ttraining's l1: 0.440122\tvalid_1's l1: 0.753049\n",
      "[1900]\ttraining's l1: 0.427644\tvalid_1's l1: 0.74834\n",
      "[2000]\ttraining's l1: 0.416112\tvalid_1's l1: 0.744358\n",
      "[2100]\ttraining's l1: 0.405117\tvalid_1's l1: 0.740261\n",
      "[2200]\ttraining's l1: 0.394615\tvalid_1's l1: 0.736556\n",
      "[2300]\ttraining's l1: 0.384665\tvalid_1's l1: 0.733107\n",
      "[2400]\ttraining's l1: 0.374848\tvalid_1's l1: 0.729751\n",
      "[2500]\ttraining's l1: 0.365518\tvalid_1's l1: 0.726652\n",
      "[2600]\ttraining's l1: 0.356867\tvalid_1's l1: 0.72383\n",
      "[2700]\ttraining's l1: 0.348644\tvalid_1's l1: 0.721424\n",
      "[2800]\ttraining's l1: 0.34059\tvalid_1's l1: 0.718871\n",
      "[2900]\ttraining's l1: 0.332686\tvalid_1's l1: 0.71622\n",
      "[3000]\ttraining's l1: 0.325085\tvalid_1's l1: 0.713851\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.325085\tvalid_1's l1: 0.713851\n",
      "1JHC Fold 4, logMAE: -0.33708043122190395\n",
      "*** Training Model for 2JHH ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.237113\tvalid_1's l1: 0.263903\n",
      "[200]\ttraining's l1: 0.193099\tvalid_1's l1: 0.232058\n",
      "[300]\ttraining's l1: 0.168377\tvalid_1's l1: 0.216717\n",
      "[400]\ttraining's l1: 0.151398\tvalid_1's l1: 0.207093\n",
      "[500]\ttraining's l1: 0.138321\tvalid_1's l1: 0.200486\n",
      "[600]\ttraining's l1: 0.127973\tvalid_1's l1: 0.195539\n",
      "[700]\ttraining's l1: 0.119231\tvalid_1's l1: 0.191543\n",
      "[800]\ttraining's l1: 0.111927\tvalid_1's l1: 0.188432\n",
      "[900]\ttraining's l1: 0.105327\tvalid_1's l1: 0.185768\n",
      "[1000]\ttraining's l1: 0.0995776\tvalid_1's l1: 0.183581\n",
      "[1100]\ttraining's l1: 0.0943901\tvalid_1's l1: 0.181555\n",
      "[1200]\ttraining's l1: 0.0896984\tvalid_1's l1: 0.179984\n",
      "[1300]\ttraining's l1: 0.0854898\tvalid_1's l1: 0.178582\n",
      "[1400]\ttraining's l1: 0.0816293\tvalid_1's l1: 0.177301\n",
      "[1500]\ttraining's l1: 0.0780406\tvalid_1's l1: 0.176099\n",
      "[1600]\ttraining's l1: 0.0746756\tvalid_1's l1: 0.175137\n",
      "[1700]\ttraining's l1: 0.0716732\tvalid_1's l1: 0.174262\n",
      "[1800]\ttraining's l1: 0.0688841\tvalid_1's l1: 0.173474\n",
      "[1900]\ttraining's l1: 0.0662724\tvalid_1's l1: 0.172684\n",
      "[2000]\ttraining's l1: 0.0637741\tvalid_1's l1: 0.171957\n",
      "[2100]\ttraining's l1: 0.0615014\tvalid_1's l1: 0.171317\n",
      "[2200]\ttraining's l1: 0.0593103\tvalid_1's l1: 0.170792\n",
      "[2300]\ttraining's l1: 0.0572596\tvalid_1's l1: 0.170332\n",
      "[2400]\ttraining's l1: 0.0553341\tvalid_1's l1: 0.169837\n",
      "[2500]\ttraining's l1: 0.0535052\tvalid_1's l1: 0.169407\n",
      "[2600]\ttraining's l1: 0.0517686\tvalid_1's l1: 0.169015\n",
      "[2700]\ttraining's l1: 0.0501089\tvalid_1's l1: 0.1686\n",
      "[2800]\ttraining's l1: 0.0485478\tvalid_1's l1: 0.168249\n",
      "[2900]\ttraining's l1: 0.0470699\tvalid_1's l1: 0.167931\n",
      "[3000]\ttraining's l1: 0.0456367\tvalid_1's l1: 0.167588\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0456367\tvalid_1's l1: 0.167588\n",
      "2JHH Fold 0, logMAE: -1.7862454734876834\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.238515\tvalid_1's l1: 0.263201\n",
      "[200]\ttraining's l1: 0.194304\tvalid_1's l1: 0.231381\n",
      "[300]\ttraining's l1: 0.169987\tvalid_1's l1: 0.216449\n",
      "[400]\ttraining's l1: 0.152632\tvalid_1's l1: 0.206709\n",
      "[500]\ttraining's l1: 0.139402\tvalid_1's l1: 0.199981\n",
      "[600]\ttraining's l1: 0.128816\tvalid_1's l1: 0.194991\n",
      "[700]\ttraining's l1: 0.120073\tvalid_1's l1: 0.19096\n",
      "[800]\ttraining's l1: 0.11254\tvalid_1's l1: 0.187949\n",
      "[900]\ttraining's l1: 0.105873\tvalid_1's l1: 0.185033\n",
      "[1000]\ttraining's l1: 0.0998941\tvalid_1's l1: 0.18265\n",
      "[1100]\ttraining's l1: 0.0946518\tvalid_1's l1: 0.180657\n",
      "[1200]\ttraining's l1: 0.0900022\tvalid_1's l1: 0.179041\n",
      "[1300]\ttraining's l1: 0.0858251\tvalid_1's l1: 0.177579\n",
      "[1400]\ttraining's l1: 0.0819004\tvalid_1's l1: 0.176282\n",
      "[1500]\ttraining's l1: 0.0783111\tvalid_1's l1: 0.175033\n",
      "[1600]\ttraining's l1: 0.0750164\tvalid_1's l1: 0.174119\n",
      "[1700]\ttraining's l1: 0.0719348\tvalid_1's l1: 0.173125\n",
      "[1800]\ttraining's l1: 0.069017\tvalid_1's l1: 0.172229\n",
      "[1900]\ttraining's l1: 0.0664037\tvalid_1's l1: 0.1715\n",
      "[2000]\ttraining's l1: 0.0639041\tvalid_1's l1: 0.170741\n",
      "[2100]\ttraining's l1: 0.0615987\tvalid_1's l1: 0.170078\n",
      "[2200]\ttraining's l1: 0.0593614\tvalid_1's l1: 0.169436\n",
      "[2300]\ttraining's l1: 0.057385\tvalid_1's l1: 0.168921\n",
      "[2400]\ttraining's l1: 0.055443\tvalid_1's l1: 0.168482\n",
      "[2500]\ttraining's l1: 0.053605\tvalid_1's l1: 0.167981\n",
      "[2600]\ttraining's l1: 0.051844\tvalid_1's l1: 0.167526\n",
      "[2700]\ttraining's l1: 0.0502416\tvalid_1's l1: 0.167167\n",
      "[2800]\ttraining's l1: 0.0486628\tvalid_1's l1: 0.166783\n",
      "[2900]\ttraining's l1: 0.0471364\tvalid_1's l1: 0.166395\n",
      "[3000]\ttraining's l1: 0.0456655\tvalid_1's l1: 0.16601\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0456655\tvalid_1's l1: 0.16601\n",
      "2JHH Fold 1, logMAE: -1.7957082186373619\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.238822\tvalid_1's l1: 0.264009\n",
      "[200]\ttraining's l1: 0.193963\tvalid_1's l1: 0.231482\n",
      "[300]\ttraining's l1: 0.169193\tvalid_1's l1: 0.21566\n",
      "[400]\ttraining's l1: 0.15236\tvalid_1's l1: 0.206409\n",
      "[500]\ttraining's l1: 0.139631\tvalid_1's l1: 0.20016\n",
      "[600]\ttraining's l1: 0.128965\tvalid_1's l1: 0.194852\n",
      "[700]\ttraining's l1: 0.12039\tvalid_1's l1: 0.191114\n",
      "[800]\ttraining's l1: 0.112744\tvalid_1's l1: 0.188057\n",
      "[900]\ttraining's l1: 0.106049\tvalid_1's l1: 0.185279\n",
      "[1000]\ttraining's l1: 0.100243\tvalid_1's l1: 0.183094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1100]\ttraining's l1: 0.0950467\tvalid_1's l1: 0.181263\n",
      "[1200]\ttraining's l1: 0.0903971\tvalid_1's l1: 0.179641\n",
      "[1300]\ttraining's l1: 0.0861781\tvalid_1's l1: 0.178093\n",
      "[1400]\ttraining's l1: 0.0822195\tvalid_1's l1: 0.176856\n",
      "[1500]\ttraining's l1: 0.0786571\tvalid_1's l1: 0.175649\n",
      "[1600]\ttraining's l1: 0.0752936\tvalid_1's l1: 0.174592\n",
      "[1700]\ttraining's l1: 0.0722023\tvalid_1's l1: 0.173657\n",
      "[1800]\ttraining's l1: 0.0692761\tvalid_1's l1: 0.172795\n",
      "[1900]\ttraining's l1: 0.0666294\tvalid_1's l1: 0.172059\n",
      "[2000]\ttraining's l1: 0.0641023\tvalid_1's l1: 0.171345\n",
      "[2100]\ttraining's l1: 0.0618268\tvalid_1's l1: 0.170728\n",
      "[2200]\ttraining's l1: 0.0595946\tvalid_1's l1: 0.170155\n",
      "[2300]\ttraining's l1: 0.0575505\tvalid_1's l1: 0.169609\n",
      "[2400]\ttraining's l1: 0.0556437\tvalid_1's l1: 0.169154\n",
      "[2500]\ttraining's l1: 0.0537717\tvalid_1's l1: 0.168691\n",
      "[2600]\ttraining's l1: 0.0520322\tvalid_1's l1: 0.168273\n",
      "[2700]\ttraining's l1: 0.0503851\tvalid_1's l1: 0.16793\n",
      "[2800]\ttraining's l1: 0.048814\tvalid_1's l1: 0.167563\n",
      "[2900]\ttraining's l1: 0.0472895\tvalid_1's l1: 0.167254\n",
      "[3000]\ttraining's l1: 0.0458811\tvalid_1's l1: 0.166915\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0458811\tvalid_1's l1: 0.166915\n",
      "2JHH Fold 2, logMAE: -1.7902733633542582\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.237781\tvalid_1's l1: 0.263032\n",
      "[200]\ttraining's l1: 0.194284\tvalid_1's l1: 0.232078\n",
      "[300]\ttraining's l1: 0.170052\tvalid_1's l1: 0.216959\n",
      "[400]\ttraining's l1: 0.152481\tvalid_1's l1: 0.207099\n",
      "[500]\ttraining's l1: 0.139445\tvalid_1's l1: 0.200197\n",
      "[600]\ttraining's l1: 0.12904\tvalid_1's l1: 0.195293\n",
      "[700]\ttraining's l1: 0.120203\tvalid_1's l1: 0.191414\n",
      "[800]\ttraining's l1: 0.112622\tvalid_1's l1: 0.188126\n",
      "[900]\ttraining's l1: 0.10613\tvalid_1's l1: 0.185535\n",
      "[1000]\ttraining's l1: 0.100318\tvalid_1's l1: 0.183168\n",
      "[1100]\ttraining's l1: 0.0951025\tvalid_1's l1: 0.181235\n",
      "[1200]\ttraining's l1: 0.0904527\tvalid_1's l1: 0.179584\n",
      "[1300]\ttraining's l1: 0.086146\tvalid_1's l1: 0.178103\n",
      "[1400]\ttraining's l1: 0.0823009\tvalid_1's l1: 0.176883\n",
      "[1500]\ttraining's l1: 0.0787291\tvalid_1's l1: 0.175755\n",
      "[1600]\ttraining's l1: 0.0753919\tvalid_1's l1: 0.17477\n",
      "[1700]\ttraining's l1: 0.0722786\tvalid_1's l1: 0.173833\n",
      "[1800]\ttraining's l1: 0.0694265\tvalid_1's l1: 0.173048\n",
      "[1900]\ttraining's l1: 0.0666867\tvalid_1's l1: 0.172315\n",
      "[2000]\ttraining's l1: 0.0641333\tvalid_1's l1: 0.17163\n",
      "[2100]\ttraining's l1: 0.061771\tvalid_1's l1: 0.170994\n",
      "[2200]\ttraining's l1: 0.0596231\tvalid_1's l1: 0.170441\n",
      "[2300]\ttraining's l1: 0.0575934\tvalid_1's l1: 0.16998\n",
      "[2400]\ttraining's l1: 0.055586\tvalid_1's l1: 0.169489\n",
      "[2500]\ttraining's l1: 0.0537851\tvalid_1's l1: 0.169041\n",
      "[2600]\ttraining's l1: 0.0520189\tvalid_1's l1: 0.168613\n",
      "[2700]\ttraining's l1: 0.05035\tvalid_1's l1: 0.168205\n",
      "[2800]\ttraining's l1: 0.0487224\tvalid_1's l1: 0.167816\n",
      "[2900]\ttraining's l1: 0.0472064\tvalid_1's l1: 0.167464\n",
      "[3000]\ttraining's l1: 0.045815\tvalid_1's l1: 0.167139\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.045815\tvalid_1's l1: 0.167139\n",
      "2JHH Fold 3, logMAE: -1.7889309067727817\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.237812\tvalid_1's l1: 0.26277\n",
      "[200]\ttraining's l1: 0.193608\tvalid_1's l1: 0.230869\n",
      "[300]\ttraining's l1: 0.169481\tvalid_1's l1: 0.215735\n",
      "[400]\ttraining's l1: 0.152424\tvalid_1's l1: 0.206103\n",
      "[500]\ttraining's l1: 0.139433\tvalid_1's l1: 0.199385\n",
      "[600]\ttraining's l1: 0.128839\tvalid_1's l1: 0.194442\n",
      "[700]\ttraining's l1: 0.119794\tvalid_1's l1: 0.190368\n",
      "[800]\ttraining's l1: 0.112235\tvalid_1's l1: 0.187051\n",
      "[900]\ttraining's l1: 0.105706\tvalid_1's l1: 0.18437\n",
      "[1000]\ttraining's l1: 0.0999451\tvalid_1's l1: 0.182082\n",
      "[1100]\ttraining's l1: 0.0947167\tvalid_1's l1: 0.180103\n",
      "[1200]\ttraining's l1: 0.0899889\tvalid_1's l1: 0.178437\n",
      "[1300]\ttraining's l1: 0.0857323\tvalid_1's l1: 0.177035\n",
      "[1400]\ttraining's l1: 0.0818601\tvalid_1's l1: 0.175737\n",
      "[1500]\ttraining's l1: 0.078244\tvalid_1's l1: 0.174509\n",
      "[1600]\ttraining's l1: 0.0749249\tvalid_1's l1: 0.173518\n",
      "[1700]\ttraining's l1: 0.0719157\tvalid_1's l1: 0.172646\n",
      "[1800]\ttraining's l1: 0.0691324\tvalid_1's l1: 0.171835\n",
      "[1900]\ttraining's l1: 0.0664697\tvalid_1's l1: 0.171103\n",
      "[2000]\ttraining's l1: 0.063976\tvalid_1's l1: 0.170398\n",
      "[2100]\ttraining's l1: 0.0615658\tvalid_1's l1: 0.169741\n",
      "[2200]\ttraining's l1: 0.0594666\tvalid_1's l1: 0.169226\n",
      "[2300]\ttraining's l1: 0.057403\tvalid_1's l1: 0.168654\n",
      "[2400]\ttraining's l1: 0.0554459\tvalid_1's l1: 0.16813\n",
      "[2500]\ttraining's l1: 0.0535782\tvalid_1's l1: 0.167687\n",
      "[2600]\ttraining's l1: 0.0518245\tvalid_1's l1: 0.167255\n",
      "[2700]\ttraining's l1: 0.0501588\tvalid_1's l1: 0.166853\n",
      "[2800]\ttraining's l1: 0.0485497\tvalid_1's l1: 0.166469\n",
      "[2900]\ttraining's l1: 0.0470291\tvalid_1's l1: 0.16615\n",
      "[3000]\ttraining's l1: 0.0456125\tvalid_1's l1: 0.165866\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0456125\tvalid_1's l1: 0.165866\n",
      "2JHH Fold 4, logMAE: -1.7965749709387564\n",
      "*** Training Model for 2JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.165668\tvalid_1's l1: 0.202556\n",
      "[200]\ttraining's l1: 0.12691\tvalid_1's l1: 0.177654\n",
      "[300]\ttraining's l1: 0.105336\tvalid_1's l1: 0.16606\n",
      "[400]\ttraining's l1: 0.0909526\tvalid_1's l1: 0.159414\n",
      "[500]\ttraining's l1: 0.0800983\tvalid_1's l1: 0.154813\n",
      "[600]\ttraining's l1: 0.0717457\tvalid_1's l1: 0.151605\n",
      "[700]\ttraining's l1: 0.0648745\tvalid_1's l1: 0.149242\n",
      "[800]\ttraining's l1: 0.0592149\tvalid_1's l1: 0.147318\n",
      "[900]\ttraining's l1: 0.054349\tvalid_1's l1: 0.14573\n",
      "[1000]\ttraining's l1: 0.0502045\tvalid_1's l1: 0.14451\n",
      "[1100]\ttraining's l1: 0.0465177\tvalid_1's l1: 0.14341\n",
      "[1200]\ttraining's l1: 0.0432419\tvalid_1's l1: 0.142642\n",
      "[1300]\ttraining's l1: 0.0403536\tvalid_1's l1: 0.141875\n",
      "[1400]\ttraining's l1: 0.0377462\tvalid_1's l1: 0.141189\n",
      "[1500]\ttraining's l1: 0.0354351\tvalid_1's l1: 0.140634\n",
      "[1600]\ttraining's l1: 0.0333751\tvalid_1's l1: 0.140164\n",
      "[1700]\ttraining's l1: 0.031553\tvalid_1's l1: 0.139713\n",
      "[1800]\ttraining's l1: 0.0298315\tvalid_1's l1: 0.139326\n",
      "[1900]\ttraining's l1: 0.0282428\tvalid_1's l1: 0.139001\n",
      "[2000]\ttraining's l1: 0.0267749\tvalid_1's l1: 0.138714\n",
      "[2100]\ttraining's l1: 0.0254701\tvalid_1's l1: 0.13845\n",
      "[2200]\ttraining's l1: 0.0242579\tvalid_1's l1: 0.138166\n",
      "[2300]\ttraining's l1: 0.0231349\tvalid_1's l1: 0.137952\n",
      "[2400]\ttraining's l1: 0.0221047\tvalid_1's l1: 0.137727\n",
      "[2500]\ttraining's l1: 0.0211592\tvalid_1's l1: 0.13754\n",
      "[2600]\ttraining's l1: 0.0202715\tvalid_1's l1: 0.137377\n",
      "[2700]\ttraining's l1: 0.0194489\tvalid_1's l1: 0.137242\n",
      "[2800]\ttraining's l1: 0.0186796\tvalid_1's l1: 0.137085\n",
      "[2900]\ttraining's l1: 0.0179323\tvalid_1's l1: 0.136957\n",
      "[3000]\ttraining's l1: 0.0172577\tvalid_1's l1: 0.136838\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0172577\tvalid_1's l1: 0.136838\n",
      "2JHN Fold 0, logMAE: -1.9889609780598831\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.165227\tvalid_1's l1: 0.202385\n",
      "[200]\ttraining's l1: 0.126215\tvalid_1's l1: 0.177529\n",
      "[300]\ttraining's l1: 0.105432\tvalid_1's l1: 0.166845\n",
      "[400]\ttraining's l1: 0.0913272\tvalid_1's l1: 0.160075\n",
      "[500]\ttraining's l1: 0.0806064\tvalid_1's l1: 0.155343\n",
      "[600]\ttraining's l1: 0.072154\tvalid_1's l1: 0.151952\n",
      "[700]\ttraining's l1: 0.0653536\tvalid_1's l1: 0.149282\n",
      "[800]\ttraining's l1: 0.0595194\tvalid_1's l1: 0.147126\n",
      "[900]\ttraining's l1: 0.0546859\tvalid_1's l1: 0.145571\n",
      "[1000]\ttraining's l1: 0.0505175\tvalid_1's l1: 0.144319\n",
      "[1100]\ttraining's l1: 0.0468174\tvalid_1's l1: 0.143325\n",
      "[1200]\ttraining's l1: 0.0435963\tvalid_1's l1: 0.142503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\ttraining's l1: 0.0407202\tvalid_1's l1: 0.141761\n",
      "[1400]\ttraining's l1: 0.0381585\tvalid_1's l1: 0.141093\n",
      "[1500]\ttraining's l1: 0.0358103\tvalid_1's l1: 0.140478\n",
      "[1600]\ttraining's l1: 0.0337593\tvalid_1's l1: 0.140035\n",
      "[1700]\ttraining's l1: 0.0318637\tvalid_1's l1: 0.139575\n",
      "[1800]\ttraining's l1: 0.0301361\tvalid_1's l1: 0.139224\n",
      "[1900]\ttraining's l1: 0.0285345\tvalid_1's l1: 0.138814\n",
      "[2000]\ttraining's l1: 0.0271346\tvalid_1's l1: 0.138519\n",
      "[2100]\ttraining's l1: 0.0258264\tvalid_1's l1: 0.138218\n",
      "[2200]\ttraining's l1: 0.02459\tvalid_1's l1: 0.13801\n",
      "[2300]\ttraining's l1: 0.0234452\tvalid_1's l1: 0.137757\n",
      "[2400]\ttraining's l1: 0.0224133\tvalid_1's l1: 0.137575\n",
      "[2500]\ttraining's l1: 0.0214397\tvalid_1's l1: 0.137431\n",
      "[2600]\ttraining's l1: 0.0205474\tvalid_1's l1: 0.137257\n",
      "[2700]\ttraining's l1: 0.0197037\tvalid_1's l1: 0.137063\n",
      "[2800]\ttraining's l1: 0.018918\tvalid_1's l1: 0.136894\n",
      "[2900]\ttraining's l1: 0.0181883\tvalid_1's l1: 0.136758\n",
      "[3000]\ttraining's l1: 0.0174931\tvalid_1's l1: 0.136628\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0174931\tvalid_1's l1: 0.136628\n",
      "2JHN Fold 1, logMAE: -1.9904910291575835\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.166514\tvalid_1's l1: 0.201166\n",
      "[200]\ttraining's l1: 0.12766\tvalid_1's l1: 0.178008\n",
      "[300]\ttraining's l1: 0.106453\tvalid_1's l1: 0.167455\n",
      "[400]\ttraining's l1: 0.0919552\tvalid_1's l1: 0.160809\n",
      "[500]\ttraining's l1: 0.0813218\tvalid_1's l1: 0.156307\n",
      "[600]\ttraining's l1: 0.0727789\tvalid_1's l1: 0.153001\n",
      "[700]\ttraining's l1: 0.0659279\tvalid_1's l1: 0.150486\n",
      "[800]\ttraining's l1: 0.0601904\tvalid_1's l1: 0.148439\n",
      "[900]\ttraining's l1: 0.0551998\tvalid_1's l1: 0.146927\n",
      "[1000]\ttraining's l1: 0.0509043\tvalid_1's l1: 0.145585\n",
      "[1100]\ttraining's l1: 0.0471367\tvalid_1's l1: 0.144438\n",
      "[1200]\ttraining's l1: 0.0439146\tvalid_1's l1: 0.143457\n",
      "[1300]\ttraining's l1: 0.0409916\tvalid_1's l1: 0.142801\n",
      "[1400]\ttraining's l1: 0.0384084\tvalid_1's l1: 0.142076\n",
      "[1500]\ttraining's l1: 0.0360559\tvalid_1's l1: 0.141424\n",
      "[1600]\ttraining's l1: 0.0339578\tvalid_1's l1: 0.140911\n",
      "[1700]\ttraining's l1: 0.0320576\tvalid_1's l1: 0.140427\n",
      "[1800]\ttraining's l1: 0.0303025\tvalid_1's l1: 0.139984\n",
      "[1900]\ttraining's l1: 0.028722\tvalid_1's l1: 0.139627\n",
      "[2000]\ttraining's l1: 0.0272632\tvalid_1's l1: 0.139268\n",
      "[2100]\ttraining's l1: 0.0259441\tvalid_1's l1: 0.138975\n",
      "[2200]\ttraining's l1: 0.0247025\tvalid_1's l1: 0.13874\n",
      "[2300]\ttraining's l1: 0.0235707\tvalid_1's l1: 0.138489\n",
      "[2400]\ttraining's l1: 0.0225072\tvalid_1's l1: 0.138264\n",
      "[2500]\ttraining's l1: 0.0215297\tvalid_1's l1: 0.138095\n",
      "[2600]\ttraining's l1: 0.0206154\tvalid_1's l1: 0.137886\n",
      "[2700]\ttraining's l1: 0.0197774\tvalid_1's l1: 0.137725\n",
      "[2800]\ttraining's l1: 0.0189795\tvalid_1's l1: 0.137575\n",
      "[2900]\ttraining's l1: 0.0182311\tvalid_1's l1: 0.137422\n",
      "[3000]\ttraining's l1: 0.0175344\tvalid_1's l1: 0.13732\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0175344\tvalid_1's l1: 0.13732\n",
      "2JHN Fold 2, logMAE: -1.9854422708344415\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.16784\tvalid_1's l1: 0.206055\n",
      "[200]\ttraining's l1: 0.127908\tvalid_1's l1: 0.180849\n",
      "[300]\ttraining's l1: 0.106484\tvalid_1's l1: 0.16893\n",
      "[400]\ttraining's l1: 0.0920286\tvalid_1's l1: 0.162238\n",
      "[500]\ttraining's l1: 0.0811153\tvalid_1's l1: 0.157555\n",
      "[600]\ttraining's l1: 0.0727272\tvalid_1's l1: 0.154427\n",
      "[700]\ttraining's l1: 0.0658408\tvalid_1's l1: 0.151948\n",
      "[800]\ttraining's l1: 0.0600326\tvalid_1's l1: 0.149922\n",
      "[900]\ttraining's l1: 0.0550501\tvalid_1's l1: 0.148345\n",
      "[1000]\ttraining's l1: 0.0508797\tvalid_1's l1: 0.14709\n",
      "[1100]\ttraining's l1: 0.0471039\tvalid_1's l1: 0.146009\n",
      "[1200]\ttraining's l1: 0.0438717\tvalid_1's l1: 0.145022\n",
      "[1300]\ttraining's l1: 0.0410112\tvalid_1's l1: 0.1442\n",
      "[1400]\ttraining's l1: 0.0384312\tvalid_1's l1: 0.143594\n",
      "[1500]\ttraining's l1: 0.0360794\tvalid_1's l1: 0.142975\n",
      "[1600]\ttraining's l1: 0.0339915\tvalid_1's l1: 0.142498\n",
      "[1700]\ttraining's l1: 0.0321028\tvalid_1's l1: 0.142032\n",
      "[1800]\ttraining's l1: 0.0303696\tvalid_1's l1: 0.141613\n",
      "[1900]\ttraining's l1: 0.0287955\tvalid_1's l1: 0.141229\n",
      "[2000]\ttraining's l1: 0.0273338\tvalid_1's l1: 0.140902\n",
      "[2100]\ttraining's l1: 0.0260171\tvalid_1's l1: 0.140564\n",
      "[2200]\ttraining's l1: 0.0247696\tvalid_1's l1: 0.140203\n",
      "[2300]\ttraining's l1: 0.023628\tvalid_1's l1: 0.139971\n",
      "[2400]\ttraining's l1: 0.0225524\tvalid_1's l1: 0.139759\n",
      "[2500]\ttraining's l1: 0.0215596\tvalid_1's l1: 0.139587\n",
      "[2600]\ttraining's l1: 0.0206641\tvalid_1's l1: 0.139415\n",
      "[2700]\ttraining's l1: 0.0198166\tvalid_1's l1: 0.139232\n",
      "[2800]\ttraining's l1: 0.0190258\tvalid_1's l1: 0.139094\n",
      "[2900]\ttraining's l1: 0.0182998\tvalid_1's l1: 0.138964\n",
      "[3000]\ttraining's l1: 0.0176046\tvalid_1's l1: 0.138842\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0176046\tvalid_1's l1: 0.138842\n",
      "2JHN Fold 3, logMAE: -1.974420424642887\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.165001\tvalid_1's l1: 0.202056\n",
      "[200]\ttraining's l1: 0.127038\tvalid_1's l1: 0.177598\n",
      "[300]\ttraining's l1: 0.105843\tvalid_1's l1: 0.16617\n",
      "[400]\ttraining's l1: 0.0913862\tvalid_1's l1: 0.159816\n",
      "[500]\ttraining's l1: 0.0806988\tvalid_1's l1: 0.155306\n",
      "[600]\ttraining's l1: 0.0723403\tvalid_1's l1: 0.152246\n",
      "[700]\ttraining's l1: 0.0655039\tvalid_1's l1: 0.149857\n",
      "[800]\ttraining's l1: 0.0596681\tvalid_1's l1: 0.148046\n",
      "[900]\ttraining's l1: 0.0548654\tvalid_1's l1: 0.146602\n",
      "[1000]\ttraining's l1: 0.0506464\tvalid_1's l1: 0.14532\n",
      "[1100]\ttraining's l1: 0.0469764\tvalid_1's l1: 0.14432\n",
      "[1200]\ttraining's l1: 0.0437486\tvalid_1's l1: 0.14347\n",
      "[1300]\ttraining's l1: 0.0408466\tvalid_1's l1: 0.142706\n",
      "[1400]\ttraining's l1: 0.0382544\tvalid_1's l1: 0.142034\n",
      "[1500]\ttraining's l1: 0.0359642\tvalid_1's l1: 0.141473\n",
      "[1600]\ttraining's l1: 0.0338721\tvalid_1's l1: 0.14096\n",
      "[1700]\ttraining's l1: 0.0319878\tvalid_1's l1: 0.1406\n",
      "[1800]\ttraining's l1: 0.0302644\tvalid_1's l1: 0.140222\n",
      "[1900]\ttraining's l1: 0.0287024\tvalid_1's l1: 0.139896\n",
      "[2000]\ttraining's l1: 0.0272576\tvalid_1's l1: 0.139603\n",
      "[2100]\ttraining's l1: 0.0259045\tvalid_1's l1: 0.139343\n",
      "[2200]\ttraining's l1: 0.0246666\tvalid_1's l1: 0.139105\n",
      "[2300]\ttraining's l1: 0.0235434\tvalid_1's l1: 0.138854\n",
      "[2400]\ttraining's l1: 0.0224984\tvalid_1's l1: 0.138638\n",
      "[2500]\ttraining's l1: 0.0215231\tvalid_1's l1: 0.138421\n",
      "[2600]\ttraining's l1: 0.0206202\tvalid_1's l1: 0.138248\n",
      "[2700]\ttraining's l1: 0.0197844\tvalid_1's l1: 0.138075\n",
      "[2800]\ttraining's l1: 0.0189974\tvalid_1's l1: 0.137918\n",
      "[2900]\ttraining's l1: 0.018266\tvalid_1's l1: 0.137768\n",
      "[3000]\ttraining's l1: 0.0175842\tvalid_1's l1: 0.137649\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0175842\tvalid_1's l1: 0.137649\n",
      "2JHN Fold 4, logMAE: -1.9830475217958452\n",
      "*** Training Model for 2JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.489629\tvalid_1's l1: 0.506259\n",
      "[200]\ttraining's l1: 0.4169\tvalid_1's l1: 0.442197\n",
      "[300]\ttraining's l1: 0.376241\tvalid_1's l1: 0.408623\n",
      "[400]\ttraining's l1: 0.34803\tvalid_1's l1: 0.386625\n",
      "[500]\ttraining's l1: 0.32651\tvalid_1's l1: 0.370686\n",
      "[600]\ttraining's l1: 0.308919\tvalid_1's l1: 0.358121\n",
      "[700]\ttraining's l1: 0.294283\tvalid_1's l1: 0.348187\n",
      "[800]\ttraining's l1: 0.281694\tvalid_1's l1: 0.339833\n",
      "[900]\ttraining's l1: 0.271103\tvalid_1's l1: 0.333158\n",
      "[1000]\ttraining's l1: 0.261154\tvalid_1's l1: 0.326944\n",
      "[1100]\ttraining's l1: 0.252354\tvalid_1's l1: 0.321561\n",
      "[1200]\ttraining's l1: 0.244388\tvalid_1's l1: 0.316967\n",
      "[1300]\ttraining's l1: 0.237179\tvalid_1's l1: 0.312744\n",
      "[1400]\ttraining's l1: 0.230572\tvalid_1's l1: 0.3091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500]\ttraining's l1: 0.224108\tvalid_1's l1: 0.305598\n",
      "[1600]\ttraining's l1: 0.218289\tvalid_1's l1: 0.302521\n",
      "[1700]\ttraining's l1: 0.212831\tvalid_1's l1: 0.299657\n",
      "[1800]\ttraining's l1: 0.207842\tvalid_1's l1: 0.297067\n",
      "[1900]\ttraining's l1: 0.202963\tvalid_1's l1: 0.294648\n",
      "[2000]\ttraining's l1: 0.198464\tvalid_1's l1: 0.292487\n",
      "[2100]\ttraining's l1: 0.194194\tvalid_1's l1: 0.290444\n",
      "[2200]\ttraining's l1: 0.19008\tvalid_1's l1: 0.288492\n",
      "[2300]\ttraining's l1: 0.186158\tvalid_1's l1: 0.286682\n",
      "[2400]\ttraining's l1: 0.182541\tvalid_1's l1: 0.285038\n",
      "[2500]\ttraining's l1: 0.178971\tvalid_1's l1: 0.283456\n",
      "[2600]\ttraining's l1: 0.175497\tvalid_1's l1: 0.281958\n",
      "[2700]\ttraining's l1: 0.172167\tvalid_1's l1: 0.280409\n",
      "[2800]\ttraining's l1: 0.169055\tvalid_1's l1: 0.279046\n",
      "[2900]\ttraining's l1: 0.16604\tvalid_1's l1: 0.277757\n",
      "[3000]\ttraining's l1: 0.163173\tvalid_1's l1: 0.27651\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.163173\tvalid_1's l1: 0.27651\n",
      "2JHC Fold 0, logMAE: -1.285510005623579\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.488684\tvalid_1's l1: 0.504694\n",
      "[200]\ttraining's l1: 0.417757\tvalid_1's l1: 0.442751\n",
      "[300]\ttraining's l1: 0.37675\tvalid_1's l1: 0.408864\n",
      "[400]\ttraining's l1: 0.34853\tvalid_1's l1: 0.386876\n",
      "[500]\ttraining's l1: 0.327282\tvalid_1's l1: 0.371117\n",
      "[600]\ttraining's l1: 0.3098\tvalid_1's l1: 0.358636\n",
      "[700]\ttraining's l1: 0.295402\tvalid_1's l1: 0.348854\n",
      "[800]\ttraining's l1: 0.282611\tvalid_1's l1: 0.340467\n",
      "[900]\ttraining's l1: 0.271741\tvalid_1's l1: 0.333515\n",
      "[1000]\ttraining's l1: 0.261692\tvalid_1's l1: 0.32706\n",
      "[1100]\ttraining's l1: 0.252874\tvalid_1's l1: 0.321646\n",
      "[1200]\ttraining's l1: 0.244816\tvalid_1's l1: 0.316894\n",
      "[1300]\ttraining's l1: 0.237549\tvalid_1's l1: 0.312816\n",
      "[1400]\ttraining's l1: 0.230748\tvalid_1's l1: 0.309077\n",
      "[1500]\ttraining's l1: 0.224634\tvalid_1's l1: 0.305661\n",
      "[1600]\ttraining's l1: 0.218724\tvalid_1's l1: 0.302523\n",
      "[1700]\ttraining's l1: 0.213294\tvalid_1's l1: 0.299632\n",
      "[1800]\ttraining's l1: 0.208221\tvalid_1's l1: 0.296904\n",
      "[1900]\ttraining's l1: 0.203507\tvalid_1's l1: 0.294603\n",
      "[2000]\ttraining's l1: 0.198833\tvalid_1's l1: 0.292338\n",
      "[2100]\ttraining's l1: 0.194339\tvalid_1's l1: 0.290121\n",
      "[2200]\ttraining's l1: 0.190145\tvalid_1's l1: 0.288115\n",
      "[2300]\ttraining's l1: 0.186279\tvalid_1's l1: 0.286335\n",
      "[2400]\ttraining's l1: 0.182514\tvalid_1's l1: 0.284548\n",
      "[2500]\ttraining's l1: 0.179042\tvalid_1's l1: 0.282994\n",
      "[2600]\ttraining's l1: 0.175714\tvalid_1's l1: 0.281444\n",
      "[2700]\ttraining's l1: 0.172483\tvalid_1's l1: 0.280035\n",
      "[2800]\ttraining's l1: 0.169312\tvalid_1's l1: 0.278645\n",
      "[2900]\ttraining's l1: 0.166245\tvalid_1's l1: 0.277427\n",
      "[3000]\ttraining's l1: 0.163321\tvalid_1's l1: 0.276233\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.163321\tvalid_1's l1: 0.276233\n",
      "2JHC Fold 1, logMAE: -1.2865121463962756\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.492641\tvalid_1's l1: 0.505636\n",
      "[200]\ttraining's l1: 0.418231\tvalid_1's l1: 0.440972\n",
      "[300]\ttraining's l1: 0.377624\tvalid_1's l1: 0.407585\n",
      "[400]\ttraining's l1: 0.349334\tvalid_1's l1: 0.386134\n",
      "[500]\ttraining's l1: 0.328007\tvalid_1's l1: 0.370633\n",
      "[600]\ttraining's l1: 0.310948\tvalid_1's l1: 0.358482\n",
      "[700]\ttraining's l1: 0.296553\tvalid_1's l1: 0.348872\n",
      "[800]\ttraining's l1: 0.28409\tvalid_1's l1: 0.340681\n",
      "[900]\ttraining's l1: 0.272762\tvalid_1's l1: 0.333359\n",
      "[1000]\ttraining's l1: 0.262731\tvalid_1's l1: 0.327175\n",
      "[1100]\ttraining's l1: 0.253743\tvalid_1's l1: 0.32169\n",
      "[1200]\ttraining's l1: 0.245938\tvalid_1's l1: 0.317185\n",
      "[1300]\ttraining's l1: 0.238684\tvalid_1's l1: 0.313221\n",
      "[1400]\ttraining's l1: 0.232168\tvalid_1's l1: 0.309668\n",
      "[1500]\ttraining's l1: 0.225706\tvalid_1's l1: 0.306039\n",
      "[1600]\ttraining's l1: 0.219762\tvalid_1's l1: 0.302733\n",
      "[1700]\ttraining's l1: 0.214156\tvalid_1's l1: 0.299879\n",
      "[1800]\ttraining's l1: 0.20903\tvalid_1's l1: 0.297268\n",
      "[1900]\ttraining's l1: 0.204166\tvalid_1's l1: 0.294753\n",
      "[2000]\ttraining's l1: 0.19958\tvalid_1's l1: 0.292485\n",
      "[2100]\ttraining's l1: 0.195225\tvalid_1's l1: 0.2904\n",
      "[2200]\ttraining's l1: 0.191087\tvalid_1's l1: 0.288387\n",
      "[2300]\ttraining's l1: 0.187158\tvalid_1's l1: 0.286537\n",
      "[2400]\ttraining's l1: 0.183402\tvalid_1's l1: 0.284803\n",
      "[2500]\ttraining's l1: 0.179819\tvalid_1's l1: 0.28322\n",
      "[2600]\ttraining's l1: 0.176361\tvalid_1's l1: 0.281671\n",
      "[2700]\ttraining's l1: 0.173028\tvalid_1's l1: 0.280259\n",
      "[2800]\ttraining's l1: 0.169858\tvalid_1's l1: 0.278804\n",
      "[2900]\ttraining's l1: 0.166867\tvalid_1's l1: 0.277604\n",
      "[3000]\ttraining's l1: 0.163894\tvalid_1's l1: 0.276356\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.163894\tvalid_1's l1: 0.276356\n",
      "2JHC Fold 2, logMAE: -1.2860668252870113\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.486558\tvalid_1's l1: 0.503038\n",
      "[200]\ttraining's l1: 0.414204\tvalid_1's l1: 0.439606\n",
      "[300]\ttraining's l1: 0.374125\tvalid_1's l1: 0.407021\n",
      "[400]\ttraining's l1: 0.345678\tvalid_1's l1: 0.385229\n",
      "[500]\ttraining's l1: 0.324758\tvalid_1's l1: 0.369688\n",
      "[600]\ttraining's l1: 0.307713\tvalid_1's l1: 0.357662\n",
      "[700]\ttraining's l1: 0.293261\tvalid_1's l1: 0.347586\n",
      "[800]\ttraining's l1: 0.280708\tvalid_1's l1: 0.33922\n",
      "[900]\ttraining's l1: 0.269808\tvalid_1's l1: 0.332116\n",
      "[1000]\ttraining's l1: 0.260467\tvalid_1's l1: 0.326386\n",
      "[1100]\ttraining's l1: 0.251738\tvalid_1's l1: 0.321155\n",
      "[1200]\ttraining's l1: 0.243839\tvalid_1's l1: 0.316516\n",
      "[1300]\ttraining's l1: 0.23667\tvalid_1's l1: 0.312586\n",
      "[1400]\ttraining's l1: 0.229864\tvalid_1's l1: 0.3088\n",
      "[1500]\ttraining's l1: 0.223554\tvalid_1's l1: 0.305393\n",
      "[1600]\ttraining's l1: 0.217862\tvalid_1's l1: 0.302365\n",
      "[1700]\ttraining's l1: 0.212487\tvalid_1's l1: 0.299548\n",
      "[1800]\ttraining's l1: 0.207242\tvalid_1's l1: 0.29687\n",
      "[1900]\ttraining's l1: 0.202413\tvalid_1's l1: 0.294408\n",
      "[2000]\ttraining's l1: 0.197894\tvalid_1's l1: 0.292286\n",
      "[2100]\ttraining's l1: 0.193604\tvalid_1's l1: 0.290346\n",
      "[2200]\ttraining's l1: 0.189546\tvalid_1's l1: 0.288475\n",
      "[2300]\ttraining's l1: 0.185712\tvalid_1's l1: 0.286663\n",
      "[2400]\ttraining's l1: 0.182043\tvalid_1's l1: 0.284927\n",
      "[2500]\ttraining's l1: 0.17861\tvalid_1's l1: 0.283251\n",
      "[2600]\ttraining's l1: 0.175177\tvalid_1's l1: 0.281657\n",
      "[2700]\ttraining's l1: 0.171832\tvalid_1's l1: 0.280242\n",
      "[2800]\ttraining's l1: 0.168706\tvalid_1's l1: 0.278806\n",
      "[2900]\ttraining's l1: 0.165728\tvalid_1's l1: 0.27753\n",
      "[3000]\ttraining's l1: 0.162793\tvalid_1's l1: 0.27627\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.162793\tvalid_1's l1: 0.27627\n",
      "2JHC Fold 3, logMAE: -1.286378376250608\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.487649\tvalid_1's l1: 0.505705\n",
      "[200]\ttraining's l1: 0.416\tvalid_1's l1: 0.443341\n",
      "[300]\ttraining's l1: 0.375808\tvalid_1's l1: 0.410059\n",
      "[400]\ttraining's l1: 0.347858\tvalid_1's l1: 0.388158\n",
      "[500]\ttraining's l1: 0.326565\tvalid_1's l1: 0.372225\n",
      "[600]\ttraining's l1: 0.308979\tvalid_1's l1: 0.359613\n",
      "[700]\ttraining's l1: 0.294459\tvalid_1's l1: 0.349649\n",
      "[800]\ttraining's l1: 0.281775\tvalid_1's l1: 0.341185\n",
      "[900]\ttraining's l1: 0.271322\tvalid_1's l1: 0.334575\n",
      "[1000]\ttraining's l1: 0.261492\tvalid_1's l1: 0.328458\n",
      "[1100]\ttraining's l1: 0.252872\tvalid_1's l1: 0.323163\n",
      "[1200]\ttraining's l1: 0.245269\tvalid_1's l1: 0.318806\n",
      "[1300]\ttraining's l1: 0.237806\tvalid_1's l1: 0.314651\n",
      "[1400]\ttraining's l1: 0.230939\tvalid_1's l1: 0.310843\n",
      "[1500]\ttraining's l1: 0.224724\tvalid_1's l1: 0.307427\n",
      "[1600]\ttraining's l1: 0.218842\tvalid_1's l1: 0.304328\n",
      "[1700]\ttraining's l1: 0.213342\tvalid_1's l1: 0.30131\n",
      "[1800]\ttraining's l1: 0.208261\tvalid_1's l1: 0.298725\n",
      "[1900]\ttraining's l1: 0.203414\tvalid_1's l1: 0.296186\n",
      "[2000]\ttraining's l1: 0.198892\tvalid_1's l1: 0.293871\n",
      "[2100]\ttraining's l1: 0.194604\tvalid_1's l1: 0.291798\n",
      "[2200]\ttraining's l1: 0.190545\tvalid_1's l1: 0.289819\n",
      "[2300]\ttraining's l1: 0.186635\tvalid_1's l1: 0.288029\n",
      "[2400]\ttraining's l1: 0.182906\tvalid_1's l1: 0.286258\n",
      "[2500]\ttraining's l1: 0.179315\tvalid_1's l1: 0.284552\n",
      "[2600]\ttraining's l1: 0.175848\tvalid_1's l1: 0.282957\n",
      "[2700]\ttraining's l1: 0.17257\tvalid_1's l1: 0.281482\n",
      "[2800]\ttraining's l1: 0.169423\tvalid_1's l1: 0.280041\n",
      "[2900]\ttraining's l1: 0.166454\tvalid_1's l1: 0.278755\n",
      "[3000]\ttraining's l1: 0.163517\tvalid_1's l1: 0.277455\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.163517\tvalid_1's l1: 0.277455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2JHC Fold 4, logMAE: -1.2820965445158718\n",
      "*** Training Model for 3JHH ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0', 'd_4_1',\n",
      "       'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0', 'd_6_1',\n",
      "       'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0', 'd_8_1',\n",
      "       'd_8_2', 'd_8_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.271414\tvalid_1's l1: 0.284276\n",
      "[200]\ttraining's l1: 0.225978\tvalid_1's l1: 0.246926\n",
      "[300]\ttraining's l1: 0.199578\tvalid_1's l1: 0.22731\n",
      "[400]\ttraining's l1: 0.181753\tvalid_1's l1: 0.214813\n",
      "[500]\ttraining's l1: 0.168049\tvalid_1's l1: 0.206071\n",
      "[600]\ttraining's l1: 0.157354\tvalid_1's l1: 0.199556\n",
      "[700]\ttraining's l1: 0.148317\tvalid_1's l1: 0.194241\n",
      "[800]\ttraining's l1: 0.140671\tvalid_1's l1: 0.190087\n",
      "[900]\ttraining's l1: 0.133874\tvalid_1's l1: 0.186568\n",
      "[1000]\ttraining's l1: 0.127999\tvalid_1's l1: 0.183667\n",
      "[1100]\ttraining's l1: 0.122691\tvalid_1's l1: 0.181181\n",
      "[1200]\ttraining's l1: 0.117857\tvalid_1's l1: 0.17891\n",
      "[1300]\ttraining's l1: 0.11335\tvalid_1's l1: 0.176941\n",
      "[1400]\ttraining's l1: 0.109289\tvalid_1's l1: 0.175101\n",
      "[1500]\ttraining's l1: 0.105501\tvalid_1's l1: 0.173485\n",
      "[1600]\ttraining's l1: 0.101906\tvalid_1's l1: 0.172032\n",
      "[1700]\ttraining's l1: 0.0986098\tvalid_1's l1: 0.170713\n",
      "[1800]\ttraining's l1: 0.095508\tvalid_1's l1: 0.169421\n",
      "[1900]\ttraining's l1: 0.0926724\tvalid_1's l1: 0.168339\n",
      "[2000]\ttraining's l1: 0.0899985\tvalid_1's l1: 0.167441\n",
      "[2100]\ttraining's l1: 0.0874393\tvalid_1's l1: 0.166566\n",
      "[2200]\ttraining's l1: 0.0850062\tvalid_1's l1: 0.165707\n",
      "[2300]\ttraining's l1: 0.0827374\tvalid_1's l1: 0.164919\n",
      "[2400]\ttraining's l1: 0.0805623\tvalid_1's l1: 0.164192\n",
      "[2500]\ttraining's l1: 0.0784608\tvalid_1's l1: 0.163453\n",
      "[2600]\ttraining's l1: 0.076523\tvalid_1's l1: 0.162791\n",
      "[2700]\ttraining's l1: 0.0745937\tvalid_1's l1: 0.162133\n",
      "[2800]\ttraining's l1: 0.0728049\tvalid_1's l1: 0.161516\n",
      "[2900]\ttraining's l1: 0.071109\tvalid_1's l1: 0.161016\n",
      "[3000]\ttraining's l1: 0.0694227\tvalid_1's l1: 0.160522\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0694227\tvalid_1's l1: 0.160522\n",
      "3JHH Fold 0, logMAE: -1.8293257231243567\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.271243\tvalid_1's l1: 0.285902\n",
      "[200]\ttraining's l1: 0.22531\tvalid_1's l1: 0.248592\n",
      "[300]\ttraining's l1: 0.199767\tvalid_1's l1: 0.229837\n",
      "[400]\ttraining's l1: 0.182178\tvalid_1's l1: 0.217805\n",
      "[500]\ttraining's l1: 0.168566\tvalid_1's l1: 0.208844\n",
      "[600]\ttraining's l1: 0.157895\tvalid_1's l1: 0.202488\n",
      "[700]\ttraining's l1: 0.148959\tvalid_1's l1: 0.197371\n",
      "[800]\ttraining's l1: 0.141272\tvalid_1's l1: 0.193066\n",
      "[900]\ttraining's l1: 0.13447\tvalid_1's l1: 0.18952\n",
      "[1000]\ttraining's l1: 0.128404\tvalid_1's l1: 0.186269\n",
      "[1100]\ttraining's l1: 0.123068\tvalid_1's l1: 0.183663\n",
      "[1200]\ttraining's l1: 0.118261\tvalid_1's l1: 0.181426\n",
      "[1300]\ttraining's l1: 0.113751\tvalid_1's l1: 0.179337\n",
      "[1400]\ttraining's l1: 0.10966\tvalid_1's l1: 0.17758\n",
      "[1500]\ttraining's l1: 0.105865\tvalid_1's l1: 0.175928\n",
      "[1600]\ttraining's l1: 0.102382\tvalid_1's l1: 0.174467\n",
      "[1700]\ttraining's l1: 0.0991586\tvalid_1's l1: 0.173115\n",
      "[1800]\ttraining's l1: 0.0959904\tvalid_1's l1: 0.17177\n",
      "[1900]\ttraining's l1: 0.0931363\tvalid_1's l1: 0.170574\n",
      "[2000]\ttraining's l1: 0.0903976\tvalid_1's l1: 0.169481\n",
      "[2100]\ttraining's l1: 0.0877938\tvalid_1's l1: 0.168534\n",
      "[2200]\ttraining's l1: 0.0853585\tvalid_1's l1: 0.16766\n",
      "[2300]\ttraining's l1: 0.083067\tvalid_1's l1: 0.166861\n",
      "[2400]\ttraining's l1: 0.0808416\tvalid_1's l1: 0.166045\n",
      "[2500]\ttraining's l1: 0.078752\tvalid_1's l1: 0.165327\n",
      "[2600]\ttraining's l1: 0.0767199\tvalid_1's l1: 0.164624\n",
      "[2700]\ttraining's l1: 0.0748107\tvalid_1's l1: 0.163958\n",
      "[2800]\ttraining's l1: 0.0729612\tvalid_1's l1: 0.163362\n",
      "[2900]\ttraining's l1: 0.071257\tvalid_1's l1: 0.162836\n",
      "[3000]\ttraining's l1: 0.0695451\tvalid_1's l1: 0.162278\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0695451\tvalid_1's l1: 0.162278\n",
      "3JHH Fold 1, logMAE: -1.8184445638147486\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.271874\tvalid_1's l1: 0.286503\n",
      "[200]\ttraining's l1: 0.224836\tvalid_1's l1: 0.247862\n",
      "[300]\ttraining's l1: 0.199135\tvalid_1's l1: 0.228719\n",
      "[400]\ttraining's l1: 0.181649\tvalid_1's l1: 0.21636\n",
      "[500]\ttraining's l1: 0.168364\tvalid_1's l1: 0.207746\n",
      "[600]\ttraining's l1: 0.15748\tvalid_1's l1: 0.201046\n",
      "[700]\ttraining's l1: 0.148586\tvalid_1's l1: 0.195755\n",
      "[800]\ttraining's l1: 0.14078\tvalid_1's l1: 0.191455\n",
      "[900]\ttraining's l1: 0.13407\tvalid_1's l1: 0.188014\n",
      "[1000]\ttraining's l1: 0.128016\tvalid_1's l1: 0.184883\n",
      "[1100]\ttraining's l1: 0.122634\tvalid_1's l1: 0.182151\n",
      "[1200]\ttraining's l1: 0.117863\tvalid_1's l1: 0.179863\n",
      "[1300]\ttraining's l1: 0.113353\tvalid_1's l1: 0.177841\n",
      "[1400]\ttraining's l1: 0.109167\tvalid_1's l1: 0.176004\n",
      "[1500]\ttraining's l1: 0.105388\tvalid_1's l1: 0.174313\n",
      "[1600]\ttraining's l1: 0.101854\tvalid_1's l1: 0.172804\n",
      "[1700]\ttraining's l1: 0.0984952\tvalid_1's l1: 0.171391\n",
      "[1800]\ttraining's l1: 0.0953928\tvalid_1's l1: 0.170127\n",
      "[1900]\ttraining's l1: 0.092517\tvalid_1's l1: 0.169041\n",
      "[2000]\ttraining's l1: 0.0898176\tvalid_1's l1: 0.167965\n",
      "[2100]\ttraining's l1: 0.0873038\tvalid_1's l1: 0.167024\n",
      "[2200]\ttraining's l1: 0.0849526\tvalid_1's l1: 0.166143\n",
      "[2300]\ttraining's l1: 0.0826022\tvalid_1's l1: 0.165311\n",
      "[2400]\ttraining's l1: 0.080428\tvalid_1's l1: 0.164475\n",
      "[2500]\ttraining's l1: 0.0783695\tvalid_1's l1: 0.163815\n",
      "[2600]\ttraining's l1: 0.0763717\tvalid_1's l1: 0.16317\n",
      "[2700]\ttraining's l1: 0.0744888\tvalid_1's l1: 0.162533\n",
      "[2800]\ttraining's l1: 0.0726609\tvalid_1's l1: 0.161911\n",
      "[2900]\ttraining's l1: 0.0709169\tvalid_1's l1: 0.161406\n",
      "[3000]\ttraining's l1: 0.069238\tvalid_1's l1: 0.160915\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.069238\tvalid_1's l1: 0.160915\n",
      "3JHH Fold 2, logMAE: -1.826876174748315\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.27156\tvalid_1's l1: 0.288488\n",
      "[200]\ttraining's l1: 0.224651\tvalid_1's l1: 0.24976\n",
      "[300]\ttraining's l1: 0.198546\tvalid_1's l1: 0.230185\n",
      "[400]\ttraining's l1: 0.181238\tvalid_1's l1: 0.218158\n",
      "[500]\ttraining's l1: 0.168215\tvalid_1's l1: 0.209776\n",
      "[600]\ttraining's l1: 0.157343\tvalid_1's l1: 0.203013\n",
      "[700]\ttraining's l1: 0.14837\tvalid_1's l1: 0.197684\n",
      "[800]\ttraining's l1: 0.140641\tvalid_1's l1: 0.193359\n",
      "[900]\ttraining's l1: 0.133693\tvalid_1's l1: 0.189551\n",
      "[1000]\ttraining's l1: 0.127761\tvalid_1's l1: 0.186482\n",
      "[1100]\ttraining's l1: 0.122368\tvalid_1's l1: 0.183796\n",
      "[1200]\ttraining's l1: 0.117356\tvalid_1's l1: 0.181412\n",
      "[1300]\ttraining's l1: 0.112916\tvalid_1's l1: 0.179365\n",
      "[1400]\ttraining's l1: 0.108882\tvalid_1's l1: 0.177567\n",
      "[1500]\ttraining's l1: 0.105129\tvalid_1's l1: 0.176025\n",
      "[1600]\ttraining's l1: 0.101567\tvalid_1's l1: 0.174507\n",
      "[1700]\ttraining's l1: 0.0982815\tvalid_1's l1: 0.17313\n",
      "[1800]\ttraining's l1: 0.0952485\tvalid_1's l1: 0.171927\n",
      "[1900]\ttraining's l1: 0.0923663\tvalid_1's l1: 0.17071\n",
      "[2000]\ttraining's l1: 0.0896779\tvalid_1's l1: 0.169628\n",
      "[2100]\ttraining's l1: 0.0870975\tvalid_1's l1: 0.168678\n",
      "[2200]\ttraining's l1: 0.0846581\tvalid_1's l1: 0.167796\n",
      "[2300]\ttraining's l1: 0.0824043\tvalid_1's l1: 0.167016\n",
      "[2400]\ttraining's l1: 0.0802145\tvalid_1's l1: 0.166327\n",
      "[2500]\ttraining's l1: 0.0781639\tvalid_1's l1: 0.165613\n",
      "[2600]\ttraining's l1: 0.0762298\tvalid_1's l1: 0.164942\n",
      "[2700]\ttraining's l1: 0.0743673\tvalid_1's l1: 0.164316\n",
      "[2800]\ttraining's l1: 0.0725959\tvalid_1's l1: 0.163765\n",
      "[2900]\ttraining's l1: 0.0708512\tvalid_1's l1: 0.163158\n",
      "[3000]\ttraining's l1: 0.069225\tvalid_1's l1: 0.162655\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.069225\tvalid_1's l1: 0.162655\n",
      "3JHH Fold 3, logMAE: -1.8161234477440296\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.271441\tvalid_1's l1: 0.287024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's l1: 0.22554\tvalid_1's l1: 0.248828\n",
      "[300]\ttraining's l1: 0.199955\tvalid_1's l1: 0.229729\n",
      "[400]\ttraining's l1: 0.18248\tvalid_1's l1: 0.217465\n",
      "[500]\ttraining's l1: 0.168945\tvalid_1's l1: 0.208859\n",
      "[600]\ttraining's l1: 0.15813\tvalid_1's l1: 0.20215\n",
      "[700]\ttraining's l1: 0.14902\tvalid_1's l1: 0.196772\n",
      "[800]\ttraining's l1: 0.141328\tvalid_1's l1: 0.192417\n",
      "[900]\ttraining's l1: 0.134547\tvalid_1's l1: 0.188762\n",
      "[1000]\ttraining's l1: 0.128532\tvalid_1's l1: 0.185534\n",
      "[1100]\ttraining's l1: 0.123194\tvalid_1's l1: 0.182818\n",
      "[1200]\ttraining's l1: 0.118293\tvalid_1's l1: 0.180546\n",
      "[1300]\ttraining's l1: 0.113761\tvalid_1's l1: 0.178449\n",
      "[1400]\ttraining's l1: 0.109674\tvalid_1's l1: 0.176659\n",
      "[1500]\ttraining's l1: 0.105872\tvalid_1's l1: 0.174961\n",
      "[1600]\ttraining's l1: 0.102373\tvalid_1's l1: 0.173463\n",
      "[1700]\ttraining's l1: 0.0990381\tvalid_1's l1: 0.172122\n",
      "[1800]\ttraining's l1: 0.0959131\tvalid_1's l1: 0.170875\n",
      "[1900]\ttraining's l1: 0.0930128\tvalid_1's l1: 0.169788\n",
      "[2000]\ttraining's l1: 0.0902573\tvalid_1's l1: 0.168815\n",
      "[2100]\ttraining's l1: 0.0876714\tvalid_1's l1: 0.167857\n",
      "[2200]\ttraining's l1: 0.0852453\tvalid_1's l1: 0.1669\n",
      "[2300]\ttraining's l1: 0.0829403\tvalid_1's l1: 0.166077\n",
      "[2400]\ttraining's l1: 0.0807343\tvalid_1's l1: 0.165261\n",
      "[2500]\ttraining's l1: 0.0786743\tvalid_1's l1: 0.164556\n",
      "[2600]\ttraining's l1: 0.0766726\tvalid_1's l1: 0.163846\n",
      "[2700]\ttraining's l1: 0.0747545\tvalid_1's l1: 0.163229\n",
      "[2800]\ttraining's l1: 0.0729299\tvalid_1's l1: 0.162613\n",
      "[2900]\ttraining's l1: 0.0711912\tvalid_1's l1: 0.162052\n",
      "[3000]\ttraining's l1: 0.0694559\tvalid_1's l1: 0.161485\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0694559\tvalid_1's l1: 0.161485\n",
      "3JHH Fold 4, logMAE: -1.8233422003057638\n",
      "*** Training Model for 3JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.540558\tvalid_1's l1: 0.551986\n",
      "[200]\ttraining's l1: 0.460892\tvalid_1's l1: 0.479681\n",
      "[300]\ttraining's l1: 0.419301\tvalid_1's l1: 0.444236\n",
      "[400]\ttraining's l1: 0.390519\tvalid_1's l1: 0.420943\n",
      "[500]\ttraining's l1: 0.367913\tvalid_1's l1: 0.403455\n",
      "[600]\ttraining's l1: 0.350146\tvalid_1's l1: 0.390224\n",
      "[700]\ttraining's l1: 0.335121\tvalid_1's l1: 0.379508\n",
      "[800]\ttraining's l1: 0.322381\tvalid_1's l1: 0.370717\n",
      "[900]\ttraining's l1: 0.311194\tvalid_1's l1: 0.363339\n",
      "[1000]\ttraining's l1: 0.301253\tvalid_1's l1: 0.356792\n",
      "[1100]\ttraining's l1: 0.292371\tvalid_1's l1: 0.351302\n",
      "[1200]\ttraining's l1: 0.284131\tvalid_1's l1: 0.346204\n",
      "[1300]\ttraining's l1: 0.276595\tvalid_1's l1: 0.3417\n",
      "[1400]\ttraining's l1: 0.269509\tvalid_1's l1: 0.337546\n",
      "[1500]\ttraining's l1: 0.262995\tvalid_1's l1: 0.333855\n",
      "[1600]\ttraining's l1: 0.256885\tvalid_1's l1: 0.33048\n",
      "[1700]\ttraining's l1: 0.251198\tvalid_1's l1: 0.327335\n",
      "[1800]\ttraining's l1: 0.245941\tvalid_1's l1: 0.324625\n",
      "[1900]\ttraining's l1: 0.240869\tvalid_1's l1: 0.322054\n",
      "[2000]\ttraining's l1: 0.236104\tvalid_1's l1: 0.319643\n",
      "[2100]\ttraining's l1: 0.231507\tvalid_1's l1: 0.317338\n",
      "[2200]\ttraining's l1: 0.227082\tvalid_1's l1: 0.315051\n",
      "[2300]\ttraining's l1: 0.222957\tvalid_1's l1: 0.313085\n",
      "[2400]\ttraining's l1: 0.218961\tvalid_1's l1: 0.311194\n",
      "[2500]\ttraining's l1: 0.215134\tvalid_1's l1: 0.309446\n",
      "[2600]\ttraining's l1: 0.211558\tvalid_1's l1: 0.307824\n",
      "[2700]\ttraining's l1: 0.208103\tvalid_1's l1: 0.306275\n",
      "[2800]\ttraining's l1: 0.204729\tvalid_1's l1: 0.304724\n",
      "[2900]\ttraining's l1: 0.201471\tvalid_1's l1: 0.30324\n",
      "[3000]\ttraining's l1: 0.19841\tvalid_1's l1: 0.301871\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.19841\tvalid_1's l1: 0.301871\n",
      "3JHC Fold 0, logMAE: -1.197754612774443\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.537254\tvalid_1's l1: 0.549907\n",
      "[200]\ttraining's l1: 0.461964\tvalid_1's l1: 0.482003\n",
      "[300]\ttraining's l1: 0.419609\tvalid_1's l1: 0.445875\n",
      "[400]\ttraining's l1: 0.39064\tvalid_1's l1: 0.422411\n",
      "[500]\ttraining's l1: 0.368962\tvalid_1's l1: 0.405536\n",
      "[600]\ttraining's l1: 0.35152\tvalid_1's l1: 0.392597\n",
      "[700]\ttraining's l1: 0.336142\tvalid_1's l1: 0.381409\n",
      "[800]\ttraining's l1: 0.323764\tvalid_1's l1: 0.372835\n",
      "[900]\ttraining's l1: 0.31226\tvalid_1's l1: 0.365052\n",
      "[1000]\ttraining's l1: 0.302346\tvalid_1's l1: 0.358665\n",
      "[1100]\ttraining's l1: 0.293328\tvalid_1's l1: 0.352979\n",
      "[1200]\ttraining's l1: 0.28521\tvalid_1's l1: 0.347983\n",
      "[1300]\ttraining's l1: 0.277658\tvalid_1's l1: 0.343429\n",
      "[1400]\ttraining's l1: 0.270535\tvalid_1's l1: 0.339245\n",
      "[1500]\ttraining's l1: 0.263993\tvalid_1's l1: 0.335548\n",
      "[1600]\ttraining's l1: 0.25776\tvalid_1's l1: 0.332018\n",
      "[1700]\ttraining's l1: 0.251984\tvalid_1's l1: 0.328877\n",
      "[1800]\ttraining's l1: 0.24655\tvalid_1's l1: 0.325912\n",
      "[1900]\ttraining's l1: 0.241498\tvalid_1's l1: 0.323234\n",
      "[2000]\ttraining's l1: 0.236693\tvalid_1's l1: 0.320759\n",
      "[2100]\ttraining's l1: 0.232173\tvalid_1's l1: 0.318536\n",
      "[2200]\ttraining's l1: 0.227771\tvalid_1's l1: 0.31641\n",
      "[2300]\ttraining's l1: 0.223524\tvalid_1's l1: 0.314262\n",
      "[2400]\ttraining's l1: 0.219499\tvalid_1's l1: 0.312307\n",
      "[2500]\ttraining's l1: 0.215641\tvalid_1's l1: 0.310463\n",
      "[2600]\ttraining's l1: 0.212046\tvalid_1's l1: 0.308835\n",
      "[2700]\ttraining's l1: 0.208508\tvalid_1's l1: 0.307209\n",
      "[2800]\ttraining's l1: 0.205071\tvalid_1's l1: 0.305637\n",
      "[2900]\ttraining's l1: 0.201861\tvalid_1's l1: 0.304163\n",
      "[3000]\ttraining's l1: 0.198674\tvalid_1's l1: 0.302696\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.198674\tvalid_1's l1: 0.302696\n",
      "3JHC Fold 1, logMAE: -1.1950269995092306\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.536396\tvalid_1's l1: 0.546981\n",
      "[200]\ttraining's l1: 0.461501\tvalid_1's l1: 0.479752\n",
      "[300]\ttraining's l1: 0.419571\tvalid_1's l1: 0.444292\n",
      "[400]\ttraining's l1: 0.391524\tvalid_1's l1: 0.421586\n",
      "[500]\ttraining's l1: 0.370301\tvalid_1's l1: 0.405399\n",
      "[600]\ttraining's l1: 0.352208\tvalid_1's l1: 0.391883\n",
      "[700]\ttraining's l1: 0.337486\tvalid_1's l1: 0.381366\n",
      "[800]\ttraining's l1: 0.324087\tvalid_1's l1: 0.372109\n",
      "[900]\ttraining's l1: 0.312445\tvalid_1's l1: 0.364092\n",
      "[1000]\ttraining's l1: 0.302523\tvalid_1's l1: 0.357575\n",
      "[1100]\ttraining's l1: 0.293554\tvalid_1's l1: 0.35198\n",
      "[1200]\ttraining's l1: 0.285538\tvalid_1's l1: 0.347116\n",
      "[1300]\ttraining's l1: 0.277953\tvalid_1's l1: 0.342511\n",
      "[1400]\ttraining's l1: 0.270808\tvalid_1's l1: 0.338331\n",
      "[1500]\ttraining's l1: 0.264135\tvalid_1's l1: 0.334476\n",
      "[1600]\ttraining's l1: 0.258128\tvalid_1's l1: 0.331022\n",
      "[1700]\ttraining's l1: 0.252306\tvalid_1's l1: 0.327976\n",
      "[1800]\ttraining's l1: 0.24671\tvalid_1's l1: 0.324822\n",
      "[1900]\ttraining's l1: 0.241601\tvalid_1's l1: 0.322315\n",
      "[2000]\ttraining's l1: 0.236688\tvalid_1's l1: 0.319695\n",
      "[2100]\ttraining's l1: 0.232179\tvalid_1's l1: 0.31737\n",
      "[2200]\ttraining's l1: 0.227826\tvalid_1's l1: 0.315151\n",
      "[2300]\ttraining's l1: 0.223607\tvalid_1's l1: 0.313055\n",
      "[2400]\ttraining's l1: 0.219658\tvalid_1's l1: 0.311114\n",
      "[2500]\ttraining's l1: 0.215965\tvalid_1's l1: 0.309349\n",
      "[2600]\ttraining's l1: 0.212248\tvalid_1's l1: 0.307589\n",
      "[2700]\ttraining's l1: 0.20873\tvalid_1's l1: 0.305907\n",
      "[2800]\ttraining's l1: 0.205326\tvalid_1's l1: 0.304432\n",
      "[2900]\ttraining's l1: 0.202131\tvalid_1's l1: 0.303016\n",
      "[3000]\ttraining's l1: 0.198919\tvalid_1's l1: 0.301649\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.198919\tvalid_1's l1: 0.301649\n",
      "3JHC Fold 2, logMAE: -1.1984906516839557\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.540765\tvalid_1's l1: 0.552179\n",
      "[200]\ttraining's l1: 0.463784\tvalid_1's l1: 0.4834\n",
      "[300]\ttraining's l1: 0.420993\tvalid_1's l1: 0.44699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's l1: 0.391894\tvalid_1's l1: 0.423608\n",
      "[500]\ttraining's l1: 0.370378\tvalid_1's l1: 0.407175\n",
      "[600]\ttraining's l1: 0.352843\tvalid_1's l1: 0.394452\n",
      "[700]\ttraining's l1: 0.337857\tvalid_1's l1: 0.383691\n",
      "[800]\ttraining's l1: 0.324905\tvalid_1's l1: 0.374698\n",
      "[900]\ttraining's l1: 0.313102\tvalid_1's l1: 0.366643\n",
      "[1000]\ttraining's l1: 0.303281\tvalid_1's l1: 0.36032\n",
      "[1100]\ttraining's l1: 0.294228\tvalid_1's l1: 0.354573\n",
      "[1200]\ttraining's l1: 0.285789\tvalid_1's l1: 0.349405\n",
      "[1300]\ttraining's l1: 0.277969\tvalid_1's l1: 0.34474\n",
      "[1400]\ttraining's l1: 0.270905\tvalid_1's l1: 0.340609\n",
      "[1500]\ttraining's l1: 0.264368\tvalid_1's l1: 0.336775\n",
      "[1600]\ttraining's l1: 0.258379\tvalid_1's l1: 0.333436\n",
      "[1700]\ttraining's l1: 0.252815\tvalid_1's l1: 0.330378\n",
      "[1800]\ttraining's l1: 0.247553\tvalid_1's l1: 0.327552\n",
      "[1900]\ttraining's l1: 0.242388\tvalid_1's l1: 0.32482\n",
      "[2000]\ttraining's l1: 0.237564\tvalid_1's l1: 0.322321\n",
      "[2100]\ttraining's l1: 0.233115\tvalid_1's l1: 0.320158\n",
      "[2200]\ttraining's l1: 0.228673\tvalid_1's l1: 0.317958\n",
      "[2300]\ttraining's l1: 0.224554\tvalid_1's l1: 0.315917\n",
      "[2400]\ttraining's l1: 0.220549\tvalid_1's l1: 0.314073\n",
      "[2500]\ttraining's l1: 0.216799\tvalid_1's l1: 0.312292\n",
      "[2600]\ttraining's l1: 0.213144\tvalid_1's l1: 0.310554\n",
      "[2700]\ttraining's l1: 0.209411\tvalid_1's l1: 0.308783\n",
      "[2800]\ttraining's l1: 0.205985\tvalid_1's l1: 0.307238\n",
      "[2900]\ttraining's l1: 0.20267\tvalid_1's l1: 0.305752\n",
      "[3000]\ttraining's l1: 0.199527\tvalid_1's l1: 0.30441\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.199527\tvalid_1's l1: 0.30441\n",
      "3JHC Fold 3, logMAE: -1.1893787599497248\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.539599\tvalid_1's l1: 0.551833\n",
      "[200]\ttraining's l1: 0.46259\tvalid_1's l1: 0.482037\n",
      "[300]\ttraining's l1: 0.42016\tvalid_1's l1: 0.445863\n",
      "[400]\ttraining's l1: 0.391088\tvalid_1's l1: 0.42216\n",
      "[500]\ttraining's l1: 0.369177\tvalid_1's l1: 0.405333\n",
      "[600]\ttraining's l1: 0.350915\tvalid_1's l1: 0.391809\n",
      "[700]\ttraining's l1: 0.336309\tvalid_1's l1: 0.381423\n",
      "[800]\ttraining's l1: 0.323447\tvalid_1's l1: 0.372514\n",
      "[900]\ttraining's l1: 0.312182\tvalid_1's l1: 0.364969\n",
      "[1000]\ttraining's l1: 0.302299\tvalid_1's l1: 0.358603\n",
      "[1100]\ttraining's l1: 0.293367\tvalid_1's l1: 0.353168\n",
      "[1200]\ttraining's l1: 0.284652\tvalid_1's l1: 0.347549\n",
      "[1300]\ttraining's l1: 0.276967\tvalid_1's l1: 0.342913\n",
      "[1400]\ttraining's l1: 0.269874\tvalid_1's l1: 0.338765\n",
      "[1500]\ttraining's l1: 0.263339\tvalid_1's l1: 0.335032\n",
      "[1600]\ttraining's l1: 0.257305\tvalid_1's l1: 0.331717\n",
      "[1700]\ttraining's l1: 0.251459\tvalid_1's l1: 0.328469\n",
      "[1800]\ttraining's l1: 0.246009\tvalid_1's l1: 0.325449\n",
      "[1900]\ttraining's l1: 0.241042\tvalid_1's l1: 0.32284\n",
      "[2000]\ttraining's l1: 0.236335\tvalid_1's l1: 0.320388\n",
      "[2100]\ttraining's l1: 0.231907\tvalid_1's l1: 0.318227\n",
      "[2200]\ttraining's l1: 0.227541\tvalid_1's l1: 0.316051\n",
      "[2300]\ttraining's l1: 0.223351\tvalid_1's l1: 0.313994\n",
      "[2400]\ttraining's l1: 0.219455\tvalid_1's l1: 0.312182\n",
      "[2500]\ttraining's l1: 0.215515\tvalid_1's l1: 0.310293\n",
      "[2600]\ttraining's l1: 0.211851\tvalid_1's l1: 0.308639\n",
      "[2700]\ttraining's l1: 0.208357\tvalid_1's l1: 0.307051\n",
      "[2800]\ttraining's l1: 0.204851\tvalid_1's l1: 0.305416\n",
      "[2900]\ttraining's l1: 0.201533\tvalid_1's l1: 0.303888\n",
      "[3000]\ttraining's l1: 0.198323\tvalid_1's l1: 0.30242\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.198323\tvalid_1's l1: 0.30242\n",
      "3JHC Fold 4, logMAE: -1.1959389742918953\n",
      "*** Training Model for 3JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'd_1_0', 'd_2_0', 'd_2_1', 'd_3_0', 'd_3_1', 'd_3_2', 'd_4_0',\n",
      "       'd_4_1', 'd_4_2', 'd_4_3', 'd_5_0', 'd_5_1', 'd_5_2', 'd_5_3', 'd_6_0',\n",
      "       'd_6_1', 'd_6_2', 'd_6_3', 'd_7_0', 'd_7_1', 'd_7_2', 'd_7_3', 'd_8_0',\n",
      "       'd_8_1', 'd_8_2', 'd_8_3', 'd_9_0', 'd_9_1', 'd_9_2', 'd_9_3'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.138984\tvalid_1's l1: 0.164109\n",
      "[200]\ttraining's l1: 0.108331\tvalid_1's l1: 0.144203\n",
      "[300]\ttraining's l1: 0.0913508\tvalid_1's l1: 0.134825\n",
      "[400]\ttraining's l1: 0.0796849\tvalid_1's l1: 0.12894\n",
      "[500]\ttraining's l1: 0.0709276\tvalid_1's l1: 0.125044\n",
      "[600]\ttraining's l1: 0.0639301\tvalid_1's l1: 0.122009\n",
      "[700]\ttraining's l1: 0.0580918\tvalid_1's l1: 0.119766\n",
      "[800]\ttraining's l1: 0.0532598\tvalid_1's l1: 0.117914\n",
      "[900]\ttraining's l1: 0.0490585\tvalid_1's l1: 0.116511\n",
      "[1000]\ttraining's l1: 0.0454385\tvalid_1's l1: 0.11529\n",
      "[1100]\ttraining's l1: 0.0422987\tvalid_1's l1: 0.11429\n",
      "[1200]\ttraining's l1: 0.0395158\tvalid_1's l1: 0.113432\n",
      "[1300]\ttraining's l1: 0.0370609\tvalid_1's l1: 0.112716\n",
      "[1400]\ttraining's l1: 0.0348533\tvalid_1's l1: 0.112111\n",
      "[1500]\ttraining's l1: 0.0328438\tvalid_1's l1: 0.111579\n",
      "[1600]\ttraining's l1: 0.0310564\tvalid_1's l1: 0.111113\n",
      "[1700]\ttraining's l1: 0.0294128\tvalid_1's l1: 0.110659\n",
      "[1800]\ttraining's l1: 0.0279025\tvalid_1's l1: 0.110302\n",
      "[1900]\ttraining's l1: 0.0265198\tvalid_1's l1: 0.109956\n",
      "[2000]\ttraining's l1: 0.0252148\tvalid_1's l1: 0.109635\n",
      "[2100]\ttraining's l1: 0.0240315\tvalid_1's l1: 0.109347\n",
      "[2200]\ttraining's l1: 0.0229427\tvalid_1's l1: 0.109086\n",
      "[2300]\ttraining's l1: 0.0219321\tvalid_1's l1: 0.108824\n",
      "[2400]\ttraining's l1: 0.0210063\tvalid_1's l1: 0.108629\n",
      "[2500]\ttraining's l1: 0.0201436\tvalid_1's l1: 0.108435\n",
      "[2600]\ttraining's l1: 0.0193186\tvalid_1's l1: 0.108262\n",
      "[2700]\ttraining's l1: 0.0185705\tvalid_1's l1: 0.108088\n",
      "[2800]\ttraining's l1: 0.0178608\tvalid_1's l1: 0.107935\n",
      "[2900]\ttraining's l1: 0.0171849\tvalid_1's l1: 0.107779\n",
      "[3000]\ttraining's l1: 0.016554\tvalid_1's l1: 0.107628\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.016554\tvalid_1's l1: 0.107628\n",
      "3JHN Fold 0, logMAE: -2.229074065655416\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.138983\tvalid_1's l1: 0.161035\n",
      "[200]\ttraining's l1: 0.108421\tvalid_1's l1: 0.141263\n",
      "[300]\ttraining's l1: 0.0912492\tvalid_1's l1: 0.132005\n",
      "[400]\ttraining's l1: 0.0795829\tvalid_1's l1: 0.126317\n",
      "[500]\ttraining's l1: 0.0707732\tvalid_1's l1: 0.122576\n",
      "[600]\ttraining's l1: 0.0637266\tvalid_1's l1: 0.119733\n",
      "[700]\ttraining's l1: 0.0579611\tvalid_1's l1: 0.117581\n",
      "[800]\ttraining's l1: 0.0531758\tvalid_1's l1: 0.115839\n",
      "[900]\ttraining's l1: 0.0490765\tvalid_1's l1: 0.114471\n",
      "[1000]\ttraining's l1: 0.0455765\tvalid_1's l1: 0.113357\n",
      "[1100]\ttraining's l1: 0.0423976\tvalid_1's l1: 0.112302\n",
      "[1200]\ttraining's l1: 0.0396125\tvalid_1's l1: 0.111503\n",
      "[1300]\ttraining's l1: 0.0371313\tvalid_1's l1: 0.110769\n",
      "[1400]\ttraining's l1: 0.0348771\tvalid_1's l1: 0.11009\n",
      "[1500]\ttraining's l1: 0.0328658\tvalid_1's l1: 0.109527\n",
      "[1600]\ttraining's l1: 0.0310386\tvalid_1's l1: 0.109003\n",
      "[1700]\ttraining's l1: 0.0293848\tvalid_1's l1: 0.10857\n",
      "[1800]\ttraining's l1: 0.0278714\tvalid_1's l1: 0.108148\n",
      "[1900]\ttraining's l1: 0.0265147\tvalid_1's l1: 0.107783\n",
      "[2000]\ttraining's l1: 0.0252307\tvalid_1's l1: 0.107453\n",
      "[2100]\ttraining's l1: 0.0240624\tvalid_1's l1: 0.107197\n",
      "[2200]\ttraining's l1: 0.0229641\tvalid_1's l1: 0.106935\n",
      "[2300]\ttraining's l1: 0.0219343\tvalid_1's l1: 0.1067\n",
      "[2400]\ttraining's l1: 0.0210234\tvalid_1's l1: 0.106481\n",
      "[2500]\ttraining's l1: 0.0201478\tvalid_1's l1: 0.106277\n",
      "[2600]\ttraining's l1: 0.0193355\tvalid_1's l1: 0.106092\n",
      "[2700]\ttraining's l1: 0.0185683\tvalid_1's l1: 0.105913\n",
      "[2800]\ttraining's l1: 0.0178549\tvalid_1's l1: 0.105742\n",
      "[2900]\ttraining's l1: 0.0171896\tvalid_1's l1: 0.105593\n",
      "[3000]\ttraining's l1: 0.0165853\tvalid_1's l1: 0.105458\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0165853\tvalid_1's l1: 0.105458\n",
      "3JHN Fold 1, logMAE: -2.249440506114124\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.138158\tvalid_1's l1: 0.165082\n",
      "[200]\ttraining's l1: 0.107299\tvalid_1's l1: 0.145123\n",
      "[300]\ttraining's l1: 0.0903991\tvalid_1's l1: 0.135928\n",
      "[400]\ttraining's l1: 0.0787636\tvalid_1's l1: 0.130061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's l1: 0.0699635\tvalid_1's l1: 0.126261\n",
      "[600]\ttraining's l1: 0.0631307\tvalid_1's l1: 0.123441\n",
      "[700]\ttraining's l1: 0.0574067\tvalid_1's l1: 0.121307\n",
      "[800]\ttraining's l1: 0.0526648\tvalid_1's l1: 0.119627\n",
      "[900]\ttraining's l1: 0.0485929\tvalid_1's l1: 0.11806\n",
      "[1000]\ttraining's l1: 0.0450832\tvalid_1's l1: 0.116789\n",
      "[1100]\ttraining's l1: 0.0418889\tvalid_1's l1: 0.115737\n",
      "[1200]\ttraining's l1: 0.0391767\tvalid_1's l1: 0.114859\n",
      "[1300]\ttraining's l1: 0.0366864\tvalid_1's l1: 0.114048\n",
      "[1400]\ttraining's l1: 0.0344687\tvalid_1's l1: 0.113367\n",
      "[1500]\ttraining's l1: 0.0324841\tvalid_1's l1: 0.112833\n",
      "[1600]\ttraining's l1: 0.0307103\tvalid_1's l1: 0.11234\n",
      "[1700]\ttraining's l1: 0.029094\tvalid_1's l1: 0.111926\n",
      "[1800]\ttraining's l1: 0.0275995\tvalid_1's l1: 0.11152\n",
      "[1900]\ttraining's l1: 0.0262292\tvalid_1's l1: 0.111173\n",
      "[2000]\ttraining's l1: 0.0249585\tvalid_1's l1: 0.110823\n",
      "[2100]\ttraining's l1: 0.0238215\tvalid_1's l1: 0.110544\n",
      "[2200]\ttraining's l1: 0.0227494\tvalid_1's l1: 0.110306\n",
      "[2300]\ttraining's l1: 0.0217421\tvalid_1's l1: 0.110047\n",
      "[2400]\ttraining's l1: 0.0208135\tvalid_1's l1: 0.109834\n",
      "[2500]\ttraining's l1: 0.0199556\tvalid_1's l1: 0.109648\n",
      "[2600]\ttraining's l1: 0.0191599\tvalid_1's l1: 0.109471\n",
      "[2700]\ttraining's l1: 0.0184225\tvalid_1's l1: 0.109293\n",
      "[2800]\ttraining's l1: 0.0177264\tvalid_1's l1: 0.109096\n",
      "[2900]\ttraining's l1: 0.0170689\tvalid_1's l1: 0.108943\n",
      "[3000]\ttraining's l1: 0.0164523\tvalid_1's l1: 0.108818\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0164523\tvalid_1's l1: 0.108818\n",
      "3JHN Fold 2, logMAE: -2.2180749331863807\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.139793\tvalid_1's l1: 0.165588\n",
      "[200]\ttraining's l1: 0.108284\tvalid_1's l1: 0.145036\n",
      "[300]\ttraining's l1: 0.0911952\tvalid_1's l1: 0.135724\n",
      "[400]\ttraining's l1: 0.0796706\tvalid_1's l1: 0.129938\n",
      "[500]\ttraining's l1: 0.0708402\tvalid_1's l1: 0.126067\n",
      "[600]\ttraining's l1: 0.0637485\tvalid_1's l1: 0.123304\n",
      "[700]\ttraining's l1: 0.0580798\tvalid_1's l1: 0.121057\n",
      "[800]\ttraining's l1: 0.0532635\tvalid_1's l1: 0.119171\n",
      "[900]\ttraining's l1: 0.0490668\tvalid_1's l1: 0.117759\n",
      "[1000]\ttraining's l1: 0.0455278\tvalid_1's l1: 0.116624\n",
      "[1100]\ttraining's l1: 0.0424063\tvalid_1's l1: 0.115614\n",
      "[1200]\ttraining's l1: 0.0395799\tvalid_1's l1: 0.114915\n",
      "[1300]\ttraining's l1: 0.0370827\tvalid_1's l1: 0.114196\n",
      "[1400]\ttraining's l1: 0.0348922\tvalid_1's l1: 0.113523\n",
      "[1500]\ttraining's l1: 0.0328981\tvalid_1's l1: 0.113003\n",
      "[1600]\ttraining's l1: 0.0310462\tvalid_1's l1: 0.112519\n",
      "[1700]\ttraining's l1: 0.0294094\tvalid_1's l1: 0.112102\n",
      "[1800]\ttraining's l1: 0.027913\tvalid_1's l1: 0.111711\n",
      "[1900]\ttraining's l1: 0.0264986\tvalid_1's l1: 0.111372\n",
      "[2000]\ttraining's l1: 0.0252204\tvalid_1's l1: 0.111073\n",
      "[2100]\ttraining's l1: 0.0240384\tvalid_1's l1: 0.110776\n",
      "[2200]\ttraining's l1: 0.022938\tvalid_1's l1: 0.110531\n",
      "[2300]\ttraining's l1: 0.0219252\tvalid_1's l1: 0.110313\n",
      "[2400]\ttraining's l1: 0.0210023\tvalid_1's l1: 0.110109\n",
      "[2500]\ttraining's l1: 0.0201277\tvalid_1's l1: 0.109887\n",
      "[2600]\ttraining's l1: 0.019324\tvalid_1's l1: 0.109704\n",
      "[2700]\ttraining's l1: 0.0185505\tvalid_1's l1: 0.109495\n",
      "[2800]\ttraining's l1: 0.0178422\tvalid_1's l1: 0.109347\n",
      "[2900]\ttraining's l1: 0.0171831\tvalid_1's l1: 0.10922\n",
      "[3000]\ttraining's l1: 0.0165593\tvalid_1's l1: 0.109074\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0165593\tvalid_1's l1: 0.109074\n",
      "3JHN Fold 3, logMAE: -2.2157284076772563\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.139532\tvalid_1's l1: 0.165496\n",
      "[200]\ttraining's l1: 0.107855\tvalid_1's l1: 0.14452\n",
      "[300]\ttraining's l1: 0.0909758\tvalid_1's l1: 0.134805\n",
      "[400]\ttraining's l1: 0.0793625\tvalid_1's l1: 0.128926\n",
      "[500]\ttraining's l1: 0.0706411\tvalid_1's l1: 0.125201\n",
      "[600]\ttraining's l1: 0.0636428\tvalid_1's l1: 0.122466\n",
      "[700]\ttraining's l1: 0.058027\tvalid_1's l1: 0.120248\n",
      "[800]\ttraining's l1: 0.0531671\tvalid_1's l1: 0.118427\n",
      "[900]\ttraining's l1: 0.0489867\tvalid_1's l1: 0.117057\n",
      "[1000]\ttraining's l1: 0.0455071\tvalid_1's l1: 0.115881\n",
      "[1100]\ttraining's l1: 0.0424025\tvalid_1's l1: 0.114929\n",
      "[1200]\ttraining's l1: 0.0396046\tvalid_1's l1: 0.114085\n",
      "[1300]\ttraining's l1: 0.0371308\tvalid_1's l1: 0.113345\n",
      "[1400]\ttraining's l1: 0.0349265\tvalid_1's l1: 0.112691\n",
      "[1500]\ttraining's l1: 0.0328855\tvalid_1's l1: 0.112122\n",
      "[1600]\ttraining's l1: 0.0311031\tvalid_1's l1: 0.111609\n",
      "[1700]\ttraining's l1: 0.0294269\tvalid_1's l1: 0.111191\n",
      "[1800]\ttraining's l1: 0.0279003\tvalid_1's l1: 0.110825\n",
      "[1900]\ttraining's l1: 0.0265092\tvalid_1's l1: 0.110462\n",
      "[2000]\ttraining's l1: 0.0252422\tvalid_1's l1: 0.110132\n",
      "[2100]\ttraining's l1: 0.0240699\tvalid_1's l1: 0.109803\n",
      "[2200]\ttraining's l1: 0.0229503\tvalid_1's l1: 0.109531\n",
      "[2300]\ttraining's l1: 0.0219564\tvalid_1's l1: 0.109321\n",
      "[2400]\ttraining's l1: 0.021011\tvalid_1's l1: 0.1091\n",
      "[2500]\ttraining's l1: 0.0201377\tvalid_1's l1: 0.108902\n",
      "[2600]\ttraining's l1: 0.0193187\tvalid_1's l1: 0.108705\n",
      "[2700]\ttraining's l1: 0.0185652\tvalid_1's l1: 0.108527\n",
      "[2800]\ttraining's l1: 0.0178581\tvalid_1's l1: 0.108381\n",
      "[2900]\ttraining's l1: 0.0171856\tvalid_1's l1: 0.108239\n",
      "[3000]\ttraining's l1: 0.0165492\tvalid_1's l1: 0.108101\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's l1: 0.0165492\tvalid_1's l1: 0.108101\n",
      "3JHN Fold 4, logMAE: -2.224692815047959\n"
     ]
=======
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3953628002312313"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(cv_scores.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[submission['scalar_coupling_constant'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4658147</th>\n",
       "      <td>24.443258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658148</th>\n",
       "      <td>142.937302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658149</th>\n",
       "      <td>9.953008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658150</th>\n",
       "      <td>142.937302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658151</th>\n",
       "      <td>24.443258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658152</th>\n",
       "      <td>93.242844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658153</th>\n",
       "      <td>2.555109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658154</th>\n",
       "      <td>-7.562157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658155</th>\n",
       "      <td>-9.632586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658156</th>\n",
       "      <td>93.242844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scalar_coupling_constant\n",
       "id                               \n",
       "4658147  24.443258               \n",
       "4658148  142.937302              \n",
       "4658149  9.953008                \n",
       "4658150  142.937302              \n",
       "4658151  24.443258               \n",
       "4658152  93.242844               \n",
       "4658153  2.555109                \n",
       "4658154 -7.562157                \n",
       "4658155 -9.632586                \n",
       "4658156  93.242844               "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> f38c5a3fada567d5fd5ef03c20ccba924f0bb423
    }
   ],
   "source": [
    "model_params = {\n",
    "    '1JHN': 7,\n",
    "    '1JHC': 10,\n",
    "    '2JHH': 9,\n",
    "    '2JHN': 9,\n",
    "    '2JHC': 9,\n",
    "    '3JHH': 9,\n",
    "    '3JHC': 10,\n",
    "    '3JHN': 10\n",
    "}\n",
    "N_FOLDS = 5\n",
    "submission = submission_csv.copy()\n",
    "\n",
    "cv_scores = {}\n",
    "for coupling_type in model_params.keys():\n",
    "    cv_score = train_and_predict_for_one_coupling_type(\n",
    "        coupling_type, submission, n_atoms=model_params[coupling_type], n_folds=N_FOLDS)\n",
    "    cv_scores[coupling_type] = cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'type': list(cv_scores.keys()), 'cv_score': list(cv_scores.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(list(cv_scores.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[submission['scalar_coupling_constant'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(f'{SUBMISSIONS_PATH}/sub_lightgbm_maxdepth=25.csv')"
=======
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(f'{SUBMISSIONS_PATH}/sub_lightgbm_two_params.csv')"
>>>>>>> f38c5a3fada567d5fd5ef03c20ccba924f0bb423
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = list(df.columns)\n",
    "cols.remove('scalar_coupling_constant')\n",
    "cols\n",
    "df_importance = pd.DataFrame({'feature': cols, 'importance': model.feature_importances_})\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=df_importance.sort_values('importance', ascending=False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
