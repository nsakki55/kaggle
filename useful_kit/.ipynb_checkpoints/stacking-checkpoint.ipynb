{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 複数の弱学習機を組み合わせたアンサンブル手法：スタッキング\n",
    "ここのカーネルを参考にしたので、困ったら個々に戻るのが良い\n",
    "https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最も単純なスタッキング。各モデルの予測を平均した値を用いるというもの"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classに引数を入れると継承ができる\n",
    "class AveraginModels(BaseEstimator,RegressorMixin,TransformerMixin):\n",
    "    def __init__(self,models):\n",
    "        self.models=models\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        # clone モデルの複製\n",
    "        self.models_=[clone(x) for x in self.models]\n",
    "        \n",
    "        for model in self.models_:\n",
    "            model.fit(X,y)\n",
    "        \n",
    "        # selfはクラスなので、もう一度自分自身を呼び出す\n",
    "        return self\n",
    "\n",
    "    def predict(self,X):\n",
    "        \n",
    "        predictions=np.column_stack([model.predict(X) for model in self.models_])\n",
    "        \n",
    "        return np.mean(predictions,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "すでに作成済みの弱学習器を入れることで、スタッキングモデルのインスタンスを作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_models = AveragingModels(models = (ENet, GBoost, KRR, lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StackingAverageModelsではモデルを返す\n",
    "\n",
    "class StackingAverageModels(BaseEstimator,RegressorMixin,TransformerMixin):\n",
    "    \n",
    "    def __init__(self,base_models,meta_model,n_folds=5):\n",
    "        self.base_models=base_models\n",
    "        self.meta_model=meta_model\n",
    "        self.n_folds=n_folds\n",
    "        \n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        # base_modelを入れるための空の配列を作成\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        # meta_modelをclone\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        # k交差分割\n",
    "        kfold=KFold(n_splits=self.n_folds,shuffle=True,random_state=156)\n",
    "        \n",
    "        # k交差分割で検証用に選ばれたデータで予測した値を格納\n",
    "        out_of_fold_predictions=np.zeros((X.shape[0],len(self.base_models)))\n",
    "        \n",
    "        # base_modelごとにおこなう\n",
    "        for i,model in enumerate(self.base_models):\n",
    "            # k交差分割を各モデルごと行う\n",
    "            for train_index,holdout_index in kfold.split(X,y):\n",
    "                # 元のモデルに影響がないようにcloneする\n",
    "                instance=clone(model)\n",
    "                # base_models_に使用したベースモデルを追加\n",
    "                self.base_models_[i].append(instance)\n",
    "                # 学習\n",
    "                instance.fit(X[train_index],y[train_index])\n",
    "                # 学習したモデルで検証用データを予測\n",
    "                y_pred=instance.predict(X[holdout_index])\n",
    "                # 予測した値を格納\n",
    "                out_of_fold_predictions[holdout_index,i]=y_pred\n",
    "            \n",
    "       # メタモデルでベースモデルが検証用データで予測した値で学習 \n",
    "        self.meta_model_.fit(out_of_fold_predictions,y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n",
    "                                                 meta_model = lasso)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
