{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorary Data Analysis (EDA)\n",
    "EDAを行うことにより  \n",
    "・データを理解するのに役立つ  \n",
    "・データに対する直感を立てる  \n",
    "・ターゲットデータへの仮説を作ることができる  \n",
    "・新しいデータ作成のための洞察を得ることができる。\n",
    "## Visualization\n",
    "可視化はEDAで最も役にたつ手法  \n",
    "データに対する仮説を立てることが可能。magic featuresを見つけることができる。  \n",
    "まずは初めにEDAを行う。モデルの作成から行ってはいけない。\n",
    "<img src=\"images/eda1.png\" width='300px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDAの流れ\n",
    "### 1. データのdomainについて理解を得る。\n",
    "自分が行なおうとしている領域に対して、それぞれの特徴量がどのような意味を持っているのか理解する。  \n",
    "kaggleは様々な分野の問題がでるので、その都度特徴量の意味をきちんと理解する必要がある。  \n",
    "### 2. データが妥当かどうか調べる\n",
    "データのdomainについての理解を得ることができれば、各カラムの特徴量の値が、その特徴量の持つ意味合いを考えて妥当な値かどうかチェックする。  \n",
    "ex) ageの特徴量に200という値がある場合は、除外する必要がある。\n",
    "### 3. データがどのように作成されたのか調べる\n",
    "訓練データとテストデータが異なる方法で作成されていた場合、検証データを訓練データから作成することができない。  \n",
    "データが作られた背景を調べることは、適切な評価を行う上で重要になる\n",
    "\n",
    "## 匿名化されたデータの扱い\n",
    "企業が情報を公開したくないため、データのカラム名をダミーの名前にしたり、文字列をハッシュ化させた値を使用しているデータのことを言う。  \n",
    "### 1. 各特徴量を調べる\n",
    "・カラムの意味を推測する  \n",
    "・カラムのタイプを推測する。\n",
    "categorical, numeric, text特徴量か調べることが最も重要。  \n",
    "流れは、まずはdf.head()で特徴量の様子を確認し、ラベルエンコーディングで文字列データを分類器にかけられるように直してから、ランダムフォレストに入れる。そして、重要な特徴量は何だったかを確認して、重要な特徴量を具体的にスケーリングしながら確認する。\n",
    "### 2. 特徴量の関係性を調べる  \n",
    "・ペアごとの関係を明らかにする  \n",
    "・特徴量のグループを明らかにする。  \n",
    "<img src=\"images/eda2.png\" width='300px'>\n",
    "### 便利なPandas機能  \n",
    "df.dtypes  \n",
    "df.info()  \n",
    "x.value_counts()  \n",
    "x.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "## 各特徴量ごとの様子を確認\n",
    "### histograms\n",
    "ヒスグラムはデータの分布をみる最も簡単な方法。ヒストグラムの欠点は、表示するスケールによっては、データの偏りを誤解してしまう可能性がある。  \n",
    "複数のプロットをする必要があるので注意。  \n",
    "下の図のピークは欠損値に平均の値を入れていることを表す。こういった場合は、欠損値を表す値（-999）などを入れるなどをする。\n",
    "<img src=\"images/visualization1.png\" width='300px'>\n",
    "### 単純なプロット plt. plot()\n",
    "### 統計データ\n",
    "df.describe()\n",
    "### 要素数のカウント\n",
    "x.value_counts()\n",
    "\n",
    "## 特徴量間の関係を確認\n",
    "### 散布図　scatterplot\n",
    "二つの特徴量間での分布の様子を可視化。  \n",
    "訓練データとテストデータを同時にプロットしたときに、分布が似ていなければ何か問題があるとわかる。\n",
    "<img src=\"images/visualization2.png\" width='300px'>\n",
    "### ヒートマップ図\n",
    "各特徴量間の相関関係を表したグラフ。  \n",
    "特徴量をグループ分けし、新しい特徴量を作成する際に役に立つ\n",
    "<img src=\"images/visualization3.png\" width='300px'>\n",
    "### 平均の値でプロット\n",
    "df.mean().plot(style='.') 各特徴量ごとの平均値でプロットすることで、グループ分けが行いやすくなる\n",
    "<img src=\"images/visualization4.png\" width='300px'>\n",
    "df.mean().sort_values().plot(style='.')\n",
    "<img src=\"images/visualization5.png\" width='300px'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Cleaning and other things to checks\n",
    "## Duplicated and constant features\n",
    "### ・要素が一つしかない特徴量  \n",
    "train.unique()==1  \n",
    "訓練データは一定値だが、テストデータには訓練データに存在しなかった要素がある場合、問題は複雑となる。  \n",
    "新しい特徴量を作るか、取り除くことによって対応する必要がある。  \n",
    "### ・重複している特徴量\n",
    "別の特徴量と重複している場合は、モデルの性能に寄与せず、訓練時間を延ばすだけので削除する  \n",
    "数値データの場合はtrain.T.drop_duplicates()  \n",
    "categorical特徴量の場合は、見た目は異なっていても、内容は全く同じ内容の場合があるので注意する。  \n",
    "for f in categorical_features:  \n",
    "　　trainf[f]=train[f].factorize()  \n",
    "　　train.T.drop_duplicates()　　\n",
    "<img src=\"images/visualization6.png\" width='300px'>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation and overfitting\n",
    "validationを十分におこなわないと、プライベートテストデータで大きく順位を下げることになる。  \n",
    "モデルが訓練データセットに対して適応しすぎると汎化性能を失う。\n",
    "<img src=\"images/validation1.png\" width='400px'> \n",
    "## validation type\n",
    "### 1. Holdout\n",
    "sklearn.model_selection.ShuffleSplit  \n",
    "データを単純に訓練データと検証データに分ける方法  \n",
    "### 2. kFold\n",
    "データを訓練データと検証データに、k回分け、検証データの平均値をとる。  \n",
    "学習時間がk倍になるので注意\n",
    "### 3. strafication\n",
    "各ラベルが均等に分配されるように分割される。kFoldよりも有効性が高い  \n",
    "\n",
    "## Validation Strategy\n",
    "時系列データで検証データを作成する際は、モデルが未来のデータに対する予測を行うものなので、時間軸で後ろのほうのデータを検証データにする必要がある。\n",
    "<img src=\"images/validation2.png\" width='400px'>  \n",
    "\n",
    "### 1. random,rowwise\n",
    "順番をシャッフルして検証データに分ける。\n",
    "### 2. timewise\n",
    "時系列データでは、未来の予測になるように検証データを分ける\n",
    "### 3. By ID\n",
    "Id-based split。データセットのIDを基準にして分ける。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
