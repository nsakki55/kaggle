{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas_profiling as pdp\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import display\n",
    "import collections\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rent</th>\n",
       "      <th>address</th>\n",
       "      <th>access</th>\n",
       "      <th>floor_info</th>\n",
       "      <th>old</th>\n",
       "      <th>direction</th>\n",
       "      <th>square</th>\n",
       "      <th>floor</th>\n",
       "      <th>bath</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>facility</th>\n",
       "      <th>parking</th>\n",
       "      <th>neighbors</th>\n",
       "      <th>structure</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>東京都北区滝野川３丁目</td>\n",
       "      <td>都営三田線\\t西巣鴨駅\\t徒歩4分\\t\\t埼京線\\t板橋駅\\t徒歩14分\\t\\t都電荒川線\\...</td>\n",
       "      <td>1K</td>\n",
       "      <td>9年9ヶ月</td>\n",
       "      <td>南東</td>\n",
       "      <td>20.01m2</td>\n",
       "      <td>1階／12階建</td>\n",
       "      <td>専用バス／\\t専用トイレ／\\tバス・トイレ別／\\tシャワー／\\t浴室乾燥機\\t／\\t温水洗浄便座</td>\n",
       "      <td>ガスコンロ／\\tコンロ2口／\\tシステムキッチン\\t／\\t給湯</td>\n",
       "      <td>インターネット対応／\\tCATV／\\tCSアンテナ／\\tBSアンテナ</td>\n",
       "      <td>エアコン付\\tシューズボックス／\\tバルコニー／\\tフローリング／\\t室内洗濯機置場／\\t敷...</td>\n",
       "      <td>駐輪場\\t空有</td>\n",
       "      <td>【小学校】 495m\\t【大学】 461m\\t【小学校】 962m\\t【公園】 1103m\\...</td>\n",
       "      <td>RC（鉄筋コンクリート）</td>\n",
       "      <td>2年間</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     rent      address  \\\n",
       "0   1  75000.0  東京都北区滝野川３丁目   \n",
       "\n",
       "                                              access floor_info    old  \\\n",
       "0  都営三田線\\t西巣鴨駅\\t徒歩4分\\t\\t埼京線\\t板橋駅\\t徒歩14分\\t\\t都電荒川線\\...         1K  9年9ヶ月   \n",
       "\n",
       "  direction   square    floor  \\\n",
       "0        南東  20.01m2  1階／12階建   \n",
       "\n",
       "                                               bath  \\\n",
       "0  専用バス／\\t専用トイレ／\\tバス・トイレ別／\\tシャワー／\\t浴室乾燥機\\t／\\t温水洗浄便座   \n",
       "\n",
       "                           kitchen                           broadcast  \\\n",
       "0  ガスコンロ／\\tコンロ2口／\\tシステムキッチン\\t／\\t給湯  インターネット対応／\\tCATV／\\tCSアンテナ／\\tBSアンテナ   \n",
       "\n",
       "                                            facility  parking  \\\n",
       "0  エアコン付\\tシューズボックス／\\tバルコニー／\\tフローリング／\\t室内洗濯機置場／\\t敷...  駐輪場\\t空有   \n",
       "\n",
       "                                           neighbors     structure period  \n",
       "0  【小学校】 495m\\t【大学】 461m\\t【小学校】 962m\\t【公園】 1103m\\...  RC（鉄筋コンクリート）    2年間  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('../input/train.csv')\n",
    "test=pd.read_csv('../input/test.csv')\n",
    "sample=pd.read_csv('../input/sample_submit.csv')\n",
    "\n",
    "train_index=len(train)\n",
    "test_index=len(test)\n",
    "df_all=pd.concat([train,test],axis=0,sort=False).reset_index(drop=True)\n",
    "\n",
    "df_all.columns=['id','rent','address','access','floor_info','old','direction','square','floor','bath','kitchen','broadcast','facility','parking','neighbors','structure','period']\n",
    "df_all[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 所在地を区、町で分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['太子堂一丁目', '本羽田一丁目', '東品川四丁目', '大森北一丁目', '八雲二丁目']\n"
     ]
    }
   ],
   "source": [
    "# 住所から区を取得\n",
    "df_all['address']=df_all['address'].apply(lambda x:x.split('都')[1])\n",
    "df_all['address_city']=df_all['address'].apply(lambda x:x.split('区')[0])\n",
    "\n",
    "le_city=LabelEncoder()\n",
    "df_all['address_city']=le_city.fit_transform(df_all['address_city'])\n",
    "df_all['address_city']=df_all['address_city'].astype('category')\n",
    "\n",
    "# 住所から町名を取得\n",
    "town_tmp=df_all['address'].apply(lambda x:x.split('区')[1])\n",
    "df_all['address_town']=town_tmp.apply(lambda x:re.split(r'\\d+',x)[0])\n",
    "\n",
    "miss_town=[w  for w in df_all['address_town'].unique() if '丁目'in w]\n",
    "print(miss_town)\n",
    "\n",
    "def clean_town(src):\n",
    "    if src in miss_town:\n",
    "        return re.split('[一,二,四]丁目',src)[0]\n",
    "    else:\n",
    "        return src\n",
    "    \n",
    "df_all['address_town']=df_all['address_town'].apply(lambda x:clean_town(x))\n",
    "\n",
    "le_town=LabelEncoder()\n",
    "df_all['address_town']=le_town.fit_transform(df_all['address_town'])\n",
    "df_all['address_town']=df_all['address_town'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アクセス特徴の一つから路線と駅名、距離をとる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  アクセス情報の初めの要素から路線と駅名をとる\n",
    "df_all['train_line']=df_all['access'].apply(lambda x:x.split('\\t')[0])\n",
    "df_all['train_station']=df_all['access'].apply(lambda x:x.split('\\t')[1])\n",
    "\n",
    "# バス移動のものはバス特徴量にまとめる\n",
    "df_all['station_access']=df_all['access'].apply(lambda x:x.split('\\t')[2])\n",
    "df_all['station_access']=df_all['station_access'].apply(lambda x:'車移動' if 'バス' in x or '車' in x else x)\n",
    "\n",
    "#  数値型に変更\n",
    "def enc_num(x):\n",
    "    if x=='車移動':\n",
    "        return 999\n",
    "    else:\n",
    "        return int(re.findall(f'\\d+',x)[0])\n",
    "    \n",
    "df_all['station_access']=df_all['station_access'].apply(lambda x:enc_num(x))\n",
    "\n",
    "for col in ['train_line','train_station']:\n",
    "    le=LabelEncoder()\n",
    "    df_all[col]=le.fit_transform(df_all[col])\n",
    "    df_all[col]=df_all[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  フロア情報をカテゴリエンコ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_floor_info=LabelEncoder()\n",
    "le_floor_info.fit(df_all['floor_info'])\n",
    "df_all['floor_cat']=le_floor_info.transform(df_all['floor_info'])\n",
    "df_all['floor_cat']=df_all['floor_cat'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  築年数を月単位の経過日数に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['old_num']=df_all['old'].apply(lambda x:int(x.split('年')[0])*12+int(x.split('年')[1].split('ヶ月')[0])+1 if x!='新築' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  方角をカテゴリエンコ、欠損を最頻値の南で補完\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欠損数: 5557\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(df_all['direction'].value_counts())\n",
    "print('欠損数:',df_all['direction'].isnull().sum())\n",
    "df_all['direction'].fillna('南',inplace=True)\n",
    "\n",
    "le_direction=LabelEncoder()\n",
    "df_all['direction_cat']=le_direction.fit_transform(df_all['direction'])\n",
    "df_all['direction_cat']=df_all['direction_cat'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 面積を数値化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['square_num']=df_all['square'].apply(lambda x:float(x.split('m')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 部屋の階、何階建てか、地下室の有無を数値化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def room_floor(src):\n",
    "    tmp=src.split('／')\n",
    "    # floor_infoは２分割までできるので、分割できる場合は、一つ目の要素が部屋の階\n",
    "    if len(tmp)==2:\n",
    "        return tmp[0]\n",
    "    \n",
    "    if len(tmp)==1:\n",
    "        if '階建' in tmp[0]:\n",
    "             return -999\n",
    "        else:\n",
    "            return tmp[0]\n",
    "\n",
    "def room_floor_enc(x):\n",
    "    #  数字部分の抜き出し\n",
    "    if x==-999:\n",
    "        return -999\n",
    "    elif x=='':\n",
    "        return -999\n",
    "    \n",
    "    else:\n",
    "\n",
    "        num=re.findall(r'\\d+',x)[0]\n",
    "    #  地下の場合はマイナスにする\n",
    "    if '地下' in x:\n",
    "        return -1*int(num)\n",
    "    else:\n",
    "        return int(num)\n",
    "    \n",
    " #  部屋の階を数値化\n",
    "df_all['floor']=df_all['floor'].fillna('2階／2階建')        \n",
    "df_all['room_floor']=df_all['floor'].apply(lambda x:room_floor(x))\n",
    "df_all['room_floor']=df_all['room_floor'].apply(lambda x:room_floor_enc(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_floor(src):\n",
    "    tmp=src.split('／')\n",
    "    # floor_infoは２分割までできるので、分割できる場合は、一つ目の要素が部屋の階\n",
    "    if len(tmp)==2:\n",
    "        return tmp[1]\n",
    "    \n",
    "    if len(tmp)==1:\n",
    "        if '階建' in tmp[0]:\n",
    "             return tmp[0]\n",
    "        else:\n",
    "            return -999\n",
    "\n",
    "# 何階建かを取得\n",
    "def building_floor_enc(x):\n",
    "    if x==-999:\n",
    "        return -999\n",
    "        \n",
    "    else:\n",
    "        return int(x.split('階建')[0])\n",
    "    \n",
    "# 　地下の階数を取得\n",
    "def check_underground(x):\n",
    "# 欠損部分は、0を埋める\n",
    "    if x==-999:\n",
    "        return 0\n",
    "    else:\n",
    "        under_info=re.findall('地下+\\d',x)\n",
    "        if len(under_info)==0:\n",
    "            return 0\n",
    "        else:\n",
    "            return int(re.findall('地下+\\d',x)[0][-1])\n",
    "    \n",
    "df_all['floor']=df_all['floor'].fillna('2階／2階建')        \n",
    "df_all['building_floor']=df_all['floor'].apply(lambda x:building_floor(x))\n",
    "\n",
    "# 地下特徴量を加える\n",
    "df_all['underground']=0\n",
    "df_all['underground']=df_all['building_floor'].apply(lambda x:check_underground(x))\n",
    "\n",
    "# 建物の階数を加える\n",
    "df_all['building_floor']=df_all['building_floor'].apply(lambda x:building_floor_enc(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## お風呂・トイレの設備をワンホットエンコ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['bath']=df_all['bath'].fillna(0)\n",
    "df_all['bath_list']=df_all['bath'].apply(lambda x:x.split('／') if x !=0 else 'nan')\n",
    "\n",
    "def drop_t(x):\n",
    "    if x!='nan':\n",
    "        return list(map(lambda y:y.strip('\\t'),x))\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df_all['bath_list']=df_all['bath_list'].apply(lambda x:drop_t(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 14\n",
      "Vocabulary content: {'専用バス': 8, '専用トイレ': 7, 'バス': 3, 'トイレ別': 2, 'シャワー': 0, '浴室乾燥機': 10, '温水洗浄便座': 11, '洗面台独立': 9, '脱衣所': 12, '追焚機能': 13, '共同トイレ': 5, 'バスなし': 4, '共同バス': 6, 'トイレなし': 1}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "words=[]\n",
    "\n",
    "# CountVectorizer用の文字列リストを作成\n",
    "for i in range(len(df_all)):\n",
    "    str_list=df_all['bath_list'][i]\n",
    "    \n",
    "    # 要素が０の時は空白文字\n",
    "    if str_list==0:\n",
    "        words.append('')\n",
    "        \n",
    "    # リストを文字列化\n",
    "    else:\n",
    "        maped_list = map(str, str_list)  #mapで要素すべてを文字列に\n",
    "        mojiretu = ','.join(maped_list)\n",
    "        words.append(mojiretu)\n",
    "\n",
    "# CountVectorizer\n",
    "vec_count = CountVectorizer()\n",
    "\n",
    "# ベクトル化\n",
    "vec_count.fit(words)\n",
    "X = vec_count.transform(words)\n",
    "\n",
    "print('Vocabulary size: {}'.format(len(vec_count.vocabulary_)))\n",
    "print('Vocabulary content: {}'.format(vec_count.vocabulary_))\n",
    "bath_df=pd.DataFrame(X.toarray(), columns=vec_count.get_feature_names())\n",
    "bath_df.drop(['バス'],axis=1,inplace=True)\n",
    "df_all=pd.concat([df_all,bath_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## キッチン情報をワンホットエンコ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['kitchen']=df_all['kitchen'].fillna(0)\n",
    "df_all['kitchen_list']=df_all['kitchen'].apply(lambda x:x.split('／') if x !=0 else 'nan')\n",
    "\n",
    "def drop_t(x):\n",
    "    if x!='nan':\n",
    "        return list(map(lambda y:y.strip('\\t'),x))\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df_all['kitchen_list']=df_all['kitchen_list'].apply(lambda x:drop_t(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 15\n",
      "Vocabulary content: {'ガスコンロ': 3, 'コンロ2口': 5, 'システムキッチン': 9, '給湯': 13, '独立キッチン': 12, 'コンロ3口': 6, 'ihコンロ': 0, 'コンロ1口': 4, '冷蔵庫あり': 10, 'コンロ設置可': 8, 'カウンターキッチン': 2, 'l字キッチン': 1, '口数不明': 11, '電気コンロ': 14, 'コンロ4口以上': 7}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "words=[]\n",
    "\n",
    "# CountVectorizer用の文字列リストを作成\n",
    "for i in range(len(df_all)):\n",
    "    str_list=df_all['kitchen_list'][i]\n",
    "    \n",
    "    # 要素が０の時は空白文字\n",
    "    if str_list==0:\n",
    "        words.append('')\n",
    "        \n",
    "    # リストを文字列化\n",
    "    else:\n",
    "        maped_list = map(str, str_list)  #mapで要素すべてを文字列に\n",
    "        mojiretu = ','.join(maped_list)\n",
    "        words.append(mojiretu)\n",
    "\n",
    "# CountVectorizer\n",
    "vec_count = CountVectorizer()\n",
    "\n",
    "# ベクトル化\n",
    "vec_count.fit(words)\n",
    "X = vec_count.transform(words)\n",
    "\n",
    "print('Vocabulary size: {}'.format(len(vec_count.vocabulary_)))\n",
    "print('Vocabulary content: {}'.format(vec_count.vocabulary_))\n",
    "kitchen_df=pd.DataFrame(X.toarray(), columns=vec_count.get_feature_names())\n",
    "\n",
    "df_all=pd.concat([df_all,kitchen_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通信機器情報をワンホットエンコ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['broadcast']=df_all['broadcast'].fillna(0)\n",
    "df_all['broadcast_list']=df_all['broadcast'].apply(lambda x:x.split('／') if x !=0 else 'nan')\n",
    "\n",
    "def drop_t(x):\n",
    "    if x!='nan':\n",
    "        return list(map(lambda y:y.strip('\\t'),x))\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df_all['broadcast_list']=df_all['broadcast_list'].apply(lambda x:drop_t(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8\n",
      "Vocabulary content: {'インターネット対応': 4, 'catv': 1, 'csアンテナ': 2, 'bsアンテナ': 0, '光ファイバー': 5, '高速インターネット': 7, 'インターネット使用料無料': 3, '有線放送': 6}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "words=[]\n",
    "\n",
    "# CountVectorizer用の文字列リストを作成\n",
    "for i in range(len(df_all)):\n",
    "    str_list=df_all['broadcast_list'][i]\n",
    "    \n",
    "    # 要素が０の時は空白文字\n",
    "    if str_list==0:\n",
    "        words.append('')\n",
    "        \n",
    "    # リストを文字列化\n",
    "    else:\n",
    "        maped_list = map(str, str_list)  #mapで要素すべてを文字列に\n",
    "        mojiretu = ','.join(maped_list)\n",
    "        words.append(mojiretu)\n",
    "\n",
    "# CountVectorizer\n",
    "vec_count = CountVectorizer()\n",
    "\n",
    "# ベクトル化\n",
    "vec_count.fit(words)\n",
    "X = vec_count.transform(words)\n",
    "\n",
    "print('Vocabulary size: {}'.format(len(vec_count.vocabulary_)))\n",
    "print('Vocabulary content: {}'.format(vec_count.vocabulary_))\n",
    "broadcast_df=pd.DataFrame(X.toarray(), columns=vec_count.get_feature_names())\n",
    "\n",
    "df_all=pd.concat([df_all,broadcast_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 設備をワンホットエンコ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['facility']=df_all['facility'].fillna(0)\n",
    "df_all['facility_list']=df_all['facility'].apply(lambda x:x.split('\\t') if x !=0 else 'nan')\n",
    "\n",
    "def clean_list(words):\n",
    "    if words=='nan':\n",
    "        return 'nan'\n",
    "    else:\n",
    "        return [w for w in words if w !='／']\n",
    "\n",
    "df_all['facility_list']=df_all['facility_list'].apply(lambda x:clean_list(x))\n",
    "\n",
    "def drop_t(x):\n",
    "    if x!='nan':\n",
    "        return list(map(lambda y:y.strip('／'),x))\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df_all['facility_list']=df_all['facility_list'].apply(lambda x:drop_t(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 42\n",
      "Vocabulary content: {'エアコン付': 4, 'シューズボックス': 10, 'バルコニー': 14, 'フローリング': 15, '室内洗濯機置場': 28, '敷地内ごみ置き場': 34, 'エレベーター': 5, '公営水道': 24, '下水': 20, '都市ガス': 40, 'タイル張り': 11, 'ウォークインクローゼット': 3, '2面採光': 1, '24時間換気システム': 0, '3面採光': 2, 'ペアガラス': 17, '専用庭': 30, '水道その他': 35, '冷房': 25, 'クッションフロア': 9, '床暖房': 32, 'プロパンガス': 16, 'ロフト付き': 19, '出窓': 26, 'トランクルーム': 12, '汲み取り': 36, 'オール電化': 6, 'ルーフバルコニー': 18, '室外洗濯機置場': 29, '床下収納': 31, 'バリアフリー': 13, '浄化槽': 38, '防音室': 41, '二重サッシ': 22, '二世帯住宅': 21, 'ガスその他': 7, '洗濯機置場なし': 37, '排水その他': 33, '石油暖房': 39, '地下室': 27, 'ガス暖房': 8, '井戸': 23}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "words=[]\n",
    "\n",
    "# CountVectorizer用の文字列リストを作成\n",
    "for i in range(len(df_all)):\n",
    "    str_list=df_all['facility_list'][i]\n",
    "    \n",
    "    # 要素が０の時は空白文字\n",
    "    if str_list==0:\n",
    "        words.append('')\n",
    "        \n",
    "    # リストを文字列化\n",
    "    else:\n",
    "        maped_list = map(str, str_list)  #mapで要素すべてを文字列に\n",
    "        mojiretu = ','.join(maped_list)\n",
    "        words.append(mojiretu)\n",
    "\n",
    "# CountVectorizer\n",
    "vec_count = CountVectorizer()\n",
    "\n",
    "# ベクトル化\n",
    "vec_count.fit(words)\n",
    "X = vec_count.transform(words)\n",
    "\n",
    "print('Vocabulary size: {}'.format(len(vec_count.vocabulary_)))\n",
    "print('Vocabulary content: {}'.format(vec_count.vocabulary_))\n",
    "facility_df=pd.DataFrame(X.toarray(), columns=vec_count.get_feature_names())\n",
    "\n",
    "df_all=pd.concat([df_all,facility_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 駐車場の料金が分かるものは値を入れる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['parking']=df_all['parking'].fillna(0)\n",
    "price=[]\n",
    "def parking_price(src):\n",
    "    #  欠損は０とする\n",
    "    if src==0:\n",
    "        return 0\n",
    "    # 何かしらの料金の値を入れる。\n",
    "    else:\n",
    "        tmp=re.findall(r'\\d+,\\d+円',src)\n",
    "        if len(tmp)==0:\n",
    "            return 0\n",
    "    # 料金が複数ある場合は最大値を入れる\n",
    "        else:\n",
    "            if len(tmp)==1:\n",
    "                nums=tmp[0][:-1].split(',')\n",
    "                return int(nums[0])*1000+int(nums[1])\n",
    "            else:\n",
    "                if len(tmp)==2:\n",
    "                    nums1=tmp[0][:-1].split(',')\n",
    "                    nums2=tmp[1][:-1].split(',')\n",
    "            \n",
    "                    return max(int(nums1[0])*1000+int(nums1[1]),int(nums2[0])*1000+int(nums2[1]))\n",
    "            \n",
    "                else:\n",
    "\n",
    "                    nums1=tmp[0][:-1].split(',')\n",
    "                    nums2=tmp[1][:-1].split(',')\n",
    "                    nums3=tmp[2][:-1].split(',')\n",
    "                    return max(int(nums1[0])*1000+int(nums1[1]),int(nums2[0])*1000+int(nums2[1]),int(nums3[0])*1000+int(nums3[1]))\n",
    "\n",
    "df_all['parking_price']=df_all['parking'].apply(lambda x:parking_price(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 近隣状況の距離を入れる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62732/62732 [00:01<00:00, 39454.68it/s]\n"
     ]
    }
   ],
   "source": [
    "df_all['neighbors']=df_all['neighbors'].fillna(0)\n",
    "neightbor_dict=[]\n",
    "convenience_count=[]\n",
    "supermarket_count=[]\n",
    "\n",
    "for i in tqdm(range(len(df_all))):\n",
    "    tmp=dict()\n",
    "    convenience=0\n",
    "    supermarket=0\n",
    "    \n",
    "    neighbor_info=df_all['neighbors'][i]\n",
    "    \n",
    "    # 近隣情報が0 の場合は０を返す\n",
    "    if neighbor_info==0:\n",
    "        neightbor_dict.append(0)\n",
    "        convenience_count.append(convenience)\n",
    "        supermarket_count.append(supermarket)\n",
    "        \n",
    "    # 近隣情報の辞書配列を作成\n",
    "    else:   \n",
    "        for word in neighbor_info.split('\\t'):\n",
    "            place = re.findall(r'\\【.+?\\】', word)[0][1:-1]  # 建物の名前\n",
    "            distance=int(re.findall(r'\\d+m', word)[0][:-1])  #  距離\n",
    "    \n",
    "    # すでに同じ建物がある場合は、近い距離の値を入れる\n",
    "            if place in tmp.keys():\n",
    "                tmp[place]=max(tmp[place],distance)\n",
    "            else:\n",
    "                tmp[place]=distance\n",
    "                \n",
    "    #  コンビニとスーパーの数をカウント\n",
    "            if place=='コンビニ':\n",
    "                convenience+=1\n",
    "            if place=='スーパー':\n",
    "                supermarket+=1\n",
    "        \n",
    "        neightbor_dict.append(tmp)\n",
    "        convenience_count.append(convenience)\n",
    "        supermarket_count.append(supermarket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['neighbor_dict']=neightbor_dict\n",
    "df_all['convenience_count']=convenience_count\n",
    "df_all['supermarket_count']=supermarket_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辞書から指定された場所の距離を取得\n",
    "def neighbor_distance(x,place):\n",
    "    if x==0:\n",
    "        return 0\n",
    "    elif place in x.keys():\n",
    "        return x[place]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# 全ての場所の配列を取得\n",
    "places=[]\n",
    "for i in range(len(df_all)):\n",
    "    neighbor=df_all['neighbor_dict'][i]\n",
    "    if neighbor==0:\n",
    "        continue\n",
    "    else:\n",
    "        places.extend(neighbor.keys())\n",
    "\n",
    "for place in set(places):\n",
    "    df_all[place]=df_all['neighbor_dict'].apply(lambda x:neighbor_distance(x,place))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 構造をラベルエンコ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_structure=LabelEncoder()\n",
    "df_all['structure_cat']=le_structure.fit_transform(df_all['structure'])\n",
    "df_all['structure_cat']=df_all['structure_cat'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 期間を月単位に数値化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損を最頻値で補完\n",
    "df_all['period']=df_all['period'].fillna('2年間')\n",
    "\n",
    "# 定期借家かどうか\n",
    "df_all['is_rent']=df_all['period'].apply(lambda x:1 if '定期借家' in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 期間を月単位に変換\n",
    "def rent_period(x):\n",
    "    if 'まで' in x:\n",
    "        year=re.findall(r'\\d+年',x)[0][:-1]\n",
    "        month=re.findall(r'\\d+月',x)[0][:-1]\n",
    "        return int(year)*12+int(month)-2019*12-8\n",
    "    \n",
    "    else:\n",
    "        year=re.findall(r'\\d+年',x)\n",
    "        year=0 if len(year)==0 else year[0][:-1]\n",
    "\n",
    "        month=re.findall(r'\\d+ヶ', x)\n",
    "        month=0 if len(month)==0 else month[0][:-1]\n",
    "        \n",
    "        return int(year)*12+int(month)\n",
    "        \n",
    "df_all['period_num']=df_all['period'].apply(lambda x:rent_period(x.split('\\t')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all=df_all.select_dtypes(exclude='object')\n",
    "train=df_all[:train_index]\n",
    "test=df_all[train_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_feat1.csv')\n",
    "test.to_csv('test_feat1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021'"
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
